<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<link href="Styles/Style00.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style01.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style02.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style03.css" rel="stylesheet" type="text/css" />
<style type="text/css" title="ibis-book">
    @charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0 !important}#sbo-rt-content div.preface p.byline+p.byline{margin:0 !important}#sbo-rt-content div.sect1&gt;p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1&gt;p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]&gt;div&gt;h1,#sbo-rt-content section[data-type="preface"]&gt;div&gt;h1,#sbo-rt-content section[data-type="appendix"]&gt;div&gt;h1,#sbo-rt-content section[data-type="glossary"]&gt;div&gt;h1,#sbo-rt-content section[data-type="bibliography"]&gt;div&gt;h1,#sbo-rt-content section[data-type="index"]&gt;div&gt;h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content div.figure h6,#sbo-rt-content figure h6,#sbo-rt-content figure figcaption{font-size:.9rem !important;text-align:center;font-weight:normal !important;font-style:italic;font-family:serif !important;text-transform:none !important;letter-spacing:normal !important;color:#000;padding-top:.25em !important;margin-top:0 !important;page-break-before:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]&gt;div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:2em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content p[data-type="footnote"]{font-size:90% !important;line-height:1.2em !important;margin-left:2.5em !important;text-indent:-2.3em !important}#sbo-rt-content p[data-type="footnote"] sup{display:inline-block !important;position:static !important;width:2em !important;text-align:right !important;font-size:100% !important;padding-right:.5em !important}#sbo-rt-content p[data-type="footnote"] a[href$="-marker"]{font-family:sans-serif !important;font-size:90% !important;color:#8e0012 !important}#sbo-rt-content p[data-type="footnote"] a[data-type="xref"]{margin:0 !important;padding:0 !important;text-indent:0 !important}#sbo-rt-content a[data-type="noteref"]{font-family:sans-serif !important;color:#8e0012;margin-left:0;padding-left:0}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dl{margin-bottom:1.5em !important}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important;line-height:1.25rem;font-style:italic}#sbo-rt-content dd{margin:10px 0 .25em 1.5em !important;line-height:1.65em !important}#sbo-rt-content dd p{padding:0 !important;margin:0 0 10px !important}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul&gt;li,#sbo-rt-content ol ul,#sbo-rt-content ol ul&gt;li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul&gt;li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul&gt;li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul&gt;li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol&gt;li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol&gt;li,#sbo-rt-content ul ol,#sbo-rt-content ul ol&gt;li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol&gt;li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol&gt;li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol&gt;li&gt;ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol&gt;li&gt;ol&gt;li&gt;ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div[data-type="tip"] figure h6,#sbo-rt-content div[data-type="note"] figure h6,#sbo-rt-content div[data-type="warning"] figure h6,#sbo-rt-content div[data-type="caution"] figure h6,#sbo-rt-content div[data-type="important"] figure h6{font-family:serif !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content table li{margin:10px 0 0 .25em !important}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:top;font-size:80%}#sbo-rt-content th{vertical-align:bottom}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller;word-break:break-all}#sbo-rt-content table.border tbody&gt;tr:last-child&gt;td{border-bottom:transparent}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content div[data-type="equation"] math{font-size:calc(.35em + 1vw)}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index h3{padding:.25em;margin-top:1em !important;background-color:#F0F0F0}#sbo-rt-content div.index li{line-height:130%;list-style-type:none}#sbo-rt-content div.index a.indexterm{color:#8e0012 !important}#sbo-rt-content div.index ul{margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.index ul ul{margin-left:2em !important;margin-top:0 !important}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content pre.break-code,#sbo-rt-content code.break-code,#sbo-rt-content .break-code pre,#sbo-rt-content .break-code code{word-break:break-all}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content .width-10,#sbo-rt-content figure.width-10 img{width:10% !important}#sbo-rt-content .width-20,#sbo-rt-content figure.width-20 img{width:20% !important}#sbo-rt-content .width-30,#sbo-rt-content figure.width-30 img{width:30% !important}#sbo-rt-content .width-40,#sbo-rt-content figure.width-40 img{width:40% !important}#sbo-rt-content .width-50,#sbo-rt-content figure.width-50 img{width:50% !important}#sbo-rt-content .width-60,#sbo-rt-content figure.width-60 img{width:60% !important}#sbo-rt-content .width-70,#sbo-rt-content figure.width-70 img{width:70% !important}#sbo-rt-content .width-80,#sbo-rt-content figure.width-80 img{width:80% !important}#sbo-rt-content .width-90,#sbo-rt-content figure.width-90 img{width:90% !important}#sbo-rt-content .width-full,#sbo-rt-content .width-100{width:100% !important}#sbo-rt-content .sc{text-transform:none !important}#sbo-rt-content .right{float:none !important}#sbo-rt-content a.totri-footnote{padding:0 !important}#sbo-rt-content figure.width-10,#sbo-rt-content figure.width-20,#sbo-rt-content figure.width-30,#sbo-rt-content figure.width-40,#sbo-rt-content figure.width-50,#sbo-rt-content figure.width-60,#sbo-rt-content figure.width-70,#sbo-rt-content figure.width-80,#sbo-rt-content figure.width-90{width:auto !important}#sbo-rt-content p img,#sbo-rt-content pre img{width:1.25em;line-height:1em;margin:0 .15em -.2em}#sbo-rt-content figure.no-frame div.border-box{border:none}#sbo-rt-content .right{text-align:right !important}
    </style>
<style type="text/css" id="font-styles">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }</style>
<style type="text/css" id="font-family">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }</style>
<style type="text/css" id="column-width">#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }</style>

<style type="text/css">body{margin:1em;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}body{background-color:transparent!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style></head>
<body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 1. NLP: A Primer"><div class="chapter" id="nlp_a_primer">
<h1><span class="label">Chapter 1. </span>NLP: A Primer</h1>

<blockquote class="right">
<p class="right"><span class="keep-together"><em>A language is not just words. It’s a culture, a tradition,</em></span><br/> <span class="keep-together"><em>a unification of a community,</em></span><br/> <span class="keep-together"><em>a whole history that creates what a community is.</em></span><br/>
<span class="keep-together"><em>It’s all embodied in a language.</em></span><br/></p>
<p data-type="attribution" style="text-align:right"><em>Noam Chomsky</em></p>
</blockquote>

<p><a contenteditable="false" data-primary="Chomsky, Noam" data-type="indexterm" id="idm45969613359736"/>Imagine a hypothetical person, John Doe. He’s the CTO of a fast-growing technology startup. On a busy day, John wakes up and has this conversation with his digital <span class="keep-together">assistant:</span></p>

<p><em>John:</em> “How is the weather today?”</p>

<p><em>Digital assistant:</em> “It is 37 degrees centigrade outside with no rain today.”</p>

<p><em>John:</em> “What does my schedule look like?”</p>

<p><em>Digital assistant:</em> “You have a strategy meeting at 4 p.m. and an all-hands at 5:30 p.m. Based on today’s traffic situation, it is recommended you leave for the office by <span class="keep-together">8:15 a.m.”</span></p>

<p><em>While he’s getting dressed, John probes the assistant on his fashion choices:</em></p>

<p><em>John:</em> “What should I wear today?”</p>

<p><em>Digital assistant:</em> “White seems like a good choice.”</p>

<p><a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="overview" data-type="indexterm" id="ch01_term1"/>You might have used smart assistants such as Amazon Alexa<a contenteditable="false" data-primary="Amazon Alexa" data-type="indexterm" id="idm45969613349864"/>, Google Home<a contenteditable="false" data-primary="Google Home" data-type="indexterm" id="idm45969613348552"/>, or Apple Siri<a contenteditable="false" data-primary="Apple Siri" data-type="indexterm" id="idm45969613347288"/> to do similar things. We talk to these assistants not in a programming language, but in our natural language—the language we all communicate in. This natural language has been the primary medium of communication between humans since time immemorial. But computers can only process data in binary, i.e., 0s and 1s. While we can represent language data in binary, how do we make machines understand the <span class="keep-together">language?</span> This is where natural language processing (NLP) comes in. It is an area of computer science that deals with methods to analyze, model, and understand human language. Every intelligent application involving human language has some NLP behind it. In this book, we’ll explain what NLP is as well as how to use NLP to build and scale intelligent applications. Due to the open-ended nature of NLP problems, there are dozens of alternative approaches one can take to solve a given problem. This book will help you navigate this maze of options and suggests how to choose the best option based on your problem.</p>

<p>This chapter aims to give a quick primer of what NLP is before we start delving deeper into how to implement NLP-based solutions for different application scenarios. We’ll start with an overview of numerous applications of NLP in real-world scenarios, then cover the various tasks that form the basis of building different NLP applications. This will be followed by an understanding of language from an NLP perspective and of why NLP is difficult. After that, we’ll give an overview of heuristics, machine learning, and deep learning, then introduce a few commonly used algorithms in NLP. This will be followed by a walkthrough of an NLP application. Finally, we’ll conclude the chapter with an overview of the rest of the topics in the book. <a data-type="xref" href="#nlp_tasks_and_applications">Figure 1-1</a> shows a preview of the organization of the chapters in terms of various NLP tasks and applications.</p>

<figure><div id="nlp_tasks_and_applications" class="figure"><img alt="NLP tasks and applications" src="Images/pnlp_0101.png" width="1431" height="730"/>
<h6><span class="label">Figure 1-1. </span>NLP tasks and applications<a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="tasks and applications" data-type="indexterm" id="idm45969613340296"/></h6>
</div></figure>

<p>Let’s start by taking a look at some popular applications you use in everyday life that have some form of NLP as a major component.</p>

<section data-type="sect1" data-pdf-bookmark="NLP in the Real World"><div class="sect1" id="nlp_in_the_real_world">
<h1>NLP in the Real World</h1>

<p>NLP is an important component in a wide range of software applications<a contenteditable="false" data-primary="software applications" data-type="indexterm" id="ch01_term2"/> that we use in our daily lives. In this section, we’ll introduce some key applications and also take a look at some common tasks that you’ll see across different NLP applications. This section reinforces the applications we showed you in <a data-type="xref" href="#nlp_tasks_and_applications">Figure 1-1</a>, which you’ll see in more detail throughout the book.</p>

<p><a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="core applications" data-type="indexterm" id="idm45969613333048"/>Core applications:</p>

<ul>
	<li>
	<p><a contenteditable="false" data-primary="email platforms" data-type="indexterm" id="idm45969613330520"/>Email platforms, such as Gmail<a contenteditable="false" data-primary="Gmail" data-type="indexterm" id="idm45969613329192"/>, <a contenteditable="false" data-primary="Microsoft Outlook" data-type="indexterm" id="idm45969613327960"/>Outlook, etc., use NLP extensively to provide a range of product features, such as spam classification, priority inbox, calendar event extraction, auto-complete, etc. We’ll discuss some of these in detail in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch05.xhtml#information_extraction">5</a>.</p>
	</li>
	<li>
	<p><a contenteditable="false" data-primary="voice-based assistants" data-type="indexterm" id="idm45969613323192"/>Voice-based assistants, such as Apple Siri<a contenteditable="false" data-primary="Apple Siri" data-type="indexterm" id="idm45969612988184"/>, Google Assistant<a contenteditable="false" data-primary="Google Assistant" data-type="indexterm" id="idm45969612986952"/>, Microsoft Cortana<a contenteditable="false" data-primary="Microsoft Cortana" data-type="indexterm" id="idm45969612985688"/>, and Amazon Alexa<a contenteditable="false" data-primary="Amazon Alexa" data-type="indexterm" id="idm45969612984424"/> rely on a range of NLP techniques to interact with the user, understand user commands, and respond accordingly. We’ll cover key aspects of such systems in <a data-type="xref" href="ch06.xhtml#chatbots">Chapter 6</a>, where we discuss chatbots.</p>
	</li>
	<li>
	<p>Modern search engines<a contenteditable="false" data-primary="search engines" data-type="indexterm" id="idm45969612981288"/>, such as Google<a contenteditable="false" data-primary="Google" data-secondary="search engine" data-type="indexterm" id="idm45969612980024"/> and Bing<a contenteditable="false" data-primary="Bing (search engine)" data-type="indexterm" id="idm45969612978488"/>, which are the cornerstone of today’s internet, use NLP heavily for various subtasks, such as query understanding, query expansion, question answering, information retrieval, and ranking and grouping of the results, to name a few. We’ll discuss some of these subtasks in <a data-type="xref" href="ch07.xhtml#topics_in_brief">Chapter 7</a>.</p>
	</li>
	<li>
	<p><a contenteditable="false" data-primary="machine translation services" data-type="indexterm" id="idm45969612975208"/>Machine translation services, such as Google Translate<a contenteditable="false" data-primary="Google Translate" data-type="indexterm" id="idm45969612973896"/>, Bing Microsoft Translator<a contenteditable="false" data-primary="Bing Microsoft Translator" data-type="indexterm" id="idm45969612972664"/>, and <a contenteditable="false" data-primary="Amazon Translate" data-type="indexterm" id="idm45969612971368"/>Amazon Translate are increasingly used in today’s world to solve a wide range of scenarios and business use cases. These services are direct applications of NLP. We’ll touch on machine translation in <a data-type="xref" href="ch07.xhtml#topics_in_brief">Chapter 7</a>.</p>
	</li>
</ul>

<p>Other applications<a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="software applications" data-type="indexterm" id="ch01_term3"/>:</p>

<ul>
	<li>
	<p>Organizations across verticals analyze their social media<a contenteditable="false" data-primary="social media" data-type="indexterm" id="idm45969612965080"/> feeds to build a better and deeper understanding of the voice of their customers. We’ll cover this in <a data-type="xref" href="ch08.xhtml#social_media">Chapter 8</a>.</p>
	</li>
	<li>
	<p>NLP is widely used to solve diverse sets of use cases on e-commerce<a contenteditable="false" data-primary="e-commerce and retail" data-secondary="NLP applications" data-type="indexterm" id="idm45969612961784"/> platforms like Amazon<a contenteditable="false" data-primary="Amazon" data-type="indexterm" id="idm45969612960200"/>. These vary from extracting relevant information from product descriptions to understanding user reviews. <a data-type="xref" href="ch09.xhtml#e_commerce_and_retail">Chapter 9</a> covers these in detail.</p>
	</li>
	<li>
	<p>Advances in NLP are being applied to solve use cases in domains such as healthcare, finance, and <a contenteditable="false" data-primary="law" data-see="legal services" data-type="indexterm" id="idm45969612956872"/>law<a contenteditable="false" data-primary="healthcare" data-type="indexterm" id="idm45969612955368"/>. <a data-type="xref" href="ch10.xhtml#healthcarecomma_financecomma_and_law">Chapter 10</a> addresses these.</p>
	</li>
	<li>
	<p>Companies such as <a contenteditable="false" data-primary="Arria" data-type="indexterm" id="idm45969612952232"/>Arria [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612950968-marker" href="ch01.xhtml#idm45969612950968">1</a>] are working to use NLP techniques to automatically generate reports for various domains, from weather forecasting<a contenteditable="false" data-primary="weather forecasting" data-type="indexterm" id="idm45969612948744"/> to financial <span class="keep-together">services</span><a contenteditable="false" data-primary="financial services" data-type="indexterm" id="idm45969612946984"/>.</p>
	</li>
	<li>
	<p>NLP forms the backbone of spelling- and grammar-correction tools<a contenteditable="false" data-primary="grammar-correction tools" data-type="indexterm" id="idm45969612944856"/><a contenteditable="false" data-primary="spelling- and grammar-correction tools" data-type="indexterm" id="idm45969612943608"/>, such as <a contenteditable="false" data-primary="Grammarly" data-type="indexterm" id="idm45969612942360"/>Grammarly and spell check in Microsoft Word<a contenteditable="false" data-primary="Microsoft Word" data-type="indexterm" id="idm45969612941032"/> and Google Docs<a contenteditable="false" data-primary="Google Docs" data-type="indexterm" id="idm45969612908760"/>.</p>
	</li>
	<li>
	<p><a contenteditable="false" data-primary="Jeopardy!" data-type="indexterm" id="idm45969612906728"/><em>Jeopardy!</em> is a popular quiz show on TV. In the show, contestants are presented with clues in the form of answers, and the contestants must phrase their responses in the form of questions. IBM<a contenteditable="false" data-primary="IBM Watson" data-type="indexterm" id="idm45969612905016"/> built the Watson AI to compete with the show’s top players. Watson won the first prize with a million dollars, more than the world champions. Watson AI was built using NLP techniques and is one of the examples of NLP bots winning a world competition.</p>
	</li>
	<li>
	<p>NLP is used in a range of learning and assessment tools<a contenteditable="false" data-primary="assessment tools" data-type="indexterm" id="idm45969612902424"/><a contenteditable="false" data-primary="learning and assessment tools" data-type="indexterm" id="idm45969612901352"/> and technologies, such as automated scoring<a contenteditable="false" data-primary="automated scoring" data-type="indexterm" id="idm45969612900088"/> in exams like the Graduate Record Examination (GRE), plagiarism detection<a contenteditable="false" data-primary="plagiarism detection" data-type="indexterm" id="idm45969612898856"/> (e.g., <a contenteditable="false" data-primary="Turnitin" data-type="indexterm" id="idm45969612897624"/>Turnitin), intelligent tutoring systems<a contenteditable="false" data-primary="intelligent tutoring systems" data-type="indexterm" id="idm45969612896360"/>, and language learning apps<a contenteditable="false" data-primary="language learning apps" data-type="indexterm" id="idm45969612895064"/> like Duolingo<a contenteditable="false" data-primary="Duolingo" data-type="indexterm" id="idm45969612893832"/>.</p>
	</li>
	<li>
	<p>NLP is used to build large knowledge bases<a contenteditable="false" data-primary="knowledge bases" data-type="indexterm" id="idm45969612891736"/>, such as the <a contenteditable="false" data-primary="Google Knowledge Graph" data-type="indexterm" id="idm45969612890504"/>Google Knowledge Graph, which are useful in a range of applications like search and question answering.</p>
	</li>
</ul>

<p>This list is by no means exhaustive. NLP is increasingly being used across several other <a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="software applications" data-startref="ch01_term3" data-type="indexterm" id="idm45969612888472"/>applications, and newer applications of NLP are coming up as we speak. Our main focus is to introduce you to the ideas behind building these applications. We do so by discussing different kinds of NLP problems and how to solve them. To get a perspective on what you are about to learn in this book, and to appreciate the nuances that go into building these NLP applications, let’s take a look at some key NLP tasks that form the bedrock of many NLP applications and industry use <a contenteditable="false" data-primary="software applications" data-startref="ch01_term2" data-type="indexterm" id="idm45969612886232"/>cases.</p>

<section data-type="sect2" data-pdf-bookmark="NLP Tasks"><div class="sect2" id="nlp_tasks">
<h2>NLP Tasks</h2>

<p>There is a collection of fundamental tasks that appear frequently across various <a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="tasks and applications" data-type="indexterm" id="ch01_term4"/>NLP projects. Owing to their repetitive and fundamental nature, these tasks have been studied extensively. Having a good grip on them will make you ready to build various NLP applications across verticals. (We also saw some of these tasks earlier in <a data-type="xref" href="#nlp_tasks_and_applications">Figure 1-1</a>.) Let’s briefly introduce them:</p>

<dl>
	<dt>Language modeling<a contenteditable="false" data-primary="language modeling" data-type="indexterm" id="idm45969612878552"/></dt>
	<dd>This is the task of predicting what the next word in a sentence will be based on the history of previous words. The goal of this task is to learn the probability of a sequence of words appearing in a given language. Language modeling is useful for building solutions for a wide variety of problems, such as speech recognition, optical character recognition, handwriting recognition, machine translation, and spelling correction.</dd>
	<dt>Text classification<a contenteditable="false" data-primary="text classification" data-type="indexterm" id="idm45969612876136"/></dt>
	<dd>This is the task of bucketing the text into a known set of categories based on its content. Text classification is by far the most popular task in NLP and is used in a variety of tools, from email spam identification to sentiment analysis.</dd>
	<dt><a contenteditable="false" data-primary="information extraction (IE)" data-type="indexterm" id="idm45969612874040"/>Information extraction</dt>
	<dd>As the name indicates, this is the task of extracting relevant information from text, such as calendar events from emails or the names of people mentioned in a social media post.</dd>
	<dt><a contenteditable="false" data-primary="information retrieval" data-type="indexterm" id="idm45969612871864"/>Information retrieval</dt>
	<dd>This is the task of finding documents relevant to a user query from a large collection. Applications like Google Search<a contenteditable="false" data-primary="Google Search" data-type="indexterm" id="idm45969612870056"/> are well-known use cases of information retrieval.</dd>
	<dt><a contenteditable="false" data-primary="conversational agents" data-type="indexterm" id="idm45969612868536"/>Conversational agent</dt>
	<dd>This is the task of building dialogue systems that can converse in human languages. Alexa<a contenteditable="false" data-primary="Amazon Alexa" data-type="indexterm" id="idm45969612866744"/>, <a contenteditable="false" data-primary="Apple Siri" data-type="indexterm" id="idm45969612865512"/>Siri, etc., are some common applications of this task.</dd>
	<dt><a contenteditable="false" data-primary="text summarization" data-type="indexterm" id="idm45969612863896"/>Text summarization</dt>
	<dd>This task aims to create short summaries of longer documents while retaining the core content and preserving the overall meaning of the text.</dd>
	<dt><a contenteditable="false" data-primary="question answering (QA)" data-type="indexterm" id="idm45969612861768"/>Question answering</dt>
	<dd>This is the task of building a system that can automatically answer questions posed in natural language.</dd>
	<dt><a contenteditable="false" data-primary="machine translation (MT)" data-type="indexterm" id="idm45969612859672"/>Machine translation</dt>
	<dd>This is the task of converting a piece of text from one language to another. Tools like Google Translate<a contenteditable="false" data-primary="Google Translate" data-type="indexterm" id="idm45969612857848"/> are common applications of this task.</dd>
	<dt><a contenteditable="false" data-primary="topic modeling" data-type="indexterm" id="idm45969612856328"/>Topic modeling</dt>
	<dd>This is the task of uncovering the topical structure of a large collection of documents. Topic modeling is a common text-mining tool and is used in a wide range of domains, from literature to bioinformatics.</dd>
</dl>

<p><a data-type="xref" href="#nlp_tasks_organized_according_to_their">Figure 1-2</a> shows a depiction of these tasks based on their relative difficulty in terms of developing comprehensive solutions.</p>

<figure><div id="nlp_tasks_organized_according_to_their" class="figure"><img alt="NLP tasks organized according to their relative difficulty" src="Images/pnlp_0102.png" width="1346" height="1078"/>
<h6><span class="label">Figure 1-2. </span>NLP tasks organized according to their relative difficulty</h6>
</div></figure>

<p>In the<a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="tasks organized according to relative difficulty" data-type="indexterm" id="idm45969612850808"/> rest of the chapters in this book, we’ll see these tasks’ challenges and learn how to develop solutions that work for certain use cases (even the hard tasks shown in the figure). To get there, it is useful to have an understanding of the nature of human language and the challenges in automating language processing. The next two sections provide a basic overview<a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="tasks and applications" data-startref="ch01_term4" data-type="indexterm" id="idm45969612848776"/>.</p>


</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="What Is Language?"><div class="sect1" id="what_is_languagequestion_mark">
<h1>What Is Language?</h1>

<p>Language is a structured system of communication that involves complex combinations of its constituent components, such as characters, words, sentences, etc. Linguistics is the systematic study of language. In order to study NLP, it is important to understand some concepts from <a contenteditable="false" data-primary="linguistics" data-type="indexterm" id="ch01_term5"/>linguistics about how language is structured. In this section, we’ll introduce them and cover how they relate to some of the NLP tasks we listed earlier.</p>

<p>We can think of human language<a contenteditable="false" data-primary="language" data-secondary="building blocks of" data-type="indexterm" id="ch01_term6"/> as composed of four major building blocks: phonemes, morphemes and lexemes, syntax, and context. NLP applications need knowledge of different levels of these building blocks, starting<a contenteditable="false" data-primary="phonemes" data-type="indexterm" id="idm45969612840424"/> from the basic sounds <span class="keep-together">of language (phonemes)</span> to texts with some meaningful expressions<a contenteditable="false" data-primary="context" data-type="indexterm" id="idm45969612838472"/> (context). <a data-type="xref" href="#building_blocks_of_language_and_their_a">Figure 1-3</a> shows these building blocks of language, what they encompass, and a few NLP applications we introduced earlier that require this knowledge. Some of the terms listed here that were not introduced earlier in this chapter (e.g., parsing, word embeddings, etc.) will be introduced later in these first three chapters.</p>

<figure><div id="building_blocks_of_language_and_their_a" class="figure"><img alt="Building blocks of language and their applications" src="Images/pnlp_0103.png" width="968" height="726"/>
<h6><span class="label">Figure 1-3. </span>Building blocks of language and their applications</h6>
</div></figure>

<section data-type="sect2" data-pdf-bookmark="Building Blocks of Language"><div class="sect2" id="building_blocks">
<h2>Building Blocks of Language</h2>
<p>Let’s first introduce what these blocks of language are to give context for the challenges involved in NLP.</p>

<section data-type="sect3" data-pdf-bookmark="Phonemes"><div class="sect3" id="phonemes">
<h3>Phonemes</h3>
<p>Phonemes are the smallest units of sound in a language. They may not have any meaning by themselves but can induce meanings when uttered in combination with other <a contenteditable="false" data-primary="phonemes" data-type="indexterm" id="idm45969612830152"/>phonemes. For example, standard English<a contenteditable="false" data-primary="English" data-type="indexterm" id="idm45969612828872"/> has 44 phonemes, which are either single letters or a combination of letters [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612827640-marker" href="ch01.xhtml#idm45969612827640">2</a>]. <a data-type="xref" href="#phonemes_and_examples">Figure 1-4</a> shows these phonemes along with sample words. Phonemes are particularly important in applications involving speech understanding, such as speech recognition, speech-to-text transcription, and text-to-speech conversion.</p>

<figure><div id="phonemes_and_examples" class="figure"><img alt="Phonemes and examples" src="Images/pnlp_0104.png" width="1302" height="843"/>
<h6><span class="label">Figure 1-4. </span>Phonemes and examples</h6>
</div></figure>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Morphemes and lexemes"><div class="sect3" id="morphemes_and_lexemes">
<h3>Morphemes and lexemes</h3>
<p>A morpheme is the smallest unit of language that has a meaning. It is formed by a combination of phonemes. Not all morphemes are words, but all prefixes and suffixes are morphemes<a contenteditable="false" data-primary="morphemes" data-type="indexterm" id="idm45969612820712"/>. For example, in the word “multimedia,” “multi-” is not a word but a prefix that changes the meaning when put together with “media.” “Multi-” is a morpheme. <a data-type="xref" href="#morpheme_examples">Figure 1-5</a> illustrates some words and their morphemes. For words like “cats” and “unbreakable,” their morphemes are just constituents of the full word, whereas for words like “tumbling” and “unreliability,” there is some variation when breaking the words down into their morphemes.</p>

<figure><div id="morpheme_examples" class="figure"><img alt="Morpheme examples" src="Images/pnlp_0105.png" width="598" height="264"/>
<h6><span class="label">Figure 1-5. </span>Morpheme examples</h6>
</div></figure>

<p>Lexemes are the structural variations of morphemes related to one another by meaning. For example, “run” and “running” belong to the same lexeme form. <a contenteditable="false" data-primary="morphological analysis" data-type="indexterm" id="idm45969612815592"/>Morphological analysis, which analyzes the structure of words by studying its morphemes and lexemes<a contenteditable="false" data-primary="lexemes" data-type="indexterm" id="idm45969612814248"/>, is a foundational block for many NLP tasks, such as tokenization, stemming, learning word embeddings, and part-of-speech tagging, which we’ll introduce in the next chapter.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Syntax"><div class="sect3" id="syntax">
<h3>Syntax</h3>
<p>Syntax<a contenteditable="false" data-primary="syntax" data-type="indexterm" id="idm45969612810920"/> is a set of rules to construct grammatically correct sentences out of words and phrases in a language. Syntactic structure in linguistics is represented in many different ways. A common approach to representing sentences is a parse tree<a contenteditable="false" data-primary="parse trees" data-type="indexterm" id="idm45969612809400"/>. <a data-type="xref" href="#syntactic_structure_of_two_syntacticall">Figure 1-6</a> shows an example parse tree for two English sentences.</p>

<figure><div id="syntactic_structure_of_two_syntacticall" class="figure"><img alt="Syntactic structure of two syntactically similar sentences" src="Images/pnlp_0106.png" width="739" height="514"/>
<h6><span class="label">Figure 1-6. </span>Syntactic structure of two syntactically similar sentences</h6>
</div></figure>

<p>This has a hierarchical structure of language, with words at the lowest level, followed by part-of-speech tags, followed by phrases, and ending with a sentence at the highest level. In <a data-type="xref" href="#syntactic_structure_of_two_syntacticall">Figure 1-6</a>, both sentences have a similar structure and hence a similar syntactic parse tree. In this representation, N stands for noun, V for verb, and P for preposition. Noun phrase is denoted by NP and verb phrase by VP. The two noun phrases are “The girl” and “The boat,” while the two verb phrases are “laughed at the monkey” and “sailed up the river.” The syntactic structure is guided by a set of grammar rules for the language (e.g., the sentence comprises an NP and a VP), and this in turn guides some of the fundamental tasks of language processing, such as parsing. Parsing is the NLP task of constructing such trees automatically. Entity extraction and relation extraction are some of the NLP tasks that build on this knowledge of parsing, which we’ll discuss in more detail in <a data-type="xref" href="ch05.xhtml#information_extraction">Chapter 5</a>. Note that the parse structure described above is specific to English. The syntax of one language can be very different from that of another language, and the language-processing approaches needed for that language will change accordingly.</p>
</div></section>

<section data-type="sect3" class="pagebreak-before" data-pdf-bookmark="Context"><div class="sect3" id="context">
<h3 class="less_space">Context</h3>
<p>Context<a contenteditable="false" data-primary="context" data-type="indexterm" id="idm45969605415752"/> is how various parts in a language come together to convey a particular meaning. Context includes long-term references, world knowledge, and common sense along with the literal meaning of words and phrases. The meaning of a sentence can change based on the context, as words and phrases can sometimes have multiple meanings. Generally, context is composed from semantics and <a contenteditable="false" data-primary="pragmatics" data-type="indexterm" id="idm45969605414216"/>pragmatics. Semantics<a contenteditable="false" data-primary="semantics" data-type="indexterm" id="idm45969605413016"/> is the direct meaning of the words and sentences without external context. Pragmatics adds world knowledge and external context of the conversation to enable us to infer implied meaning. Complex NLP tasks such as sarcasm detection, summarization, and topic modeling are some of tasks that use context heavily.</p>

<p>Linguistics is the study of language and hence is a vast area in itself, and we only introduced some basic ideas to illustrate the role of linguistic knowledge in NLP. Different tasks in NLP require varying degrees of knowledge about these building blocks of language. An interested reader can refer to the books written by Emily <a contenteditable="false" data-primary="Bender, Emily" data-type="indexterm" id="idm45969605410440"/>Bender [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605409208-marker" href="ch01.xhtml#idm45969605409208">3</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605407864-marker" href="ch01.xhtml#idm45969605407864">4</a>] on the <a contenteditable="false" data-primary="linguistics" data-startref="ch01_term5" data-type="indexterm" id="idm45969605406536"/>linguistic fundamentals for NLP for further study. Now that we have some idea of what the building blocks of <a contenteditable="false" data-primary="language" data-secondary="building blocks of" data-startref="ch01_term6" data-type="indexterm" id="idm45969605404904"/>language are, let’s see why language can be hard for computers to understand and what makes NLP challenging.</p>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Why Is NLP Challenging?"><div class="sect2" id="how_does_language_make_nlp_challengingq">
<h2>Why Is NLP Challenging?</h2>

<p>What makes NLP a challenging problem domain? The ambiguity and creativity of human language<a contenteditable="false" data-primary="language" data-secondary="characteristics that make NLP challenging" data-type="indexterm" id="ch01_term7"/> are just two of the characteristics that make NLP a demanding area to work in. This section explores each characteristic in more detail, starting with ambiguity of language.</p>

<section data-type="sect3" data-pdf-bookmark="Ambiguity"><div class="sect3" id="ambiguity">
<h3>Ambiguity</h3>

<p><a contenteditable="false" data-primary="ambiguity " data-type="indexterm" id="ch01_term8"/>Ambiguity means uncertainty of meaning. Most human <a contenteditable="false" data-primary="language" data-secondary="ambiguity in" data-type="indexterm" id="ch01_term9"/>languages are inherently ambiguous. Consider the following sentence: “I made her duck.” This sentence has multiple meanings. The first one is: I cooked a duck for her. The second meaning is: I made her bend down to avoid an object. (There are other possible meanings, too; we’ll leave them for the reader to think of.) Here, the ambiguity comes from the use of the word “made.” Which of the two meanings applies depends on the context in which the sentence appears. If the sentence appears in a story about a mother and a child, then the first meaning will probably apply. But if the sentence appears in a book about sports, then the second meaning will likely apply. The example we saw is a direct sentence.</p>



<p>When it comes to <a contenteditable="false" data-primary="figurative language" data-type="indexterm" id="idm45969605392680"/>figurative language<a contenteditable="false" data-primary="language" data-secondary="figurative" data-type="indexterm" id="idm45969605391416"/>—i.e., idioms—the ambiguity only increases. For example, “He is as good as John Doe.” Try to answer, “How good is he?” The answer depends on how good John Doe is. <a data-type="xref" href="#examples_of_ambiguity_in_language_from">Figure 1-7</a> shows some examples illustrating ambiguity in language.</p>

<figure><div id="examples_of_ambiguity_in_language_from" class="figure"><img alt="Examples of ambiguity in language from the Winograd Schema Challenge" src="Images/pnlp_0107.png" width="960" height="982"/>
<h6><span class="label">Figure 1-7. </span>Examples of ambiguity in language from the Winograd Schema Challenge</h6>
</div></figure>

<p>The examples come from the Winograd Schema Challenge<a contenteditable="false" data-primary="Winograd Schema Challenge" data-type="indexterm" id="idm45969605386072"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605384872-marker" href="ch01.xhtml#idm45969605384872">5</a>], named after Professor Terry Winograd of Stanford University. This schema has pairs of sentences that differ by only a few words, but the meaning of the sentences is often flipped because of this minor change. These examples are easily disambiguated by a human but are not solvable using most NLP techniques. Consider the pairs of sentences in the figure and the questions associated with them. With some thought, how the answer changes should be apparent based on a single word variation. As another experiment, consider taking an off-the-shelf NLP system like Google Translate<a contenteditable="false" data-primary="Google Translate" data-type="indexterm" id="idm45969605382920"/> and try various examples to see how such ambiguities<a contenteditable="false" data-primary="language" data-secondary="ambiguity in" data-startref="ch01_term9" data-type="indexterm" id="idm45969605381656"/> affect (or don’t affect) the output of the <a contenteditable="false" data-primary="ambiguity" data-startref="ch01_term8" data-type="indexterm" id="idm45969605379816"/>system.</p>




</div></section>

<section data-type="sect3" data-pdf-bookmark="Common knowledge"><div class="sect3" id="common_knowledge">
<h3>Common knowledge</h3>
<p>A key aspect of any human language is “common knowledge<a contenteditable="false" data-primary="common knowledge" data-type="indexterm" id="ch01_term10"/>.” It is the set of all facts that most humans are aware of. In any conversation, it is assumed that these facts are known, hence they’re not explicitly mentioned, but they do have a bearing on the meaning of the sentence. For example, consider two sentences: “man bit dog” and “dog bit man.” We all know that the first sentence is unlikely to happen, while the second one is very possible. Why do we say so? Because we all “know” that it is very unlikely that a human will bite a dog. Further, dogs are known to bite humans. This knowledge is required for us to say that the first sentence is unlikely to happen while the second one is possible. Note that this common knowledge was not mentioned in either sentence. Humans use common knowledge all the time to understand and <span class="keep-together">process</span> any language. In the above example, the two sentences are syntactically very similar, but a computer would find it very difficult to differentiate between the two, as it lacks the common knowledge humans have. One of the key challenges in NLP is how to encode all the things that are common knowledge to humans in a computational <a contenteditable="false" data-primary="common knowledge" data-startref="ch01_term10" data-type="indexterm" id="idm45969605373240"/>model.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Creativity"><div class="sect3" id="creativity">
<h3>Creativity</h3>

<p>Language is not just rule driven; there is also a creative aspect to it. Various styles, dialects, genres, and variations are used in any language. Poems are a great example of creativity<a contenteditable="false" data-primary="creativity" data-type="indexterm" id="idm45969605369640"/> in language. Making machines understand creativity is a hard problem not just in NLP, but in AI in general.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Diversity across languages"><div class="sect3" id="diversity_across_languages">
<h3>Diversity across languages</h3>

<p>For<a contenteditable="false" data-primary="diversity across languages" data-secondary-sortas="languages" data-type="indexterm" id="idm45969605366488"/> most languages<a contenteditable="false" data-primary="language" data-secondary="diversity across" data-type="indexterm" id="idm45969605364936"/> in the world, there is no direct mapping between the vocabularies of any two languages. This makes porting an NLP solution from one language to another hard. A solution that works for one language might not work at all for another language. This means that one either builds a solution that is language agnostic or that one needs to build separate solutions for each language. While the first one is conceptually very hard, the other is laborious and time intensive.</p>

<p>All these issues make NLP a challenging—yet rewarding—domain to work in. Before looking into how some of these challenges are tackled in NLP, we should know the common approaches to solving NLP problems. Let’s start with an overview of how machine learning and deep learning are connected to NLP before delving deeper into different approaches to <a contenteditable="false" data-primary="language" data-secondary="characteristics that make NLP challenging" data-startref="ch01_term7" data-type="indexterm" id="idm45969605362136"/>NLP.</p>
</div></section>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Machine Learning, Deep Learning, and NLP: An Overview"><div class="sect1" id="machine_learningcomma_deep_learningcomm">
<h1>Machine Learning, Deep Learning, and NLP: An Overview</h1>

<p>Loosely speaking, artificial intelligence (AI)<a contenteditable="false" data-primary="artificial intelligence (AI)" data-type="indexterm" id="idm45969605357816"/> is a branch of computer science that aims to build systems that can perform tasks that require human intelligence. This is sometimes also called “<a contenteditable="false" data-primary="machine intelligence" data-seealso="artificial intelligence" data-type="indexterm" id="idm45969605356456"/>machine intelligence.” The foundations of AI were laid in the 1950s at a workshop organized at Dartmouth College<a contenteditable="false" data-primary="Dartmouth College" data-type="indexterm" id="idm45969605354824"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605353592-marker" href="ch01.xhtml#idm45969605353592">6</a>]. Initial AI was largely built out of logic-, heuristics-, and rule-based systems. <a contenteditable="false" data-primary="machine learning (ML)" data-secondary="overview" data-type="indexterm" id="ch01_term11"/>Machine learning (ML) is a branch of AI that deals with the development of algorithms that can learn to perform tasks automatically based on a large number of examples, without requiring handcrafted rules. Deep learning (DL<a contenteditable="false" data-primary="DL" data-see="deep learning" data-type="indexterm" id="idm45969605350200"/>)<a contenteditable="false" data-primary="deep learning (DL)" data-secondary="overview" data-type="indexterm" id="ch01_term12"/> refers to the branch of machine learning that is based on artificial neural network architectures. ML<a contenteditable="false" data-primary="ML" data-see="machine learning" data-type="indexterm" id="idm45969605346776"/>, DL, and NLP are all subfields within AI, and the relationship between them is depicted in <a data-type="xref" href="#how_nlpcomma_mlcomma_and_dl_are_related">Figure 1-8</a>.</p>

<p>While there is some overlap between NLP, ML, and DL, they are also quite different areas of study, as the figure illustrates. Like other early work in AI, early NLP applications were also based on rules and heuristics. In the past few decades, though, NLP application development has been heavily influenced by methods from ML. More recently, DL has also been frequently used to build NLP applications. Considering this, let’s do a short overview of ML and DL in this section.</p>

<figure><div id="how_nlpcomma_mlcomma_and_dl_are_related" class="figure"><img alt="How NLP, ML, and DL are related" src="Images/pnlp_0108.png" width="1388" height="864"/>
<h6><span class="label">Figure 1-8. </span>How NLP, ML, and DL are related</h6>
</div></figure>

<p>The goal of ML is to “learn” to perform tasks based on examples (called “<a contenteditable="false" data-primary="training data" data-type="indexterm" id="idm45969605340840"/>training data”) without explicit instruction. This is typically done by creating a numeric representation (called “<a contenteditable="false" data-primary="features" data-type="indexterm" id="idm45969605339480"/>features”) of the training data and using this representation to learn the patterns in those examples. Machine learning algorithms can be grouped into three primary paradigms: <a contenteditable="false" data-primary="supervised learning" data-type="indexterm" id="idm45969605338056"/>supervised learning, unsupervised learning<a contenteditable="false" data-primary="unsupervised learning" data-type="indexterm" id="idm45969605336760"/>, and reinforcement learning<a contenteditable="false" data-primary="reinforcement learning" data-type="indexterm" id="idm45969605335528"/>. In supervised learning, the goal is to learn the mapping function from input to output given a large number of examples in the form of input-output pairs. The input-output pairs are known as <em>training data</em>, and the outputs are specifically known as <em><a contenteditable="false" data-primary="labels" data-type="indexterm" id="idm45969605333448"/>labels</em> or <em>ground truth<a contenteditable="false" data-primary="ground truth" data-type="indexterm" id="idm45969605331768"/></em>. An example of a supervised learning problem related to language is learning to classify email messages as spam or non-spam given thousands of examples in both categories. This is a common scenario in NLP, and we’ll see examples of supervised learning throughout the book, especially in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>.</p>

<p>Unsupervised learning refers to a set of machine learning methods that aim to find hidden patterns in given input data without any reference output. That is, in contrast to supervised learning, unsupervised learning works with large collections of unlabeled data. In NLP, an example of such a task is to identify latent topics in a large collection of textual data without any knowledge of these topics. This is known as <em>topic modeling<a contenteditable="false" data-primary="topic modeling" data-type="indexterm" id="idm45969605328232"/></em>, and we’ll discuss it in <a data-type="xref" href="ch07.xhtml#topics_in_brief">Chapter 7</a>.</p>

<p>Common in real-world NLP projects is a case of semi-supervised learning<a contenteditable="false" data-primary="semi-supervised learning" data-type="indexterm" id="idm45969605325592"/>, where we have a small labeled dataset and a large unlabeled dataset. Semi-supervised techniques involve using both datasets to learn the task at hand. Last but not least, reinforcement learning deals with methods to learn tasks via trial and error and is characterized by the absence of either labeled or unlabeled data in large quantities. The learning is done in a self-contained environment and improves via feedback (reward or punishment) facilitated by the environment. This form of learning is not common in applied NLP (yet). It is more common in applications such as machine-playing games like go or chess, in the design of autonomous vehicles, and in robotics.</p>

<p>Deep learning refers to the branch of machine learning that is based on artificial neural network architectures. The ideas behind neural networks are inspired by neurons in the human brain and how they interact with one another. In the past decade, deep learning–based neural architectures have been used to successfully improve the performance of various intelligent applications, such as image and speech recognition and machine translation. This has resulted in a proliferation of deep learning–based solutions in industry, including in NLP applications.</p>

<p>Throughout this book, we’ll discuss how all these approaches are used for developing various NLP applications. Let’s now discuss the different approaches to solve any given <a contenteditable="false" data-primary="deep learning (DL)" data-secondary="overview" data-startref="ch01_term12" data-type="indexterm" id="idm45969605321928"/>NLP <a contenteditable="false" data-primary="machine learning (ML)" data-secondary="overview" data-startref="ch01_term11" data-type="indexterm" id="idm45969605320152"/>problem.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Approaches to NLP"><div class="sect1" id="approaches_to_nlp">
<h1>Approaches to NLP</h1>

<p>The different <a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="approaches to" data-type="indexterm" id="ch01_term13"/>approaches used to solve NLP problems commonly fall into three categories: heuristics, machine learning, and deep learning. This section is simply an introduction to each approach—don’t worry if you can’t quite grasp the concepts yet, as they’ll be discussed in detail throughout the rest of the book. Let’s jump in by discussing <a contenteditable="false" data-primary="heuristics" data-type="indexterm" id="ch01_term15"/><a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="heuristics-based" data-type="indexterm" id="ch01_term14"/>heuristics-based NLP.</p>

<section data-type="sect2" data-pdf-bookmark="Heuristics-Based NLP"><div class="sect2" id="heuristics_based_nlp">
<h2>Heuristics-Based NLP</h2>

<p>Similar to other early AI systems, early attempts at designing NLP systems were based on building rules for the task at hand. This required that the developers had some expertise in the domain to formulate rules that could be incorporated into a program. Such systems also required resources like dictionaries and thesauruses, typically compiled and digitized over a period of time. An example of designing rules to solve an NLP problem using such resources is lexicon-based sentiment analysis. It uses counts of positive and negative words in the text to deduce the sentiment of the text. We’ll cover this briefly in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>.</p>

<p>Besides dictionaries and thesauruses, more elaborate knowledge bases have been built to aid NLP in general and rule-based NLP in particular. One example is <a contenteditable="false" data-primary="Wordnet" data-type="indexterm" id="idm45969605306888"/>Wordnet [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605305656-marker" href="ch01.xhtml#idm45969605305656">7</a>], which is a database of words and the semantic relationships between them. Some examples of such relationships are synonyms, hyponyms, and meronyms. Synonyms refer to words with similar meanings. Hyponyms capture is-type-of relationships. For example, baseball, sumo wrestling, and tennis are all hyponyms of sports. Meronyms capture is-part-of relationships. For example, hands and legs are meronyms of the body. All this information becomes useful when building rule-based systems around language. <a data-type="xref" href="#wordnet_graph_for_the_word_quotation_ma">Figure 1-9</a> shows an example depiction of such relationships between words using Wordnet.</p>

<figure><div id="wordnet_graph_for_the_word_quotation_ma" class="figure"><img alt="Wordnet graph for the word “sport” [_38]" src="Images/pnlp_0109.png" width="1417" height="1267"/>
<h6><span class="label">Figure 1-9. </span>Wordnet graph for the word “sport” [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605301160-marker" href="ch01.xhtml#idm45969605301160">8</a>]</h6>
</div></figure>

<p>More recently, common sense world knowledge has also been incorporated into knowledge bases like Open Mind Common Sense<a contenteditable="false" data-primary="Open Mind Common Sense" data-type="indexterm" id="idm45969605298840"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605297608-marker" href="ch01.xhtml#idm45969605297608">9</a>], which also aids such rule-based systems. While what we’ve seen so far are largely lexical resources based on word-level information, rule-based systems go beyond words and can incorporate other forms of information, too. Some of them are introduced below.</p>

<p><a contenteditable="false" data-primary="regular expressions (regex)" data-type="indexterm" id="idm45969605295208"/>Regular expressions (regex) are a great tool for text analysis and building rule-based systems. A regex is a set of characters or a pattern that is used to match and find <span class="keep-together">substrings</span> in text. For example, a regex like ‘^([a-zA-Z0-9_\-\.]+)@([a-zA-Z0-9_\-\.]+)\.([a-zA-Z]{2,5})$’ is used to find all email IDs in a piece of text. Regexes are a great way to incorporate domain knowledge in your NLP system. For example, given a customer complaint that comes via chat or email, we want to build a system to automatically identify the product the complaint is about. There is a range of product codes that map to certain brand names. We can use regexes to match these easily.</p>

<p>Regexes are a very popular paradigm for building rule-based systems. NLP software like StanfordCoreNLP<a contenteditable="false" data-primary="Stanford Natural Language Processing Group" data-secondary="TokensRegex" data-type="indexterm" id="idm45969605291800"/> includes TokensRegex<a contenteditable="false" data-primary="TokensRegex (Stanford NLP)" data-type="indexterm" id="idm45969605290200"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605288968-marker" href="ch01.xhtml#idm45969605288968">10</a>], which is a framework for defining regular expressions. It is used to identify patterns in text and use matched text to create rules. Regexes are used for deterministic matches<a contenteditable="false" data-primary="deterministic matches" data-type="indexterm" id="idm45969605287304"/>—meaning it’s either a match or it’s not. Probabilistic regexes is a sub-branch that addresses this limitation by including a probability of a match. Interested readers can look at software libraries such as pregex<a contenteditable="false" data-primary="pregex" data-type="indexterm" id="idm45969605285864"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605284632-marker" href="ch01.xhtml#idm45969605284632">11</a>]. Last accessed June 15, 2020.</p>

<p><a contenteditable="false" data-primary="context-free grammar (CFG)" data-type="indexterm" id="idm45969605283016"/>Context-free grammar (<a contenteditable="false" data-primary="CFG (context-free grammar)" data-type="indexterm" id="idm45969605281368"/>CFG) is a type of formal grammar that is used to model natural languages. CFG was invented by Professor Noam <a contenteditable="false" data-primary="Chomsky, Noam" data-type="indexterm" id="idm45969605279960"/>Chomsky, a renowned linguist and scientist. CFGs can be used to capture more complex and hierarchical information that a regex might not. The Earley parser<a contenteditable="false" data-primary="Earley parser" data-type="indexterm" id="idm45969605278552"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605277320-marker" href="ch01.xhtml#idm45969605277320">12</a>] allows parsing of all kinds of CFGs. To model more complex rules, grammar languages like JAPE (Java Annotation Patterns Engine)<a contenteditable="false" data-primary="JAPE (Java Annotation Patterns Engine)" data-type="indexterm" id="idm45969605275960"/> can be used [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605274696-marker" href="ch01.xhtml#idm45969605274696">13</a>]. JAPE has features from both regexes as well as CFGs and can be used for rule-based NLP systems<a contenteditable="false" data-primary="rule-based systems" data-type="indexterm" id="idm45969605272888"/> like GATE (General Architecture for Text Engineering)<a contenteditable="false" data-primary="GATE (General Architecture for Text Engineering)" data-type="indexterm" id="idm45969605271656"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605270328-marker" href="ch01.xhtml#idm45969605270328">14</a>]. GATE is used for building text extraction for closed and well-defined domains where accuracy and completeness of coverage is more important. As an example, JAPE and GATE were used to extract information on pacemaker implantation procedures from clinical reports [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969605268664-marker" href="ch01.xhtml#idm45969605268664">15</a>]. <a data-type="xref" href="#gate_tool">Figure 1-10</a> shows the GATE interface along with several types of information highlighted in the text as an example of a rule-based system.</p>



<p>Rules and heuristics play a role across the entire life cycle of NLP projects even now. At one end, they’re a great way to build first versions of NLP systems. Put simply, <a contenteditable="false" data-primary="rules" data-type="indexterm" id="idm45969605265736"/>rules and heuristics help you quickly build the first version of the model and get a better understanding of the problem at hand. We’ll discuss this point in depth in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch11.xhtml#the_end_to_end_nlp_process">11</a>. Rules and heuristics can also be useful as features for machine learning–based NLP systems. At the other end of the spectrum of the project life cycle, rules and heuristics are used to plug the gaps in the system. Any NLP system built using statistical, machine learning, or deep learning techniques will make mistakes. Some mistakes can be too expensive—for example, a healthcare system that looks into all the medical records of a patient and wrongly decides to not advise a critical test. This mistake could even cost a life. Rules and <a contenteditable="false" data-primary="heuristics" data-startref="ch01_term15" data-type="indexterm" id="idm45969605261288"/>heuristics are a great way to plug such gaps in production systems. Now let’s turn our attention to machine learning techniques used for <a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="heuristics-based" data-startref="ch01_term14" data-type="indexterm" id="idm45969605259816"/>NLP.</p>

<figure><div id="gate_tool" class="figure"><img alt="GATE tool" src="Images/pnlp_0110.png" width="775" height="541"/>
<h6><span class="label">Figure 1-10. </span>GATE tool</h6>
</div></figure>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Machine Learning for NLP"><div class="sect2" id="machine_learning_for_nlp">
<h2>Machine Learning for NLP</h2>

<p><a contenteditable="false" data-primary="machine learning (ML)" data-secondary="for NLP" data-secondary-sortas="NLP" data-type="indexterm" id="ch01_term16"/>Machine learning techniques are applied to textual data just as they’re used on other forms of data, such as images, speech, and structured data. <a contenteditable="false" data-primary="supervised machine learning techniques" data-type="indexterm" id="idm45969611709848"/>Supervised machine learning techniques such as classification and regression methods are heavily used for various NLP tasks. As an example, an NLP classification task<a contenteditable="false" data-primary="classification tasks" data-type="indexterm" id="idm45969611708424"/> would be to classify news articles into a set of news topics like sports or politics. On the other hand, regression techniques<a contenteditable="false" data-primary="regression techniques" data-type="indexterm" id="idm45969611707048"/>, which give a numeric prediction, can be used to estimate the price of a stock based on processing the social media discussion about that stock. Similarly, unsupervised clustering algorithms can be used to club together text documents.</p>

<p>Any machine learning approach for NLP, supervised or unsupervised, can be described as consisting of three common steps: extracting features from text, using the feature representation to learn a model, and evaluating and improving the model. We’ll learn more about feature representations for text specifically in <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a> and evaluation in <a data-type="xref" href="ch02.xhtml#nlp_pipeline">Chapter 2</a>. We’ll now briefly outline some of the commonly used supervised ML methods in NLP for the second step (using the feature representation to learn a model). Having a basic idea of these methods will help you understand the concepts discussed in later chapters.</p>

<section data-type="sect3" data-pdf-bookmark="Naive Bayes"><div class="sect3" id="naive_bayes">
<h3>Naive Bayes</h3>

<p>Naive Bayes is<a contenteditable="false" data-primary="Naive Bayes" data-type="indexterm" id="idm45969611700856"/> a classic algorithm for classification tasks [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611699496-marker" href="ch01.xhtml#idm45969611699496">16</a>] that mainly relies on Bayes’ theorem<a contenteditable="false" data-primary="Bayes’ theorem" data-type="indexterm" id="idm45969611698152"/> (as is evident from the name). Using Bayes’ theorem, it calculates the probability of observing a class label given the set of features for the input data. A characteristic of this algorithm is that it assumes each feature is independent of all other features. For the news classification example mentioned earlier in this chapter, one way to represent the text numerically is by using the count of domain-specific words, such as sport-specific or politics-specific words, present in the text. We assume that these word counts are not correlated to one another. If the assumption holds, we can use Naive Bayes to classify news articles. While this is a strong assumption to make in many cases, Naive Bayes is commonly used as a starting algorithm for text classification. This is primarily because it is simple to understand and very fast to train and run.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Support vector machine"><div class="sect3" id="support_vector_machine-id00041">
<h3>Support vector machine</h3>

<p><a contenteditable="false" data-primary="support vector machines (SVMs)" data-type="indexterm" id="idm45969611694248"/>The support vector machine (<a contenteditable="false" data-primary="SVMs (support vector machines)" data-type="indexterm" id="idm45969611693000"/>SVM) is another popular classification [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611691640-marker" href="ch01.xhtml#idm45969611691640">17</a>] algorithm. The goal in any classification approach is to learn a decision boundary that acts as a separation between different categories of text (e.g., politics versus sports in our news classification example). This decision boundary can be linear or nonlinear (e.g., a circle). An SVM can learn both a linear and nonlinear decision boundary to separate data points belonging to different classes. A linear decision boundary learns to represent the data in a way that the class differences become apparent. For two-dimensional feature representations, an illustrative example is given in <a data-type="xref" href="#a_two_dimensional_feature_representatio">Figure 1-11</a>, where the black and white points belong to different classes (e.g., sports and politics news groups). An SVM learns an optimal decision boundary so that the distance between points across classes is at its maximum. The biggest strength of SVMs are their robustness to variation and noise in the data. A major weakness is the time taken to train and the inability to scale when there are large amounts of training data.</p>

<figure><div id="a_two_dimensional_feature_representatio" class="figure"><img alt="A two-dimensional feature representation of an SVM" src="Images/pnlp_0111.png" width="1289" height="1286"/>
<h6><span class="label">Figure 1-11. </span>A two-dimensional feature representation of an <a contenteditable="false" data-primary="SVMs (support vector machines)" data-type="indexterm" id="idm45969611686360"/><a contenteditable="false" data-primary="support vector machines (SVMs)" data-type="indexterm" id="idm45969611685144"/>SVM</h6>
</div></figure>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Hidden Markov Model"><div class="sect3" id="hidden_markov_model">
<h3>Hidden Markov Model</h3>
<p>The hidden Markov model (HMM)<a contenteditable="false" data-primary="HMM (Hidden Markov Model)" data-type="indexterm" id="ch01_term18"/> is a statistica<a contenteditable="false" data-primary="Hidden Markov Model (HMM)" data-type="indexterm" id="ch01_term17"/>l model [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611678408-marker" href="ch01.xhtml#idm45969611678408">18</a>] that assumes there is an underlying, unobservable process with hidden states that generates the data—i.e., we can only observe the data once it is generated. An HMM then tries to model the hidden states from this data. For example, consider the NLP task of <a contenteditable="false" data-primary="part-of-speech (POS) tagging" data-type="indexterm" id="idm45969611676808"/>part-of-speech (POS<a contenteditable="false" data-primary="POS (part-of-speech) tagging" data-type="indexterm" id="idm45969611675576"/>) tagging, which deals with assigning part-of-speech tags to sentences. HMMs are used for POS tagging of text data. Here, we assume that the text is generated according to an underlying grammar, which is hidden underneath the text. The hidden states are parts of speech that inherently define the structure of the sentence following the language grammar, but we only observe the words that are governed by these latent states. Along with this, HMMs also make the Markov assumption, which means that each hidden state is dependent on the previous state(s). Human language is sequential in nature, and the current word in a sentence depends on what occurred before it. Hence, HMMs with these two assumptions are a powerful tool for modeling textual data. In <a data-type="xref" href="#a_graphical_representation_of_a_hidden">Figure 1-12</a>, we can see an example of an HMM that learns parts of speech from a given sentence. Parts of speech like JJ (adjective) and NN (noun) are hidden states, while the sentence “natural language processing ( nlp )…” is directly observed.</p>

<figure><div id="a_graphical_representation_of_a_hidden" class="figure"><img alt="A graphical representation of a Hidden Markov Model" src="Images/pnlp_0112.png" width="1387" height="297"/>
<h6><span class="label">Figure 1-12. </span>A graphical representation of a hidden Markov model</h6>
</div></figure>

<p>For a detailed discussion on <a contenteditable="false" data-primary="Hidden Markov Model (HMM)" data-startref="ch01_term17" data-type="indexterm" id="idm45969611669896"/>HMMs<a contenteditable="false" data-primary="HMM (Hidden Markov Model)" data-startref="ch01_term18" data-type="indexterm" id="idm45969611668376"/> for NLP, refer to <a data-type="xref" href="ch08.xhtml#social_media">Chapter 8</a> in the book <em>Speech and Language Processing</em> by Professor Jurafsky [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611665336-marker" href="ch01.xhtml#idm45969611665336">19</a>].</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Conditional random fields"><div class="sect3" id="conditional_random_fields">
<h3>Conditional random fields</h3>

<p><a contenteditable="false" data-primary="conditional random fields (CRFs)" data-type="indexterm" id="idm45969611662024"/>The conditional random field (<a contenteditable="false" data-primary="CRFs (conditional random fields)" data-type="indexterm" id="idm45969611660552"/>CRF) is another algorithm that is used for sequential data. Conceptually, a CRF essentially performs a classification task on each element in the sequence [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611659080-marker" href="ch01.xhtml#idm45969611659080">20</a>]. Imagine the same example of POS tagging, where a CRF can tag word by word by classifying them to one of the parts of speech from the pool of all POS tags. Since it takes the sequential input and the context of tags into consideration, it becomes more expressive than the usual classification methods and generally performs better. CRFs outperform HMMs for tasks such as POS tagging, which rely on the sequential nature of language. We discuss CRFs and their variants along with applications in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch05.xhtml#information_extraction">5</a>, <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch06.xhtml#chatbots">6</a>, and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch09.xhtml#e_commerce_and_retail">9</a>.</p>

<p>These are some of the popular ML algorithms that are used heavily across NLP tasks. Having some understanding of these ML methods helps to understand various solutions discussed in the book. Apart from that, it is also important to understand when to use which algorithm, which we’ll discuss in the upcoming chapters. To learn more about other steps and further theoretical details of the machine learning process, we recommend the textbook <em>Pattern Recognition and Machine Learning</em> by Christopher Bishop [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611652184-marker" href="ch01.xhtml#idm45969611652184">21</a>]. For a more applied machine learning perspective, Aurélien Géron’s book [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611650952-marker" href="ch01.xhtml#idm45969611650952">22</a>] is a great resource to start with. Let’s now take a look at deep learning approaches to NLP<a contenteditable="false" data-primary="machine learning (ML)" data-secondary="for NLP" data-secondary-sortas="NLP" data-startref="ch01_term16" data-type="indexterm" id="idm45969611649560"/>.</p>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Deep Learning for NLP"><div class="sect2" id="deep_learning_for_nlp">
<h2>Deep Learning for NLP</h2>

<p>We briefly touched on a couple of popular machine learning methods that are used heavily in various NLP tasks. In the last few years, we have seen a huge surge in using neural networks to deal with complex, unstructured data. Language is inherently complex and unstructured. Therefore, we need models with better representation and learning capability to understand and solve language tasks. Here are a few popular <a contenteditable="false" data-primary="deep learning (DL)" data-secondary="for NLP" data-secondary-sortas="NLP" data-type="indexterm" id="ch01_term19"/>deep neural network architectures that have become the status quo in NLP.</p>

<section data-type="sect3" data-pdf-bookmark="Recurrent neural networks"><div class="sect3" id="recurrent_neural_networks">
<h3>Recurrent neural networks</h3>

<p>As we mentioned earlier, language<a contenteditable="false" data-primary="recurrent neural networks (RNNs)" data-type="indexterm" id="idm45969611641080"/> is<a contenteditable="false" data-primary="RNNs (recurrent neural networks)" data-type="indexterm" id="idm45969611639784"/> inherently sequential. A sentence in any language flows from one direction to another (e.g., <a contenteditable="false" data-primary="English" data-type="indexterm" id="idm45969611638392"/>English reads from left to right). Thus, a model that can progressively read an input text from one end to another can be very useful for language understanding. Recurrent neural networks (RNNs) are specially designed to keep such sequential processing and learning in mind. RNNs have neural units that are capable of remembering what they have processed so far. This memory is temporal, and the information is stored and updated with every time step as the RNN reads the next word in the input. <a data-type="xref" href="#an_unrolled_recurrent_neural_network_le">Figure 1-13</a> shows an unrolled RNN and how it keeps track of the input at different time steps.</p>

<figure><div id="an_unrolled_recurrent_neural_network_le" class="figure"><img alt="An unrolled recurrent neural network [_10]" src="Images/pnlp_0113.png" width="1132" height="369"/>
<h6><span class="label">Figure 1-13. </span>An unrolled recurrent neural network [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_1_10-marker" href="ch01.xhtml#footnote_1_10">23</a>]</h6>
</div></figure>

<p>RNNs are powerful and work very well for solving a variety of NLP tasks, such as text classification, named entity recognition, machine translation, etc. One can also use RNNs to generate text where the goal is to read the preceding text and predict the next word or the next character. Refer to “The Unreasonable Effectiveness of Recurrent Neural Networks” [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611631048-marker" href="ch01.xhtml#idm45969611631048">24</a>] for a detailed discussion on the versatility of RNNs and the range of applications within and outside NLP for which they are useful.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Long short-term memory"><div class="sect3" id="long_short_term_memory">
<h3>Long short-term memory</h3>

<p>Despite their capability<a contenteditable="false" data-primary="short-term memory, long" data-type="indexterm" id="idm45969611627720"/> and versatility, RNNs suffer from the problem of forgetful memory—they cannot remember longer contexts and therefore do not perform well when the input text is long, which is typically the case with text inputs. <a contenteditable="false" data-primary="long short-term memory networks (LSTMs)" data-type="indexterm" id="idm45969611625880"/>Long short-term memory networks (<a contenteditable="false" data-primary="LSTMs (long short-term memory networks)" data-type="indexterm" id="idm45969611624632"/>LSTMs), a type of RNN, were invented to mitigate this shortcoming of the RNNs. LSTMs circumvent this problem by letting go of the irrelevant context and only remembering the part of the context that is needed to solve the task at hand. This relieves the load of remembering very long context in one vector representation. LSTMs have replaced RNNs in most applications because of this workaround. Gated recurrent units (<a contenteditable="false" data-primary="GRUs (gated recurrent units)" data-type="indexterm" id="idm45969611622904"/>GRUs)<a contenteditable="false" data-primary="gated recurrent units (GRUs)" data-type="indexterm" id="idm45969611621656"/> are another variant of RNNs that are used mostly in language generation. (The article written by Christopher <a contenteditable="false" data-primary="Olah, Christopher" data-type="indexterm" id="idm45969611620248"/>Olah [<a data-type="noteref" href="ch01.xhtml#footnote_1_10">23</a>] covers the family of RNN models in great detail.) <a data-type="xref" href="#architecture_of_an_lstm_cell_left_squar">Figure 1-14</a> illustrates the architecture of a single LSTM cell. We’ll discuss specific uses of LSTMs in various NLP applications in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a>, <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch05.xhtml#information_extraction">5</a>, <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch06.xhtml#chatbots">6</a>, and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch09.xhtml#e_commerce_and_retail">9</a>.</p>

<figure><div id="architecture_of_an_lstm_cell_left_squar" class="figure"><img alt="Architecture of an LSTM cell [_10]" src="Images/pnlp_0114.png" width="1388" height="548"/>
<h6><span class="label">Figure 1-14. </span>Architecture of an LSTM cell [<a data-type="noteref" href="ch01.xhtml#footnote_1_10">23</a>]</h6>
</div></figure>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Convolutional neural networks"><div class="sect3" id="convolutional_neural_networks">
<h3>Convolutional neural networks</h3>

<p>Convolutional neural networks (CNNs<a contenteditable="false" data-primary="CNNs (convolutional neural networks)" data-type="indexterm" id="ch01_term21"/>) are very popular and used heavily in computer vision tasks like image classification, video recognition, etc. CNNs have also seen success in NLP, especially in text-classification tasks. One can replace each word in a sentence with its corresponding word vector, and all vectors are of the same size (<em>d</em>) (refer to “Word Embeddings” in <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a>). Thus, they can be stacked one over another to form a matrix or 2D array of dimension <em>n</em> ✕ <em>d</em>, where <em>n</em> is the number of words in the sentence and <em>d</em> is the size of the word vectors. This matrix can now be treated similar to an image and can be modeled by a CNN. The main advantage CNNs have is their ability to look at a group of words together using a context window. For example, we are doing sentiment classification, and we get a sentence like, “I like this movie very much!” In order to make sense of this sentence, it is better to look at words and different sets of contiguous words. CNNs can do exactly this by definition of their architecture. We’ll touch on this in more detail in later chapters. <a data-type="xref" href="#cnn_model_in_action_left_square_bracket">Figure 1-15</a> shows a CNN in action on a piece of text to extract useful phrases to ultimately arrive at a binary number indicating the sentiment of the sentence from a given piece of text.</p>



<p>As shown in the figure, CNN uses a collection of convolution and pooling layers to achieve this condensed representation of the text, which is then fed as input to a fully connected layer to learn some NLP tasks like text classification. More details on the usage CNNs for NLP can be found in [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_1_27-marker" href="ch01.xhtml#footnote_1_27">25</a>] and [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611598344-marker" href="ch01.xhtml#idm45969611598344">26</a>]. We also cover them in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>.</p>

<figure><div id="cnn_model_in_action_left_square_bracket" class="figure"><img alt="CNN model in action [_11]" src="Images/pnlp_0115.png" width="1410" height="1460"/>
<h6><span class="label">Figure 1-15. </span>CNN model in action [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611594136-marker" href="ch01.xhtml#idm45969611594136">27</a>]</h6>
</div></figure>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Transformers"><div class="sect3" id="transformers">
<h3>Transformers</h3>

<p>Transformers [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611590664-marker" href="ch01.xhtml#idm45969611590664">28</a>] are the latest<a contenteditable="false" data-primary="transformers" data-type="indexterm" id="ch01_term22"/> entry in the league of deep learning models for NLP. Transformer models have achieved state of the art in almost all major NLP tasks in the past two years. They model the textual context but not in a sequential manner. Given a word in the input, it prefers to look at all the words around it (known as <em>self-attention<a contenteditable="false" data-primary="self-attention" data-type="indexterm" id="idm45969611587240"/></em>) and represent each word with respect to its context. For example, the word “bank” can have different meanings depending on the context in which it appears. If the context talks about finance, then “bank” probably denotes a financial institution. On the other hand, if the context mentions a river, then it probably indicates a bank of the river. Transformers can model such context and hence have been used heavily in NLP tasks due to this higher representation capacity as compared to other deep networks.</p>

<p>Recently, large transformers have been used for <em>transfer learning<a contenteditable="false" data-primary="transfer learning" data-type="indexterm" id="idm45969611584488"/></em> with smaller downstream tasks. Transfer learning is a technique in AI where the knowledge gained while solving one problem is applied to a different but related problem. With transformers, the idea is to train a very large transformer mode in an unsupervised manner (known as <em>pre-trainin<a contenteditable="false" data-primary="pre-training" data-type="indexterm" id="idm45969611582680"/>g</em>) to predict a part of a sentence given the rest of the content so that it can encode the high-level nuances of the language in it. These models are trained on more than 40 GB of textual data, scraped from the whole internet. An example of a large transformer is BERT (Bidirectional Encoder Representations from Transformers)<a contenteditable="false" data-primary="BERT (Bidirectional Encoder Representations from Transformers)" data-type="indexterm" id="idm45969611580952"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611579672-marker" href="ch01.xhtml#idm45969611579672">29</a>], shown in <a data-type="xref" href="#bert_architecturedotleft_parenthesisari">Figure 1-16</a>, which is pre-trained on massive data and open sourced by Google.</p>

<figure><div id="bert_architecturedotleft_parenthesisari" class="figure"><img alt="BERT architecture. (a) Pre-trained model (b) fine-tuned, task-specific models" src="Images/pnlp_0116.png" width="1428" height="597"/>
<h6><span class="label">Figure 1-16. </span>BERT architecture: pre-trained model and fine-tuned, task-specific <span class="keep-togetther">models</span></h6>
</div></figure>

<p>The pre-trained model is shown on the left side of <a data-type="xref" href="#bert_architecturedotleft_parenthesisari">Figure 1-16</a>. This model is then fine-tuned on downstream NLP tasks, such as text classification, entity extraction, question answering, etc., as shown on the right of <a data-type="xref" href="#bert_architecturedotleft_parenthesisari">Figure 1-16</a>. Due to the sheer amount of pre-trained knowledge, BERT works efficiently in transferring the knowledge for downstream tasks and achieves state of the art for many of these tasks. Throughout the book, we have covered various examples of using BERT for various tasks. <a data-type="xref" href="#self_attention_mechanism_in_a_transform">Figure 1-17</a> illustrates the workings of a self-attention mechanism, which is a key component of a transformer. Interested readers can look at [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_1_3-marker" href="ch01.xhtml#footnote_1_3">30</a>] for more details on self-attention mechanisms and transformer architecture<a contenteditable="false" data-primary="transformers" data-startref="ch01_term22" data-type="indexterm" id="idm45969611568664"/>. We cover BERT and its applications in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a>, <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch06.xhtml#chatbots">6</a>, and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch10.xhtml#healthcarecomma_financecomma_and_law">10</a>.</p>

<figure><div id="self_attention_mechanism_in_a_transform" class="figure"><img alt="Self-attention mechanism in a transformer [_3]" src="Images/pnlp_0117.png" width="1166" height="1156"/>
<h6><span class="label">Figure 1-17. </span><a contenteditable="false" data-primary="self-attention" data-type="indexterm" id="idm45969611561816"/>Self-attention mechanism in a transformer<a contenteditable="false" data-primary="transformers" data-type="indexterm" id="idm45969611560488"/> [<a data-type="noteref" href="ch01.xhtml#footnote_1_3">30</a>]</h6>
</div></figure>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Autoencoders"><div class="sect3" id="autoencoders">
<h3>Autoencoders</h3>

<p>An autoencoder<a contenteditable="false" data-primary="autoencoders" data-type="indexterm" id="ch01_term23"/> is a different kind of network that is used mainly for learning compressed vector representation of the input. For example, if we want to represent a text by a vector, what is a good way to do it? We can learn a mapping function from input text to the vector. To make this mapping function useful, we “reconstruct” the input back from the vector representation. This is a form of unsupervised learning since you don’t need human-annotated labels for it. After the training, we collect the vector representation, which serves as an encoding of the input text as a dense vector. Autoencoders are typically used to create feature representations needed for any downstream tasks. <a data-type="xref" href="#architecture_of_an_autoencoder">Figure 1-18</a> depicts the architecture of an autoencoder.</p>

<figure><div id="architecture_of_an_autoencoder" class="figure"><img alt="Architecture of an autoencoder" src="Images/pnlp_0118.png" width="1356" height="671"/>
<h6><span class="label">Figure 1-18. </span>Architecture of an autoencoder</h6>
</div></figure>

<p>In this scheme, the hidden layer gives a compressed representation of input data, capturing the essence, and the output layer (decoder) reconstructs the input representation from the compressed representation. While the architecture of the autoencoder shown in <a data-type="xref" href="#architecture_of_an_autoencoder">Figure 1-18</a> cannot handle specific properties of sequential data like text, variations of autoencoders, such as LSTM autoencoders, address these well. More information about autoencoders can be found in [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_1_29-marker" href="ch01.xhtml#footnote_1_29">31</a>].</p>

<p>We briefly introduced some of the popular DL architectures for NLP here. For a more detailed study of deep learning architectures in general, refer to [<a data-type="noteref" href="ch01.xhtml#footnote_1_29">31</a>], and specifically for NLP, refer to [<a data-type="noteref" href="ch01.xhtml#footnote_1_27">25</a>]. We hope this introduction gives you enough background to understand the use of DL in the rest of this book.</p>

<p>Going by all the recent achievements of DL models, one might think that DL should be the go-to way to build NLP systems. However, that is far from the truth for most industry use cases. Let’s look at why this is the <a contenteditable="false" data-primary="deep learning (DL)" data-secondary="for NLP" data-secondary-sortas="NLP" data-startref="ch01_term19" data-type="indexterm" id="idm45969611544856"/>case<a contenteditable="false" data-primary="autoencoders" data-startref="ch01_term23" data-type="indexterm" id="idm45969611542808"/>.</p>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Why Deep Learning Is Not Yet the Silver Bullet for NLP"><div class="sect2" id="why_deep_learning_is_not_yet_the_silver">
<h2>Why Deep Learning Is Not Yet the Silver Bullet for NLP</h2>

<p>Over the last few years, DL<a contenteditable="false" data-primary="deep learning (DL)" data-secondary="limitations" data-type="indexterm" id="ch01_term24"/> has made amazing advances in NLP. For example, in text classification, LSTM- and CNN-based models have surpassed the performance of standard machine learning techniques such as Naive Bayes and SVM for many classification tasks. Similarly, LSTMs have performed better in sequence-labeling tasks like entity extraction as compared to CRF models. Recently, powerful transformer models have become state of the art in most of these NLP tasks, ranging from classification to sequence labeling. A huge trend right now is to leverage large (in terms of number of parameters) transformer models, train them on huge datasets for generic NLP tasks like language models, then adapt them to smaller downstream tasks. This approach (known as <em>transfer learning</em>) has also been successful in other domains, such as computer vision and speech.</p>

<p>Despite such tremendous success, DL is still not the silver bullet for all NLP tasks when it comes to industrial applications. Some of the key reasons for this are as <span class="keep-together">follows:</span></p>

<dl>
	<dt>Overfitting on small datasets<a contenteditable="false" data-primary="small datasets" data-type="indexterm" id="idm45969611534152"/></dt>
	<dd>DL models tend to have more parameters than traditional ML models, which means they possess more expressivity. This also comes with a curse. Occam’s razor<a contenteditable="false" data-primary="Occam’s razor" data-type="indexterm" id="idm45969611532424"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611531192-marker" href="ch01.xhtml#idm45969611531192">32</a>] suggests that a simpler solution is always preferable given that all other conditions are equal. Many times, in the development phase, sufficient training data is not available to train a complex network. In such cases, a simpler model should be preferred over a DL model. DL models overfit on small datasets and subsequently lead to poor generalization capability, which in turn leads to poor performance in production.</dd>
	<dt>Few-shot learning and synthetic data generation<a contenteditable="false" data-primary="synthetic data generation" data-type="indexterm" id="idm45969611528648"/></dt>
	<dd>In disciplines like computer vision, DL has made significant strides in <a contenteditable="false" data-primary="few-shot learning" data-type="indexterm" id="idm45969611527096"/>few-shot learning (i.e., learning from very few training examples) [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611525864-marker" href="ch01.xhtml#idm45969611525864">33</a>] and in models that can generate superior-quality images [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611524152-marker" href="ch01.xhtml#idm45969611524152">34</a>]. Both of these advances have made training DL-based vision models on small amounts of data feasible. Therefore, DL has achieved much wider adoption for solving problems in industrial settings. We have not yet seen similar DL techniques be successfully developed for NLP.</dd>
	<dt>Domain adaptation</dt>
	<dd>If we utilize a large DL model that is trained on datasets originating from some common domains (e.g., news articles) and apply the trained model to a newer domain that is different from the common domains (e.g., social media posts), it may yield poor performance. This loss in generalization performance indicates that DL models are not always useful. For example, models trained on internet texts and product reviews will not work well when applied to domains such as law, social media, or healthcare, where both the syntactic and semantic structure of the language is specific to the domain. We need specialized models to encode the domain knowledge, which could be as simple as domain-specific, rule-based models.</dd>
	<dt>Interpretable models</dt>
	<dd>Apart from efficient domain adaptation, controllability and interpretability is hard for DL models because, most of the time, they work like a black box. Businesses often demand more interpretable results that can be explained to the customer or end user. In those cases, traditional techniques might be more useful. For example, a Naive Bayes model for sentiment classification may explain the effect of strong positive and negative words on the final prediction of sentiment. As of today, obtaining such insights from an LSTM-based classification model is difficult. This is in contrast to computer vision, where DL models are not black boxes. There are plenty of techniques [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611519256-marker" href="ch01.xhtml#idm45969611519256">35</a>] in computer vision that are used to gain insight into why a model is making a particular prediction. Such approaches for NLP are not as common.</dd>
	<dt>Common sense and world knowledge</dt>
	<dd>Even though we have achieved good performance on benchmark NLP tasks using ML and DL models, language remains a bigger enigma to scientists. Beyond syntax and semantics, language encompasses knowledge of the world around us. Language for communication relies on logical reasoning and common sense regarding events from the world. For example, “I like pizza” implies “I feel happy when I eat pizza.” A more complex reasoning example would be, “If John walks out of the bedroom and goes to the garden, then John is not in the bedroom anymore, and his current location is the garden.” This might seem trivial to us humans, but it requires multistep reasoning for a machine to identify events and understand their consequences. Since this world knowledge<a contenteditable="false" data-primary="world knowledge" data-type="indexterm" id="idm45969611516104"/> and common sense<a contenteditable="false" data-primary="common sense" data-type="indexterm" id="idm45969611514872"/> are inherent in language, understanding them is crucial for any DL model to perform well on various language tasks. Current DL models may perform well on standard benchmarks but are still not capable of common sense understanding and logical reasoning. There are some efforts to collect common sense events and logical rules (such as if-them reasoning), but they are not well integrated yet with ML or DL models.</dd>
	<dt>Cost</dt>
	<dd>Building DL-based solutions for NLP tasks can be pretty expensive. The cost<a contenteditable="false" data-primary="costs" data-type="indexterm" id="idm45969611512312"/>, in terms of both money and time, stems from multiple sources. DL models are known to be data guzzlers. Collecting a large dataset and getting it labeled can be very expensive. Owing to the size of DL models, training them to achieve desired performance can not only increase your development cycles but also result in a heavy bill for the specialized hardware (GPUs). Further, deploying and maintaining DL models can be expensive in terms of both hardware requirements and effort. Last but not least, because they’re bulky, these models may cause latency issues during inference time and may not be useful in cases where low latency is a must. To this list, one can also add technical debt arising from building and maintaining a heavy model. Loosely speaking, technical debt is the cost of rework that arises from prioritizing speedy delivery over good design and implementation choices.</dd>
	<dt>On-device deployment<a contenteditable="false" data-primary="device deployment" data-type="indexterm" id="idm45969611509752"/><a contenteditable="false" data-type="indexterm" data-primary="deployment" data-secondary="device" id="idm45969611508616"/></dt>
	<dd>For many use cases, the NLP solution needs to be deployed on an embedded device rather than in the cloud—for example, a machine-translation system that helps tourists speak the translated text even without the internet. In such cases, owing to limitations of the device, the solution must work with limited memory and power. Most DL solutions do not fit such constraints. There are some efforts in this direction [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611506392-marker" href="ch01.xhtml#idm45969611506392">36</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611504968-marker" href="ch01.xhtml#idm45969611504968">37</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611503496-marker" href="ch01.xhtml#idm45969611503496">38</a>] where one can deploy DL models on edge devices, but we’re still quite far from generic solutions.</dd>
</dl>

<p>In most industry projects, one or more of the points mentioned above plays out. This leads to longer project cycles and higher costs (hardware, manpower), and yet the performance is either comparable or sometimes even lower than ML models. This results in a poor return on investment and often causes the NLP project to fail.</p>

<p>Based on this discussion, it may be apparent that DL is not always the go-to solution for all industrial NLP applications. So, this book starts with fundamental aspects of various NLP tasks and how we can solve them using techniques ranging from rule-based systems to DL models. We emphasize the data requirements and model-building pipeline, not just the technical details of individual models. Given the rapid advances in this area, we anticipate that newer DL models will come in the future to advance the state of the art but that the fundamentals of NLP tasks will not change substantially. This is why we’ll discuss the basics of NLP and build on them to develop models of increasing complexity wherever possible, rather than directly jumping to the cutting edge.</p>

<p>Echoing Professor Zachary <a contenteditable="false" data-primary="Lipton, Zachary" data-type="indexterm" id="idm45969611499640"/>Lipton from Carnegie Mellon University and Professor Jacob <a contenteditable="false" data-primary="Steinhardt, Jacob" data-type="indexterm" id="idm45969611498408"/>Steinhardt from UC Berkeley [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611497128-marker" href="ch01.xhtml#idm45969611497128">39</a>], we also want to provide a word of caution about consuming a lot of scientific articles, research papers, and blogs on ML and NLP without context and proper training. Following a large volume of cutting-edge work may cause confusion and not-so-precise understanding. Many recent DL models are not interpretable enough to indicate the sources of empirical gains. Lipton and Steinhardt also recognize the possible conflation of technical terms and misuse of language in ML-related scientific articles, which often fail to provide any clear path to solving the problem at hand. Therefore, in this book, we carefully describe various technical concepts in the application of ML in NLP tasks via examples, code, and tips throughout the chapters.</p>

<p>So far, we’ve covered some foundational concepts related to language, NLP, ML, and DL. Before we wrap up <a data-type="xref" href="#nlp_a_primer">Chapter 1</a>, let’s look at a case study to help get a better understanding of the various components of an NLP <a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="approaches to" data-startref="ch01_term13" data-type="indexterm" id="idm45969611493192"/><a contenteditable="false" data-primary="deep learning (DL)" data-secondary="limitations" data-startref="ch01_term24" data-type="indexterm" id="idm45969611491480"/>application.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="An NLP Walkthrough: Conversational Agents"><div class="sect1" id="an_nlp_walkthrough_conversational_agent">
<h1>An NLP Walkthrough: Conversational Agents</h1>

<p><a contenteditable="false" data-primary="voice-based assistants" data-secondary="case study" data-type="indexterm" id="ch01_term28"/>Voice-based conversational agents<a contenteditable="false" data-primary="conversational agents" data-secondary="case study" data-type="indexterm" id="ch01_term25"/><a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="case studies" data-type="indexterm" id="ch01_term26"/> like Amazon Alexa<a contenteditable="false" data-primary="Amazon Alexa" data-type="indexterm" id="idm45969611482504"/> and <a contenteditable="false" data-primary="Apple Siri" data-type="indexterm" id="idm45969611481240"/>Apple Siri are some of the most ubiquitous applications of NLP, and they’re the ones most people are already familiar with. <a data-type="xref" href="#flow_of_conversation_agents">Figure 1-19</a> shows the typical interaction model of a conversational agent.</p>

<figure><div id="flow_of_conversation_agents" class="figure"><img alt="Flow of conversation agents" src="Images/pnlp_0119.png" width="1349" height="519"/>
<h6><span class="label">Figure 1-19. </span>Flow of <a contenteditable="false" data-primary="conversational agents" data-secondary="typical flow" data-type="indexterm" id="idm45969611477224"/>conversation agents</h6>
</div></figure>

<p>Here, we’ll walk through all the major NLP components used in this flow:</p>

<ol>
	<li><p><em>Speech recognition and synthesis</em>: These are the main components of any voice-based conversational agent. <a contenteditable="false" data-primary="speech recognition" data-type="indexterm" id="idm45969611473736"/>Speech recognition involves converting speech signals to their phonemes, which are then transcribed as words. Speech synthesis<a contenteditable="false" data-primary="speech synthesis" data-type="indexterm" id="idm45969611472296"/> achieves the reverse process by transforming textual results into spoken language to the user. Both of these techniques have advanced considerably in the last decade, and we recommend using cloud APIs for most standard cases.</p></li>
	<li><p><a contenteditable="false" data-primary="natural language understanding (NLU)" data-secondary="case study" data-type="indexterm" id="idm45969611470408"/><em>Natural language understanding</em>: This is the next component in the conversational agent pipeline, where the user response received (transcribed as text) is analyzed using a natural language understanding system. This can be broken into many small NLP subtasks, such as:</p>
	<ul>
		<li><p><em><a contenteditable="false" data-primary="sentiment analysis" data-type="indexterm" id="idm45969611467208"/>Sentiment analysis</em>: Here, we analyze the sentiment of the user response. This will be covered in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>.</p></li>
		<li><p><em>Named entity recognition<a contenteditable="false" data-primary="named entity recognition (NER)" data-type="indexterm" id="idm45969611464008"/></em>: Here, we identify all the important entities the user mentioned in their response. This will be covered in <a data-type="xref" href="ch05.xhtml#information_extraction">Chapter 5</a>.</p></li>
		<li><p><em>Coreference resolution<a contenteditable="false" data-primary="coreference resolution" data-type="indexterm" id="idm45969611460824"/></em>: Here, we find out the references of the extracted entities from the conversation history. For example, a user may say “<em>Avengers Endgame</em> was awesome” and later refer back to the movie, saying “The movie’s special effects were great.” In this case, we would want to link that “movie” is referring to <em>Avengers Endgame</em>. This is covered briefly in <a data-type="xref" href="ch05.xhtml#information_extraction">Chapter 5</a>.</p></li>
	</ul>
	</li>
	<li><p><em><a contenteditable="false" data-primary="dialog management" data-type="indexterm" id="idm45969611456600"/>Dialog management</em>: Once we’ve extracted the useful information from the user’s response, we may want to understand the user’s intent—i.e., if they’re asking a factual question like “What is the weather today?” or giving a command like “Play Mozart songs.” We can use a text-classification system to classify the user response as one of the pre-defined intents. This helps the conversational agent know what’s being asked. Intent classification will be covered in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch06.xhtml#chatbots">6</a>. During this process, the system may ask a few clarifying questions to elicit further information from the user. Once we’ve figured out the user’s intent, we want to figure out which suitable action the conversational agent should take to fulfill the user’s request. This is done based on the information and intent extracted from the user’s response. Examples of suitable actions could be generating an answer from the internet, playing music, dimming lights, or asking a clarifying question. We’ll cover this in <a data-type="xref" href="ch06.xhtml#chatbots">Chapter 6</a>.</p></li>
	<li><p><em><a contenteditable="false" data-primary="response generation" data-secondary="case study" data-type="indexterm" id="idm45969611450136"/>Response generation</em>: Finally, the conversational agent generates a suitable action to perform based on a semantic interpretation of the user’s intent and additional inputs from the dialogue with the user. As mentioned earlier, the agent can retrieve information from the knowledge base and generate responses using a pre-defined template. For example, it might respond by saying, “Now playing Symphony No. 25” or “The lights have been dimmed.” In certain scenarios, it can also generate a completely new response.</p>
	</li>
</ol>

<p>We hope this brief case study provided an overview of how different NLP components we’ll be discussing throughout this book will come together to build one application: a conversational agent. We’ll see more details about these components as we progress through the book, and we’ll discuss <a contenteditable="false" data-primary="voice-based assistants" data-secondary="case study" data-startref="ch01_term28" data-type="indexterm" id="idm45969611446984"/>conversational agents<a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="case study" data-startref="ch01_term26" data-type="indexterm" id="idm45969611445208"/><a contenteditable="false" data-primary="conversational agents" data-secondary="case study" data-startref="ch01_term25" data-type="indexterm" id="idm45969611443464"/> specifically in <a data-type="xref" href="ch06.xhtml#chatbots">Chapter 6</a>.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Wrapping Up"><div class="sect1" id="wrapping_up-id00061">
<h1>Wrapping Up</h1>

<p>From the broader contours of what a language is to a concrete case study of a real-world NLP application, we’ve covered a range of NLP topics in this chapter. We also discussed how NLP is applied in the real world, some of its challenges and different tasks, and the role of ML and DL in NLP. This chapter was meant to give you a baseline of knowledge that we’ll build on throughout the book. The next two chapters (Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch02.xhtml#nlp_pipeline">2</a> and 
<a data-type="xref" data-xrefstyle="select:labelnumber" href="ch03.xhtml#text_representation">3</a>) will introduce you to some of the foundational steps necessary for building NLP applications. Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a>–<a data-type="xref" data-xrefstyle="select:labelnumber" href="ch07.xhtml#topics_in_brief">7</a> focus on core NLP tasks along with industrial use cases that can be solved with them. In Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch08.xhtml#social_media">8</a>–<a data-type="xref" data-xrefstyle="select:labelnumber" href="ch10.xhtml#healthcarecomma_financecomma_and_law">10</a>, we discuss how NLP is used across different industry verticals such as e-commerce, healthcare, finance, etc. <a data-type="xref" href="ch11.xhtml#the_end_to_end_nlp_process">Chapter 11</a> brings everything together and discusses what it takes to build end-to-end NLP applications in terms of design, development, testing, and deployment. With this broad overview<a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="overview" data-startref="ch01_term1" data-type="indexterm" id="idm45969611429304"/> in place, let’s start delving deeper into the world of NLP.</p>
</div></section>
<div data-type="footnotes"><h5>Footnotes</h5></div><div data-type="footnotes"><h5>References</h5><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612950968">[<a href="ch01.xhtml#idm45969612950968-marker">1</a>] <a href="http://Arria.com">Arria.com</a>. <a href="https://oreil.ly/R8hSI">“NLG for Your Industry”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612827640">[<a href="ch01.xhtml#idm45969612827640-marker">2</a>] UCL. <a href="https://oreil.ly/5jnsl">Phonetic symbols for English</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605409208">[<a href="ch01.xhtml#idm45969605409208-marker">3</a>] Bender, Emily M. “Linguistic Fundamentals for Natural Language Processing: 100 Essentials From Morphology and Syntax.” <em>Synthesis Lectures on Human Language Technologies</em> 6.3 (2013): 1–184.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605407864">[<a href="ch01.xhtml#idm45969605407864-marker">4</a>] Bender, Emily M. and Alex Lascarides. “Linguistic Fundamentals for Natural Language Processing II: 100 Essentials from Semantics and Pragmatics.” <em>Synthesis Lectures on Human Language Technologies</em> 12.3 (2019): 1–268.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605384872">[<a href="ch01.xhtml#idm45969605384872-marker">5</a>] Levesque, Hector, Ernest Davis, and Leora Morgenstern. “The Winograd Schema Challenge.” <em>The Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning</em> (2012).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605353592">[<a href="ch01.xhtml#idm45969605353592-marker">6</a>] Wikipedia. <a href="https://oreil.ly/6NZGh">“Dartmouth workshop”</a>. Last modified March 30, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605305656">[<a href="ch01.xhtml#idm45969605305656-marker">7</a>] Miller, George A. “WordNet: A Lexical Database for English.” <em>Communications of the ACM</em> 38.11 (1995): 39–41.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605301160">[<a href="ch01.xhtml#idm45969605301160-marker">8</a>] Visual Thesaurus of English Collocations. <a href="https://oreil.ly/EY1HB">“Visual Wordnet with D3.js”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605297608">[<a href="ch01.xhtml#idm45969605297608-marker">9</a>] Singh, Push, Thomas Lin, Erik T. Mueller, Grace Lim, Travell Perkins, and Wan Li Zhu. “Open Mind Common Sense: Knowledge Acquisition from the General Public,” Meersman R. and Tari Z. (eds), <em>On the Move to Meaningful Internet Systems 2002: CoopIS, DOA, and ODBASE</em>. OTM 2002. <em>Lecture Notes in Computer Science</em>, vol. 2519. Berlin, Heidelberg: Springer.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605288968">[<a href="ch01.xhtml#idm45969605288968-marker">10</a>] The Stanford Natural Language Processing Group. <a href="https://oreil.ly/M3KnK">Stanford TokensRegex</a>, (software). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605284632">[<a href="ch01.xhtml#idm45969605284632-marker">11</a>] Hewitt, Luke. <a href="https://oreil.ly/BqhJX">Probabilistic regular expressions</a>, (GitHub repo).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605277320">[<a href="ch01.xhtml#idm45969605277320-marker">12</a>] Earley, Jay. “An Efficient Context-Free Parsing Algorithm.” <em>Communications of the ACM</em> 13.2 (1970): 94–102.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605274696">[<a href="ch01.xhtml#idm45969605274696-marker">13</a>] <a href="https://oreil.ly/dmdOs">“Java Annotation Patterns Engine: Regular Expressions over Annotations”</a>. <em>Developing Language Processing Components with GATE Version 9 (a User Guide)</em>, Chapter 8. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605270328">[<a href="ch01.xhtml#idm45969605270328-marker">14</a>] <a href="https://gate.ac.uk">General Architecture for Text Engineering (GATE)</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969605268664">[<a href="ch01.xhtml#idm45969605268664-marker">15</a>] Rosier, Arnaud, Anita Burgun, and Philippe Mabo. “Using Regular Expressions to Extract Information on Pacemaker Implantation Procedures from Clinical Reports.” <em>AMIA Annual Symposium Proceedings</em> v.2008 (2008): 81–85.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611699496">[<a href="ch01.xhtml#idm45969611699496-marker">16</a>] Zhang, Haiyi and Di Li. “Naïve Bayes Text Classifier.” <em>2007 IEEE International Conference on Granular Computing</em> (GRC 2007): 708.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611691640">[<a href="ch01.xhtml#idm45969611691640-marker">17</a>] Joachims, Thorsten. <em>Learning to Classify Text Using Support Vector Machines</em><em>,</em> Vol. 668. New York: Springer Science &amp; Business Media, 2002. ISBN: 978-1-4615-0907-3</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611678408">[<a href="ch01.xhtml#idm45969611678408-marker">18</a>] Baum, Leonard E. and Ted Petrie. “Statistical Inference for Probabilistic Functions of Finite State Markov Chains.” <em>The Annals of Mathematical Statistics</em> 37.6 (1966): 1554–1563.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611665336">[<a href="ch01.xhtml#idm45969611665336-marker">19</a>] Jurafsky, Dan and James H. Martin. <a href="https://oreil.ly/sZfWl"><em>Speech and Language Processing</em>, Third Edition (Draft)</a>, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611659080">[<a href="ch01.xhtml#idm45969611659080-marker">20</a>] Settles, Burr. “Biomedical Named Entity Recognition Using Conditional Random Fields and Rich Feature Sets.” <em>Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications (NLPBA/BioNLP)</em> (2004): 107–110.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611652184">[<a href="ch01.xhtml#idm45969611652184-marker">21</a>] Bishop, Christopher M. <em>Pattern Recognition and Machine Learning</em>. New York: Springer, 2006. ISBN: 978-0-3873-1073-2</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611650952">[<a href="ch01.xhtml#idm45969611650952-marker">22</a>] Géron, Aurélien. <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</em>. Boston: O’Reilly, 2019. ISBN: 978-1-492-03264-9</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_1_10">[<a href="ch01.xhtml#footnote_1_10-marker">23</a>] Olah, Christopher. <a href="https://oreil.ly/X6dwG">“Understanding LSTM Networks”</a>. August 27, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611631048">[<a href="ch01.xhtml#idm45969611631048-marker">24</a>] Karpathy, Andrej. <a href="https://oreil.ly/qTAxV">“The Unreasonable Effectiveness of Recurrent Neural Networks”</a>. May 21, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_1_27">[<a href="ch01.xhtml#footnote_1_27-marker">25</a>] Goldberg, Yoav. “Neural Network Methods for Natural Language Processing.” <em>Synthesis Lectures on Human Language Technologies</em> 10.1 (2017): 1–309.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611598344">[<a href="ch01.xhtml#idm45969611598344-marker">26</a>] Britz, Denny. <a href="https://oreil.ly/vJppc">“Understanding Convolutional Neural Networks for NLP”</a>. November 7, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611594136">[<a href="ch01.xhtml#idm45969611594136-marker">27</a>] Le, Hoa T., Christophe Cerisara, and Alexandre Denis. “Do Convolutional Networks need to be Deep for Text Classification?” <em>Workshops at the Thirty-Second AAAI Conference on Artificial Intelligence</em>, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611590664">[<a href="ch01.xhtml#idm45969611590664-marker">28</a>] Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. “Attention Is All You Need.” <em>Advances in Neural Information Processing Systems</em>, 2017: 5998–6008.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611579672">[<a href="ch01.xhtml#idm45969611579672-marker">29</a>] Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. <a href="https://oreil.ly/xdtmX">“BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”</a>. October 11, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_1_3">[<a href="ch01.xhtml#footnote_1_3-marker">30</a>] Alammar, Jay. <a href="https://oreil.ly/Fl9n3">“The Illustrated Transformer”</a>. June 27, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_1_29">[<a href="ch01.xhtml#footnote_1_29-marker">31</a>] Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. <em>Deep Learning</em>. Cambridge: MIT Press, 2016. ISBN: 978-0-262-03561-3</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611531192">[<a href="ch01.xhtml#idm45969611531192-marker">32</a>] Varma, Nakul. <a href="https://oreil.ly/yRJZP">COMS 4771: Introduction to Machine Learning</a>, Lecture 6, Slide 7. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611525864">[<a href="ch01.xhtml#idm45969611525864-marker">33</a>] Wang, Yaqing, Quanming Yao, James Kwok, and Lionel M. Ni. <a href="https://oreil.ly/LyMxm">“Generalizing from a Few Examples: A Survey on Few-Shot Learning”</a>, (2019).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611524152">[<a href="ch01.xhtml#idm45969611524152-marker">34</a>] Wang, Zhengwei, Qi She, and Tomas E. Ward. <a href="https://oreil.ly/OFvz7">“Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy”</a>, (2019).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611519256">[<a href="ch01.xhtml#idm45969611519256-marker">35</a>] Olah, Chris, Arvind Satyanarayan, Ian Johnson, Shan Carter, Ludwig Schubert, Katherine Ye, and Alexander Mordvintsev. “The Building Blocks of Interpretability.” <em>Distill</em> 3.3 (March 2018): e10.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611506392">[<a href="ch01.xhtml#idm45969611506392-marker">36</a>] Nan, Kaiming, Sicong Liu, Junzhao Du, and Hui Liu. “Deep Model Compression for Mobile Platforms: A Survey.” <em>Tsinghua Science and Technology</em> 24.6 (2019): 677–693.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611504968">[<a href="ch01.xhtml#idm45969611504968-marker">37</a>] TensorFlow. <a href="https://oreil.ly/Jxsuc">“Get started with TensorFlow Lite”</a>. Last modified March 21, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611503496">[<a href="ch01.xhtml#idm45969611503496-marker">38</a>] Ganesh, Prakhar, Yao Chen, Xin Lou, Mohammad Ali Khan, Yin Yang, Deming Chen, Marianne Winslett, Hassan Sajjad, and Preslav Nakov. <a href="https://oreil.ly/VSQvc">“Compressing Large-Scale Transformer-Based Models: A Case Study on BERT”</a>, (2020).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611497128">[<a href="ch01.xhtml#idm45969611497128-marker">39</a>] Lipton, Zachary C. and Jacob Steinhardt. <a href="https://oreil.ly/lpay1">“Troubling Trends in Machine Learning Scholarship”</a>, (2018).</p></div></div></section></div>



  </body>
</html>