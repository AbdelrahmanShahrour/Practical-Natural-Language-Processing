<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<link href="Styles/Style00.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style01.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style02.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style03.css" rel="stylesheet" type="text/css" />
<style type="text/css" title="ibis-book">
    @charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0 !important}#sbo-rt-content div.preface p.byline+p.byline{margin:0 !important}#sbo-rt-content div.sect1&gt;p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1&gt;p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]&gt;div&gt;h1,#sbo-rt-content section[data-type="preface"]&gt;div&gt;h1,#sbo-rt-content section[data-type="appendix"]&gt;div&gt;h1,#sbo-rt-content section[data-type="glossary"]&gt;div&gt;h1,#sbo-rt-content section[data-type="bibliography"]&gt;div&gt;h1,#sbo-rt-content section[data-type="index"]&gt;div&gt;h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content div.figure h6,#sbo-rt-content figure h6,#sbo-rt-content figure figcaption{font-size:.9rem !important;text-align:center;font-weight:normal !important;font-style:italic;font-family:serif !important;text-transform:none !important;letter-spacing:normal !important;color:#000;padding-top:.25em !important;margin-top:0 !important;page-break-before:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]&gt;div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:2em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content p[data-type="footnote"]{font-size:90% !important;line-height:1.2em !important;margin-left:2.5em !important;text-indent:-2.3em !important}#sbo-rt-content p[data-type="footnote"] sup{display:inline-block !important;position:static !important;width:2em !important;text-align:right !important;font-size:100% !important;padding-right:.5em !important}#sbo-rt-content p[data-type="footnote"] a[href$="-marker"]{font-family:sans-serif !important;font-size:90% !important;color:#8e0012 !important}#sbo-rt-content p[data-type="footnote"] a[data-type="xref"]{margin:0 !important;padding:0 !important;text-indent:0 !important}#sbo-rt-content a[data-type="noteref"]{font-family:sans-serif !important;color:#8e0012;margin-left:0;padding-left:0}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dl{margin-bottom:1.5em !important}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important;line-height:1.25rem;font-style:italic}#sbo-rt-content dd{margin:10px 0 .25em 1.5em !important;line-height:1.65em !important}#sbo-rt-content dd p{padding:0 !important;margin:0 0 10px !important}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul&gt;li,#sbo-rt-content ol ul,#sbo-rt-content ol ul&gt;li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul&gt;li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul&gt;li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul&gt;li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol&gt;li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol&gt;li,#sbo-rt-content ul ol,#sbo-rt-content ul ol&gt;li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol&gt;li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol&gt;li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol&gt;li&gt;ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol&gt;li&gt;ol&gt;li&gt;ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div[data-type="tip"] figure h6,#sbo-rt-content div[data-type="note"] figure h6,#sbo-rt-content div[data-type="warning"] figure h6,#sbo-rt-content div[data-type="caution"] figure h6,#sbo-rt-content div[data-type="important"] figure h6{font-family:serif !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content table li{margin:10px 0 0 .25em !important}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:top;font-size:80%}#sbo-rt-content th{vertical-align:bottom}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller;word-break:break-all}#sbo-rt-content table.border tbody&gt;tr:last-child&gt;td{border-bottom:transparent}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content div[data-type="equation"] math{font-size:calc(.35em + 1vw)}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index h3{padding:.25em;margin-top:1em !important;background-color:#F0F0F0}#sbo-rt-content div.index li{line-height:130%;list-style-type:none}#sbo-rt-content div.index a.indexterm{color:#8e0012 !important}#sbo-rt-content div.index ul{margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.index ul ul{margin-left:2em !important;margin-top:0 !important}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content pre.break-code,#sbo-rt-content code.break-code,#sbo-rt-content .break-code pre,#sbo-rt-content .break-code code{word-break:break-all}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content .width-10,#sbo-rt-content figure.width-10 img{width:10% !important}#sbo-rt-content .width-20,#sbo-rt-content figure.width-20 img{width:20% !important}#sbo-rt-content .width-30,#sbo-rt-content figure.width-30 img{width:30% !important}#sbo-rt-content .width-40,#sbo-rt-content figure.width-40 img{width:40% !important}#sbo-rt-content .width-50,#sbo-rt-content figure.width-50 img{width:50% !important}#sbo-rt-content .width-60,#sbo-rt-content figure.width-60 img{width:60% !important}#sbo-rt-content .width-70,#sbo-rt-content figure.width-70 img{width:70% !important}#sbo-rt-content .width-80,#sbo-rt-content figure.width-80 img{width:80% !important}#sbo-rt-content .width-90,#sbo-rt-content figure.width-90 img{width:90% !important}#sbo-rt-content .width-full,#sbo-rt-content .width-100{width:100% !important}#sbo-rt-content .sc{text-transform:none !important}#sbo-rt-content .right{float:none !important}#sbo-rt-content a.totri-footnote{padding:0 !important}#sbo-rt-content figure.width-10,#sbo-rt-content figure.width-20,#sbo-rt-content figure.width-30,#sbo-rt-content figure.width-40,#sbo-rt-content figure.width-50,#sbo-rt-content figure.width-60,#sbo-rt-content figure.width-70,#sbo-rt-content figure.width-80,#sbo-rt-content figure.width-90{width:auto !important}#sbo-rt-content p img,#sbo-rt-content pre img{width:1.25em;line-height:1em;margin:0 .15em -.2em}#sbo-rt-content figure.no-frame div.border-box{border:none}#sbo-rt-content .right{text-align:right !important}
    </style>
<style type="text/css" id="font-styles">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }</style>
<style type="text/css" id="font-family">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }</style>
<style type="text/css" id="column-width">#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }</style>

<style type="text/css">body{margin:1em;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}body{background-color:transparent!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style></head>
<body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 7. Topics in Brief"><div class="chapter" id="topics_in_brief">
<h1><span class="label">Chapter 7. </span>Topics in Brief</h1>

<blockquote class="right">
<p class="right"><em>The problems are solved, not by giving new information,</em><br/> <em>but by arranging what we have known since long.</em></p>
<p data-type="attribution" style="text-align:right"><em>Ludwig Wittgenstein,</em> Philosophical Investigations</p>
</blockquote>

<p><a contenteditable="false" data-primary="Wittgenstein, Ludwig" data-type="indexterm" id="idm45969595068664"/>So far in <a data-type="xref" href="part02.xhtml#essentials">Part II</a> of this book, we’ve discussed a few common application scenarios of NLP: text classification, information extraction, and chatbots (Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a> through <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch06.xhtml#chatbots">6</a>). While these are the most common use cases for NLP we’re likely to encounter in industry projects, there are many other NLP tasks that are relevant in building real-world applications involving large collections of documents. We’ll take a quick look at some of these topics in this chapter. Let’s first start with a few largely unrelated scenarios you may encounter in your workplace projects. We’ll discuss them in more detail throughout the chapter.</p>

<p>If someone asks us to find out what NLP is and we have no idea, where do we start? In the pre-internet era, we would’ve hit the nearest library to do some research. However, now the first place we’d go is to a search engine. <em>Search</em><a contenteditable="false" data-primary="search" data-type="indexterm" id="idm45969595062360"/> involves a lot of human-computer interaction using natural language, so it gives rise to very interesting use cases for NLP.</p>

<p>Our client is a big law firm. When a new case comes up, they sometimes have to research lots and lots of documents related to the case to get a bigger picture of what it’s about. Many times, there isn’t enough time for a thorough manual review. Our client wants us to develop software that can provide a quick overview of the topics discussed in large document collections. <em>Topic modeling</em><a contenteditable="false" data-primary="topic modeling" data-type="indexterm" id="idm45969595059880"/> is a technique that’s used to address this problem of finding latent topics in a large collection of documents.</p>

<p>The same client’s firm has another problem: case report documents they receive are usually quite long, and it’s difficult even for an experienced lawyer to get the gist quickly. So our client wants a solution to automatically create summaries of text documents. <em>Text summarization</em><a contenteditable="false" data-primary="text summarization" data-type="indexterm" id="idm45969595057528"/> approaches are used to address such use cases in the industry.</p>

<p>Many of us read news online every day. A common feature of many news websites is the “related articles” feature, which shows articles that are topically related to the article we’re reading. Consider a related scenario where we’re shown jobs related to a given job based on the profile descriptions. <em>Recommendation</em><a contenteditable="false" data-primary="recommendations" data-type="indexterm" id="idm45969595055192"/> methods using NLP are key to building solutions for such use cases.</p>

<p>We live in an increasingly multicultural world, and many organizations have clients or customers across the globe. This results in the need to translate documents (at scale) in all supported languages in the organization. <em>Machine translation (MT)</em><a contenteditable="false" data-primary="machine translation (MT)" data-type="indexterm" id="idm45969595052744"/><a contenteditable="false" data-primary="MT" data-see="machine translation" data-type="indexterm" id="idm45969595051672"/> is useful in such scenarios. Streaming services like Amazon<a contenteditable="false" data-primary="Amazon" data-type="indexterm" id="idm45969595050168"/>, Netflix<a contenteditable="false" data-primary="Netflix" data-type="indexterm" id="idm45969595048856"/>, and YouTube<a contenteditable="false" data-primary="YouTube" data-type="indexterm" id="idm45969595047592"/> use MT extensively for generating subtitles in various languages. Tools like Google Translate<a contenteditable="false" data-primary="Google Translate" data-type="indexterm" id="idm45969595046216"/> help tourists across the globe communicate in local languages.</p>

<p>We use search engines for many reasons in day-to-day life. Sometimes, we want to know answers to questions. Try asking a factual question such as, “Who wrote Animal Farm?” to your favorite search engine. Google shows “George Orwell” as its top result along with some biographical details about him, followed by other regular search results. Try asking a somewhat descriptive question, say, “How do I calm down a crying baby?” Among the answers, you’ll also see a blurb from some website that lists a number of ways to calm a baby. This is an example of <em>question answering</em><a contenteditable="false" data-primary="question answering (QA)" data-type="indexterm" id="idm45969595043752"/><a contenteditable="false" data-primary="answering questions" data-see="question answering" data-type="indexterm" id="idm45969595042648"/>, where the task is to locate the most appropriate answer to the user query instead of showing a collection of documents. Note that this is slightly different from the FAQ chatbot we saw in <a data-type="xref" href="ch06.xhtml#chatbots">Chapter 6</a>, where the scope of answers lies within a much smaller dataset (i.e., FAQs) instead of a large collection of documents (such as the web).</p>

<p>These are the topics we’ll discuss in this chapter. While they may seem very different from one another, we’ll see the similarities between them as we progress through the chapter. This collection is not an exhaustive list, but these are some common scenarios encountered when developing NLP-based solutions for industrial applications. The first four tasks (search, topic modeling, text summarization, and recommendation) are more common in real-world applied NLP scenarios, so we’ll discuss them in greater detail than the other two. With large-scale question answering and machine translation, you’re unlikely to encounter a scenario where you’d have to develop solutions from scratch, so we’ll only introduce them so you’ll know where to get started to build an MVP quickly. <a data-type="xref" href="Images/#list_of_the_topics_covered_in">Table 7-1</a> summarizes the topics we’ll cover in this chapter, along with example usage scenarios and the kind of data they work on.</p>

<table class="less_space pagebreak-before" id="list_of_the_topics_covered_in">
	<caption><span class="label">Table 7-1. </span>List of the topics covered in this chapter</caption>
	<thead class="less_space">
		<tr>
			<th class="less space">NLP task</th>
			<th>Use</th>
			<th>Nature of data</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>Search</td>
			<td>Find relevant content for a given user query.</td>
			<td>World wide web/large collection of documents</td>
		</tr>
		<tr>
			<td>Topic modeling</td>
			<td>Find topics and hidden patterns in a set of documents.</td>
			<td>Large collection of documents</td>
		</tr>
		<tr>
			<td>Text summarization</td>
			<td>Create a shorter version of the text with the most important content</td>
			<td>Typically a single document</td>
		</tr>
		<tr>
			<td>Recommendations</td>
			<td>Showing related articles</td>
			<td>Large collection of documents</td>
		</tr>
		<tr>
			<td>Machine translation</td>
			<td>Translate from one language to another</td>
			<td>A single document</td>
		</tr>
		<tr>
			<td>Question answering system</td>
			<td>Get answers to queries directly instead of a set of documents.</td>
			<td>A single document or a large collection of documents</td>
		</tr>
	</tbody>
</table>

<p>With this overview, let us start introducing these topics one by one in a little bit more detail. Our first topic is search and information retrieval.</p>

<section data-type="sect1" data-pdf-bookmark="Search and Information Retrieval"><div class="sect1" id="search_and_information_retrieval">
<h1>Search and Information Retrieval</h1>

<p><a contenteditable="false" data-primary="search" data-type="indexterm" id="ch07_term1"/><a contenteditable="false" data-primary="information retrieval" data-type="indexterm" id="ch07_term2"/>A search engine is an important component of everyone’s online activity. We search for information to decide on the best items to purchase, nice places to eat out, and businesses to frequent, just to name a few examples. We also rely heavily on search to sift through our emails, documents, and financial transactions. A lot of these search interactions happen through text (or speech converted to text in voice input). This means that a lot of language processing happens inside a search engine. Thus, we can say that NLP plays an important role in modern search engines.</p>

<p>Let’s start with a quick look into what happens when we search. When a user searches using a query, the search engine collects a ranked list of documents that matches the query. For this to happen, an “index” of documents and vocabulary used in them should be constructed first and is then used to search and rank results. One popular form of indexing<a contenteditable="false" data-primary="indexing" data-type="indexterm" id="idm45969595014600"/> textual data and ranking search results for search engines is something we studied in <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a>: TF-IDF<a contenteditable="false" data-primary="TF-IDF (Term Frequency–Inverse Document Frequency)" data-type="indexterm" id="idm45969595012408"/>. Recent developments in DL models for NLP can also be used for this purpose. For example, Google<a contenteditable="false" data-primary="Google" data-secondary="search engine" data-type="indexterm" id="idm45969595010936"/> recently started ranking search results and showing search snippets using the BERT model. They claim that this has improved the quality and relevance of their search results [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969595009240-marker" href="ch07.xhtml#idm45969595009240">1</a>]. This is an important example of NLP’s usefulness in a modern-day search engine.</p>

<p><a contenteditable="false" data-primary="search engines" data-secondary="features that use NLP" data-type="indexterm" id="ch07_term3"/>Apart from this major function of storing data and ranking search results, several features in a modern search engine involve NLP. For example, consider the screenshot of a Google search result shown in <a data-type="xref" href="#figure_7_1_screenshot_of_a_google_searc">Figure 7-1</a>, which illustrates some features that use NLP.</p>

<figure><div id="figure_7_1_screenshot_of_a_google_searc" class="figure"><img alt="Screenshot of a Google search query" src="Images/pnlp_0701.png" width="892" height="763"/>
<h6><span class="label">Figure 7-1. </span>Screenshot of a Google search query<a contenteditable="false" data-primary="Google Search" data-type="indexterm" id="idm45969595002504"/></h6>
</div></figure>

<ol>
	<li>
	<p><em>Spelling correction<a contenteditable="false" data-primary="spelling correction" data-type="indexterm" id="idm45969594999768"/>:</em> The user entered an incorrect spelling, and the search engine offered a suggestion showing the correct spelling.</p>
	</li>
	<li>
	<p><em>Related queries<a contenteditable="false" data-primary="related queries" data-type="indexterm" id="idm45969594997096"/>:</em> The “People also ask” feature shows other related questions people ask about Marie Curie.</p>
	</li>
	<li>
	<p><em>Snippet extraction<a contenteditable="false" data-primary="snippet extraction" data-type="indexterm" id="idm45969594994568"/>:</em> All the search results show a text snippet involving the query.</p>
	</li>
	<li>
	<p><em>Biographical information extraction<a contenteditable="false" data-primary="biographical information extraction" data-type="indexterm" id="idm45969594992072"/>:</em> On the right-hand side, there’s a small snippet showing Marie Curie’s biographical details along with some specific information extracted from text. There are also some quotes and a list of people related to her in some way.</p>
	</li>
	<li>
	<p><em>Search results classification<a contenteditable="false" data-primary="search results classification" data-type="indexterm" id="idm45969594989384"/>:</em> On top, there are categories of search results: all, news, images, videos, and so on.</p>
	</li>
</ol>

<p>Here, we see a range of concepts we’ve learned about in this book being put to use. While these are by no means the only places NLP is used in search engines, they are examples of where NLP is useful in the user interface aspect of search. However, there’s much more to search than NLP, and building a search engine seems like a massive endeavor requiring a lot of infrastructure. This may make one wonder: when do you need to build a search engine, and how? Do we always build search engines as massive as Google? Let’s take a look at two scenarios to answer these questions.</p>

<p class="pagebreak-before">Imagine we work for a company like Broad Reader. Our company wants to develop a search engine that crawls forums and discussion boards from all over the web and lets users query this large collection. Consider another scenario: let’s say our client is a law firm where loads of legal documents from clients and other legal sources are <span class="keep-together">uploaded</span> every day. We’re asked to develop a custom search engine for the client to search through their database. How are these two scenarios different?</p>

<p>The first scenario requires that we build what we call a generic search engine, where we would have to set up a way to scrape different websites, keep looking for new content and new websites, and constantly build and update our “index.” The second scenario is an example of an enterprise search engine, as we don’t have to scout for content to index. Thus, these two types of search engines are distinguished as follows:</p>

<ul>
	<li>
	<p>Generic search engines<a contenteditable="false" data-primary="search engines" data-secondary="generic" data-type="indexterm" id="idm45969594983016"/>, such as Google and Bing, that crawl the web and aim to cover as much as possible by constantly looking for new webpages</p>
	</li>
	<li>
	<p>Enterprise search engines<a contenteditable="false" data-primary="search engines" data-secondary="enterprise" data-type="indexterm" id="idm45969594980376"/><a contenteditable="false" data-primary="enterprise search engines" data-type="indexterm" id="idm45969594979000"/>, where our search space is restricted to a smaller set of already existing documents within an organization</p>
	</li>
</ul>

<p>In our experience, the second form of search is the most common use case you may encounter at your workplace, so we’ll only briefly introduce a generic search engine by discussing a few basic components that are also relevant to enterprise search.</p>

<section data-type="sect2" data-pdf-bookmark="Components of a Search Engine"><div class="sect2" id="components_of_a_search_engine">
<h2>Components of a Search Engine</h2>

<p><a contenteditable="false" data-primary="search engines" data-secondary="components" data-type="indexterm" id="ch07_term4"/>How does a search engine work? What are some of the basic components? We briefly introduce them through <a data-type="xref" href="#early_architecture_of_the_google_search">Figure 7-2</a>, taken from the now-famous 1998 research paper on the architecture of Google [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_7_23-marker" href="ch07.xhtml#footnote_7_23">2</a>].</p>

<figure><div id="early_architecture_of_the_google_search" class="figure"><img alt="Early architecture of the Google search engine [_23]" src="Images/pnlp_0702.png" width="1091" height="1114"/>
<h6><span class="label">Figure 7-2. </span>Early architecture of the Google search engine<a contenteditable="false" data-primary="Google" data-secondary="search engine" data-type="indexterm" id="idm45969594968600"/> [<a data-type="noteref" href="ch07.xhtml#footnote_7_23">2</a>]</h6>
</div></figure>

<p>There are several small and large components inside a search engine, as shown in the figure. The three major components that can be considered its building blocks (and a fourth component that is now also common) are:</p>

<dl>
	<dt>Crawler<a contenteditable="false" data-primary="crawlers" data-type="indexterm" id="idm45969594964520"/></dt> 
<dd><p>Collects all the content for the search engine. The crawler’s job is to traverse the web following a bunch of seed URLs and build its collection of URLs through them in a breadth-first way. It visits each URL, saves a copy of the document, detects the outgoing hyperlinks, then adds them to the list of URLs to be visited next. Typical decisions that need to be made when designing a crawler include identifying what to crawl, when to stop crawling, when to re-crawl, what to re-crawl, and how to make sure we don’t crawl duplicate content. From our experience, even when you have to develop some sort of generic search engine (say, a blog search engine), you’re unlikely to encounter a scenario where you should design your own crawler. Production-ready crawlers, such as Apache Nutch<a contenteditable="false" data-primary="Apache Nutch" data-type="indexterm" id="idm45969594961976"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594960744-marker" href="ch07.xhtml#idm45969594960744">3</a>] and Scrapy<a contenteditable="false" data-primary="Scrapy" data-type="indexterm" id="idm45969594959368"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594958136-marker" href="ch07.xhtml#idm45969594958136">4</a>], can be customized and used for your project in such scenarios.</p></dd>

	<dt>Indexer<a contenteditable="false" data-primary="indexers" data-type="indexterm" id="ch07_term5"/></dt> 
<dd><p>Parses and stores the content that the crawler collects and builds an “index” so it can be searched and retrieved efficiently. While it’s possible to index videos, audio, images, etc., text indexing<a contenteditable="false" data-primary="indexing" data-type="indexterm" id="ch07_term6"/> is the most common type of indexing in real-world projects. Data structures for a search engine index are developed keeping in mind the need for fast and efficient search of its crawl in response to a user query. An example of a popular indexing algorithm used in web search engines is an “inverted index<a contenteditable="false" data-primary="inverted indexes" data-type="indexterm" id="idm45969594952120"/>,” which stores the list of documents associated with each word in its vocabulary. As with crawlers, you’re unlikely to encounter a situation where you have to develop your own indexer. Software like Apache Solr<a contenteditable="false" data-primary="Apache Solr software" data-type="indexterm" id="idm45969594950664"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_7_3-marker" href="ch07.xhtml#footnote_7_3">5</a>] and Elasticsearch [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594947816-marker" href="ch07.xhtml#idm45969594947816">6</a>] are typically used in the industry to build an index and search over it.</p></dd>
	<dt>Searcher<a contenteditable="false" data-primary="searchers" data-type="indexterm" id="idm45969594946232"/></dt>
<dd><p>Searches the index and ranks the search results for the user query based on the relevance of the results to the query. A typical search query on Google or Bing will likely yield hundreds and thousands of results. As users, we can’t go through them manually to decide whether the result is relevant to our query. This is where a ranking of search results becomes important. An intuitive approach to ranking<a contenteditable="false" data-primary="ranking" data-type="indexterm" id="idm45969594944200"/> based on what we’ve seen so far in this book is to obtain a vector representation of the result document and user query and rank the documents based on some measure of similarity. In fact, as we mentioned at the start of the chapter, TF-IDF<a contenteditable="false" data-primary="TF-IDF (Term Frequency–Inverse Document Frequency)" data-type="indexterm" id="idm45969594942712"/>, which we saw in detail in <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a> and used for text classification in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>, is one of the popular methods of searching and ranking search results.</p></dd>
<dt>Feedback</dt>
	<dd><p>A fourth component, which is now common in all search engines, that<a contenteditable="false" data-primary="feedback" data-type="indexterm" id="idm45969594938408"/> tracks and analyzes user interactions with the search engine, such as click-throughs, time spent on searching and on each clicked result, etc., and uses it for continuous improvement of the search system.</p></dd>
</dl>

<p>We hope this short discussion gave a quick glance into what a typical search engine is made up of. Information retrieval is a major research area in itself, and search engine development is a massive undertaking involving a lot of computation and infrastructure. All the topics discussed above are not completely solved problems yet. In this section, we only provided an overview of how a search engine works in order to lead into a discussion on where NLP comes into the picture and how to develop custom search engines. Interested readers can refer to [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594935816-marker" href="ch07.xhtml#idm45969594935816">7</a>] for a detailed discussion on the algorithms and data structures behind search engine development.</p>

<p>With this introduction, let’s move on to what a typical search engine pipeline looks like in the use cases you may encounter in your workplace and what NLP methods we’ve learned so far can be put to use in this pipeline.<a contenteditable="false" data-primary="search engines" data-secondary="components" data-startref="ch07_term4" data-type="indexterm" id="idm45969594933816"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="A Typical Enterprise Search Pipeline"><div class="sect2" id="a_typical_enterprise_search_pipeline">
<h2>A Typical Enterprise Search Pipeline</h2>

<p><a contenteditable="false" data-primary="enterprise search engines" data-type="indexterm" id="ch07_term7"/>Say we work for a large newspaper and are tasked with developing a search engine for its website. We already mentioned that Solr and ElasticSearch are typically used for addressing such scenarios. How will we use them? Let’s do a step-by-step walkthrough and also discuss which NLP tools we’ll need in this process.</p>

<dl>
	<dt>Crawling/content acquisition<a contenteditable="false" data-primary="crawling/content acquisition" data-type="indexterm" id="idm45969594927608"/><a contenteditable="false" data-primary="content acquisition" data-type="indexterm" id="idm45969594926440"/></dt>
	<dd>We don’t really need a crawler in this case, as we don’t need data from external websites. What we need is a way to read data from the location where all the news articles are stored (e.g., in a local database or in some cloud location).</dd>
	<dt>Text normalization<a contenteditable="false" data-primary="text normalization" data-type="indexterm" id="idm45969594924216"/><a contenteditable="false" data-primary="normalization" data-secondary="text" data-type="indexterm" id="idm45969594923080"/></dt>
	<dd>Once we collect the content, depending on its format, we start by first extracting the main text and discarding additional information (e.g., newspaper headers). It’s also common to do some pre-processing steps, such as tokenizing, lowercasing, stop word removal, stemming, etc., before vectorizing.</dd>
	<dt>Indexing<a contenteditable="false" data-primary="indexing" data-type="indexterm" id="idm45969594920552"/></dt>
	<dd>For indexing, we have to vectorize the text. TF-IDF<a contenteditable="false" data-primary="TF-IDF (Term Frequency–Inverse Document Frequency)" data-type="indexterm" id="idm45969594918936"/> is a popular scheme for this, as we discussed earlier. However, like Google<a contenteditable="false" data-primary="Google" data-secondary="search engine" data-type="indexterm" id="idm45969594917608"/>, we can also use BERT instead. How do we use BERT<a contenteditable="false" data-primary="BERT (Bidirectional Encoder Representations from Transformers)" data-secondary="search with" data-type="indexterm" id="idm45969594916104"/> for search? We can use BERT to get a vector representation of the query and documents and generate a ranked list of closest documents for a given query in terms of vector distance. [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594914360-marker" href="ch07.xhtml#idm45969594914360">8</a>] shows how we can use such text embeddings to index and search using <span class="keep-together">Elasticsearch.</span></dd>
</dl>

<p>In addition to indexing the entire content of an article, we can also add additional fields/facets to the index for each document and later search by these facets. For example, for a newspaper, this can be the news category, other tags like the state involved (e.g., California for a news article about something in the USA), and so on. Text classification<a contenteditable="false" data-primary="text classification" data-type="indexterm" id="idm45969594910984"/> approaches we saw in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a> can be used to get such categories and tags, if necessary. At the time of displaying the search results, we can combine this with filters like date to enrich the user experience. We’ll see an example of such a faceted search in <a data-type="xref" href="ch09.xhtml#e_commerce_and_retail">Chapter 9</a>.</p>

<p>So, let’s assume we’ve built our search engine following the above process. What next? What happens when the user types a query? At this point, the pipeline typically consists of the following steps:</p>

<ol>
	<li>
	<p><em>Query processing and execution<a contenteditable="false" data-primary="search engines" data-secondary="query processing and execution" data-type="indexterm" id="idm45969594905544"/>:</em> The search query is passed through the text normalization process as above. Once the query is framed, it’s executed, and results are retrieved and ranked according to some notion of relevance. Search engine libraries like Elasticsearch even provide custom scoring functions to modify the ranking of documents retrieved for a given query [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594903496-marker" href="ch07.xhtml#idm45969594903496">9</a>].</p>
	</li>
	<li>
	<p><em>Feedback and ranking<a contenteditable="false" data-primary="feedback" data-type="indexterm" id="idm45969594901032"/><a contenteditable="false" data-primary="ranking" data-type="indexterm" id="idm45969594899896"/><a contenteditable="false" data-primary="search engines" data-secondary="feedback" data-type="indexterm" id="idm45969594898792"/><a contenteditable="false" data-primary="search engines" data-secondary="ranking" data-type="indexterm" id="idm45969594897416"/>:</em> To evaluate search results and make them more relevant to the user, user behavior is recorded and analyzed, and signals such as click action on result and time spent on a result page are used to improve the ranking algorithm. An example in our newspaper’s case could be to learn the reader’s preference (e.g., the reader prefers reading local news from Region X) and show them a personalized ranking of suggested articles.</p>
	</li>
</ol>

<p>We hope this newspaper use case shows what a typical enterprise search engine development pipeline looks like. Like with many software applications, recent developments in the field of machine learning have also influenced enterprise search. We briefly mentioned how BERT and other such embedding-based text representations can be used with Elasticsearch. Amazon Kendra [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_7_27-marker" href="ch07.xhtml#footnote_7_27">10</a>], an enterprise search engine powered by machine learning, is a recent addition to this space.<a contenteditable="false" data-primary="enterprise search engines" data-startref="ch07_term7" data-type="indexterm" id="idm45969594892600"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Setting Up a Search Engine: An Example"><div class="sect2" id="setting_up_a_search_engine_an_example">
<h2>Setting Up a Search Engine: An Example</h2>

<p><a contenteditable="false" data-primary="search engines" data-secondary="example build" data-type="indexterm" id="ch07_term8"/>Now that we have an idea of the components of a search engine and how they work together in an example scenario, let’s take a quick look at building a small search engine using Elasticsearch<a contenteditable="false" data-primary="Elasticsearch" data-secondary="Python API" data-type="indexterm" id="idm45969594887272"/><a contenteditable="false" data-primary="Elasticsearch" data-type="indexterm" id="ch07_term9"/>’s Python API. We’ll use the CMU Book Summaries dataset<a contenteditable="false" data-primary="CMU Book Summaries dataset" data-type="indexterm" id="idm45969594884392"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_7_5-marker" href="ch07.xhtml#footnote_7_5">11</a>], which consists of plot summaries of over 16,000 books extracted from Wikipedia pages. We’ll illustrate the process using 500 documents, but the notebook associated with this section (<em>Ch7/ElasticSearch.ipynb</em>) can be used to build a search engine with the full dataset. We already have our content in place, so we don’t need a crawler. Taking a simple use case that doesn’t involve additional pre-processing (no stemming, for example), the following code snippet shows how to build an index using Elasticsearch<a contenteditable="false" data-primary="indexing" data-type="indexterm" id="idm45969594880424"/>:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="c1">#Build an index from booksummaries dataset, using only 500 documents.</code>
<code class="n">path</code> <code class="o">=</code> <code class="s2">"../booksummaries/booksummaries.txt"</code>
<code class="n">count</code> <code class="o">=</code> <code class="mi">1</code>
<code class="k">for</code> <code class="n">line</code> <code class="ow">in</code> <code class="nb">open</code><code class="p">(</code><code class="n">path</code><code class="p">):</code>
    <code class="n">fields</code> <code class="o">=</code> <code class="n">line</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s2">"</code><code class="se">\t</code><code class="s2">"</code><code class="p">)</code>
    <code class="n">doc</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'id'</code> <code class="p">:</code> <code class="n">fields</code><code class="p">[</code><code class="mi">0</code><code class="p">],</code>
          <code class="s1">'title'</code><code class="p">:</code> <code class="n">fields</code><code class="p">[</code><code class="mi">2</code><code class="p">],</code>
          <code class="s1">'author'</code><code class="p">:</code> <code class="n">fields</code><code class="p">[</code><code class="mi">3</code><code class="p">],</code>
          <code class="s1">'summary'</code><code class="p">:</code> <code class="n">fields</code><code class="p">[</code><code class="mi">6</code><code class="p">]</code>
          <code class="p">}</code>
      <code class="c1">#Index is called myindex</code>
    <code class="n">res</code> <code class="o">=</code> <code class="n">es</code><code class="o">.</code><code class="n">index</code><code class="p">(</code><code class="n">index</code><code class="o">=</code><code class="s2">"myindex"</code><code class="p">,</code> <code class="nb">id</code><code class="o">=</code><code class="n">fields</code><code class="p">[</code><code class="mi">0</code><code class="p">],</code> <code class="n">body</code><code class="o">=</code><code class="n">doc</code><code class="p">)</code>
    <code class="n">count</code> <code class="o">=</code> <code class="n">count</code><code class="o">+</code><code class="mi">1</code>
    <code class="k">if</code> <code class="n">count</code><code class="o">%</code><code class="mi">100</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
          <code class="k">print</code><code class="p">(</code><code class="s2">"indexed 100 documents"</code><code class="p">)</code>
    <code class="k">if</code> <code class="n">count</code> <code class="o">==</code> <code class="mi">501</code><code class="p">:</code>
          <code class="k">break</code>
<code class="n">res</code> <code class="o">=</code> <code class="n">es</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="n">index</code><code class="o">=</code><code class="s2">"myindex"</code><code class="p">,</code> <code class="n">body</code><code class="o">=</code><code class="p">{</code><code class="s2">"query"</code><code class="p">:</code> <code class="p">{</code><code class="s2">"match_all"</code><code class="p">:</code> <code class="p">{}}})</code>
<code class="k">print</code><code class="p">(</code><code class="s2">"Your index has </code><code class="si">%d</code><code class="s2"> entries"</code> <code class="o">%</code> <code class="n">res</code><code class="p">[</code><code class="s1">'hits'</code><code class="p">][</code><code class="s1">'total'</code><code class="p">][</code><code class="s1">'value'</code><code class="p">])</code></pre>

<p>This code builds an index with four fields per document—<code>id</code>, <code>title</code>, <code>author</code>, and <code>summary</code>—which are all available in the dataset itself. Once the index is built, it runs a query to check the size of the index. In this case, the output will show as 500 entries. Once the index is built, we have to figure out how to use it to perform search. While we won’t go into the user interface design aspects of the search process, the following code snippet illustrates how to search with Elasticsearch:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="c1">#match query works as a OR query when the query string has multiple words</code>
<code class="c1">#match_phrase looks for exact matches. So using that here.</code>
<code class="k">while</code> <code class="bp">True</code><code class="p">:</code>
    <code class="n">query</code> <code class="o">=</code> <code class="nb">input</code><code class="p">(</code><code class="s2">"Enter your search query: "</code><code class="p">)</code>
    <code class="k">if</code> <code class="n">query</code> <code class="o">==</code> <code class="s2">"STOP"</code><code class="p">:</code>
        <code class="k">break</code>
    <code class="n">res</code> <code class="o">=</code> <code class="n">es</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="n">index</code><code class="o">=</code><code class="s2">"myindex"</code><code class="p">,</code> <code class="n">body</code><code class="o">=</code><code class="p">{</code><code class="s2">"query"</code><code class="p">:</code> <code class="p">{</code><code class="s2">"match_phrase"</code><code class="p">:</code>
                                            <code class="p">{</code><code class="s2">"summary"</code><code class="p">:</code> <code class="n">query</code><code class="p">}}})</code>
    <code class="k">print</code><code class="p">(</code><code class="s2">"Your search returned </code><code class="si">%d</code><code class="s2"> results:"</code>
                     <code class="o">%</code><code class="n">res</code><code class="p">[</code><code class="s1">'hits'</code><code class="p">][</code><code class="s1">'total'</code><code class="p">][</code><code class="s1">'value'</code><code class="p">])</code>
    <code class="k">for</code> <code class="n">hit</code> <code class="ow">in</code> <code class="n">res</code><code class="p">[</code><code class="s2">"hits"</code><code class="p">][</code><code class="s2">"hits"</code><code class="p">]:</code>
          <code class="k">print</code><code class="p">(</code><code class="n">hit</code><code class="p">[</code><code class="s2">"_source"</code><code class="p">][</code><code class="s2">"title"</code><code class="p">])</code>
          <code class="c1">#to get a snippet 100 characters before and after the match</code>
          <code class="n">loc</code> <code class="o">=</code> <code class="n">hit</code><code class="p">[</code><code class="s2">"_source"</code><code class="p">][</code><code class="s2">"summary"</code><code class="p">]</code><code class="o">.</code><code class="n">lower</code><code class="p">()</code><code class="o">.</code><code class="n">index</code><code class="p">(</code><code class="n">query</code><code class="p">)</code>
          <code class="k">print</code><code class="p">(</code><code class="n">hit</code><code class="p">[</code><code class="s2">"_source"</code><code class="p">][</code><code class="s2">"summary"</code><code class="p">][:</code><code class="mi">100</code><code class="p">])</code>
          <code class="k">print</code><code class="p">(</code><code class="n">hit</code><code class="p">[</code><code class="s2">"_source"</code><code class="p">][</code><code class="s2">"summary"</code><code class="p">][</code><code class="n">loc</code><code class="o">-</code><code class="mi">100</code><code class="p">:</code><code class="n">loc</code><code class="o">+</code><code class="mi">100</code><code class="p">])</code></pre>

<p>This snippet keeps asking the user to enter a search query until the word STOP is typed and shows the search results, along with a short snippet containing the search phrase. For example, if the user searches for the word “countess,” the results look as follows:</p>

<pre data-type="programlisting">
Enter your search query: countess
Your search returned 7 results:
All's Well That Ends Well
71
 Helena, the orphan daughter of a famous physician, is the ward of the Countess
 of Rousillon, and ho
…
…
…
Enter your search query: STOP</pre>

<p>Elasticsearch has many features to alter the scoring function, to change the search process in terms of query formulation (e.g., exact match versus fuzzy match), to add pre-processing steps like stemming during the indexing process, and so on. We leave them as further exercises for the reader. Now, let’s look at a case study of building an enterprise search engine from scratch and improving it.<a contenteditable="false" data-primary="search engines" data-secondary="example build" data-startref="ch07_term8" data-type="indexterm" id="idm45969594643720"/><a contenteditable="false" data-primary="Elasticsearch" data-startref="ch07_term9" data-type="indexterm" id="idm45969594642136"/></p>
</div></section>

<section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="A Case Study: Book Store Search"><div class="sect2" id="a_case_study_book_store_search">
<h2 class="less_space">A Case Study: Book Store Search</h2>

<p><a contenteditable="false" data-primary="search engines" data-secondary="case study" data-type="indexterm" id="ch07_term11"/>Imagine a scenario where we have a new e-commerce store focused on books and we have to build its search pipeline. We have metadata<a contenteditable="false" data-primary="metadata" data-type="indexterm" id="idm45969594558408"/> like author, title, and summary. The search functionality we saw earlier can serve as the baseline at the start. We can set up our own search engine backend or use online services like Elasticsearch [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594556952-marker" href="ch07.xhtml#idm45969594556952">12</a>] or Elastic on Azure<a contenteditable="false" data-primary="Elastic on Azure" data-type="indexterm" id="idm45969594555704"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594554504-marker" href="ch07.xhtml#idm45969594554504">13</a>].</p>

<p>This default search output might have a bunch of issues. For instance, it may show the results with exact query matches in title or summary to be higher than more relevant results that aren’t an exact match. Some of the exact matches might be poorly written books with bad reviews, which we’re not accounting for in our search ranking. For example, consider these two books on Marie Curie: <em>Marie Curie Biography</em> and <em>The Life of Marie Curie</em>. The latter is an authoritative biography on Marie Curie, while the former is a new and poorly reviewed book. But while querying for “marie curie biography,” the less-relevant book, <em>Marie Curie Biography</em>, is ranked higher than the popular <em>The Life of Marie Curie</em>.</p>

<p>We can incorporate real-world metrics that account for this into our search engine. For instance, the number of times a book is viewed and sold, the number of reviews, and the book’s rating can all be incorporated into the search ranking function. In Elasticsearch, this can be done by using function scoring and giving a manually selected weightage to number of ratings, number of books sold, and average rating. So, we might want to give more weightage to books sold than the number of times it was viewed. These heuristics will provide more relevant results as more books get sold and reviewed. This method of manually defining search relevance weights can be a good starting point when there’s no data or the data is limited.</p>

<p>We should start collecting user interactions with the search engine to improve it further. These interactions can include the search query, the kind of user, and their actions on the books. When recording such granular search information, various patterns can be found—for example, when searching for “science books for children,” scientists’ biographies get purchased at a higher rate even when they’re ranked lower. Over time, with increasing amounts of data, we can learn relevance ranking from these logs. We can use a tool like Elasticsearch Learning to Rank<a contenteditable="false" data-primary="Elasticsearch Learning to Rank" data-type="indexterm" id="idm45969594548280"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594547032-marker" href="ch07.xhtml#idm45969594547032">14</a>] to learn this information and improve search relevance. Over time, more advanced techniques like neural embeddings can also be incorporated into search query analysis [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594545400-marker" href="ch07.xhtml#idm45969594545400">15</a>].</p>

<p>As more user information is collected, search results can also be personalized based on the user’s past preferences. Generally, such systems are built as a layer over the initial ranking retrieved from the search engine.</p>

<p>Another point to consider in this journey of building an advanced search engine is how important it is to keep complete control of the system and data. If such a search engine is not a core part of your offering and the organization is comfortable with data sharing, many of these features also come as a managed service. These managed search engine<a contenteditable="false" data-primary="search engines" data-secondary="managed services" data-type="indexterm" id="idm45969594542520"/> services include Algolia<a contenteditable="false" data-primary="Algolia" data-type="indexterm" id="idm45969594541016"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594539784-marker" href="ch07.xhtml#idm45969594539784">16</a>] and  Swiftype<a contenteditable="false" data-primary="Swiftype" data-type="indexterm" id="idm45969594538408"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594537208-marker" href="ch07.xhtml#idm45969594537208">17</a>].</p>

<p>Since the implementation of a search engine involves many other factors beyond NLP and is typically reserved for larger-sized datasets, we’re not showing a running example covering all the aspects of a search engine in this book. However, we hope this short introduction gave you an overview of how to get started developing custom search engines involving textual data and of where the NLP techniques you learned so far may play a role. For more details on implementing search engines with Elasticsearch, refer to [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594534328-marker" href="ch07.xhtml#idm45969594534328">18</a>]. Now, let’s move on to the second topic of this chapter: topic modeling.<a contenteditable="false" data-primary="search" data-startref="ch07_term1" data-type="indexterm" id="idm45969594532424"/><a contenteditable="false" data-primary="information retrieval" data-startref="ch07_term2" data-type="indexterm" id="idm45969594531112"/><a contenteditable="false" data-primary="search engines" data-secondary="case study" data-startref="ch07_term11" data-type="indexterm" id="idm45969594529736"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Topic Modeling"><div class="sect1" id="topic_modeling">
<h1>Topic Modeling</h1>

<p><a contenteditable="false" data-primary="topic modeling" data-type="indexterm" id="ch07_term12"/>Topic modeling is one of the most common applications of NLP in industrial use cases. For analyzing different forms of text from news articles to tweets, from visualizing word clouds (see <a data-type="xref" href="ch08.xhtml#social_media">Chapter 8</a>) to creating graphs of connected topics and documents, topic models are useful for a range of use cases. Topic models are used extensively for document clustering and organizing large collections of text data. They’re also useful for text classification.</p>

<p>But what is topic modeling? Say we’re given a large collection of documents, and we’re asked to “make sense” out of it. What will we do? Clearly, the task is not well defined. Given the large volume of documents, going through each of them manually is not an option. One way to approach it is to bring out some words that best describe the corpus, like the most common words in the corpus. This is called a <em>word cloud</em><a contenteditable="false" data-primary="word clouds" data-type="indexterm" id="idm45969594521912"/>. The key to a good word cloud is to remove stop words. If we take any English text corpus and list out the most frequent k words, we won’t get any meaningful insights, as the most frequent words will be stop words<a contenteditable="false" data-primary="stop words" data-type="indexterm" id="idm45969594520440"/> (the, is, are, am, etc.). After doing appropriate pre-processing, the word cloud may yield some meaningful insights depending on the document collection.</p>

<p>Another approach is to break the documents into words and phrases, then group these words and phrases together based on some notion of similarity between them. The resulting groups of words and phrases can then be used to build some understanding of what the corpus is about. Intuitively, if we pick one word from each group, then the set of selected words represents (in a semantic sense) what the corpus is about. Another possibility is to use TF-IDF<a contenteditable="false" data-primary="TF-IDF (Term Frequency–Inverse Document Frequency)" data-type="indexterm" id="idm45969594518152"/> (See <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a>). Consider a corpus of documents wherein some documents are on farming. Then, terms like “farm,” “crops,” “wheat,” and “agriculture” should form the “topics” in the documents on farming. What’s the easiest way to find these terms that occur frequently in a document but do not occur much in other documents in the corpus?</p>

<p>Topic modeling operationalizes this intuition. It tries to identify the “key” words<a contenteditable="false" data-primary="key words" data-seealso="topics" data-type="indexterm" id="idm45969594515048"/> (called “topics”<a contenteditable="false" data-primary="topics" data-type="indexterm" id="idm45969594513544"/>) present in a text corpus without prior knowledge about it, unlike the rule-based text mining approaches that use regular expressions or dictionary-based keyword searching techniques. <a data-type="xref" href="#figure_7_3_illustration_a_of_topic_mode">Figure 7-3</a> shows a visualization of a topic model’s results for a humanities corpus.</p>

<figure class="width-100"><div id="figure_7_3_illustration_a_of_topic_mode" class="figure"><img alt="Illustration a of topic modeling visualization [_32]" src="Images/pnlp_0703.png" width="682" height="596"/>
<h6><span class="label">Figure 7-3. </span>Illustration a of topic modeling<a contenteditable="false" data-primary="topic modeling" data-secondary="example visualization" data-type="indexterm" id="idm45969594509096"/> visualization [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594507592-marker" href="ch07.xhtml#idm45969594507592">19</a>].</h6>
</div></figure>

<p>In this figure, we see a collection of keywords for individual humanities disciplines—and also how some keywords overlap between disciplines—obtained through a topic model. This is an example of how we can use a topic model to discover what the topics in a large corpus are about. It has to be noted that there’s no single topic model. Topic modeling generally refers to a collection of unsupervised statistical learning methods to discover latent topics in a large collection of text documents. Some of the popular topic modeling algorithms<a contenteditable="false" data-primary="topic modeling" data-secondary="algorithms" data-type="indexterm" id="idm45969594504920"/> are latent Dirichlet allocation (LDA)<a contenteditable="false" data-primary="latent Dirichlet allocation (LDA)" data-type="indexterm" id="ch07_term13"/><a contenteditable="false" data-primary="LDA (latent Dirichlet allocation)" data-type="indexterm" id="ch07_term14"/>, latent semantic analysis (LSA)<a contenteditable="false" data-primary="latent semantic analysis (LSA)" data-type="indexterm" id="idm45969594500456"/><a contenteditable="false" data-primary="LSA (latent semantic analysis)" data-type="indexterm" id="idm45969594499288"/>, and probabilistic latent semantic analysis (PLSA)<a contenteditable="false" data-primary="probabilistic latent semantic analysis (PLSA)" data-type="indexterm" id="idm45969594498040"/><a contenteditable="false" data-primary="PLSA (probabilistic latent semantic analysis)" data-type="indexterm" id="idm45969594496840"/>. In practice, the technique that’s most commonly used is LDA.</p>

<p>What does LDA do? Let’s start with a toy corpus [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594495288-marker" href="ch07.xhtml#idm45969594495288">20</a>]. Say we have a collection of documents, D1 to D5, and each document consists of a single sentence:</p>

<ul class="list_style_type_none">
	<li>
	<p>D1: I like to eat broccoli and bananas.</p>
	</li>
	<li>
	<p>D2: I ate a banana and salad for breakfast.</p>
	</li>
	<li>
	<p>D3: Puppies and kittens are cute.</p>
	</li>
	<li>
	<p>D4: My sister adopted a kitten yesterday.</p>
	</li>
	<li>
	<p>D5: Look at this cute hamster munching on a piece of broccoli.</p>
	</li>
</ul>

<p>Learning a topic model on this collection using LDA may produce an output like this:</p>

<ul class="list_style_type_none">
	<li>
	<p>Topic A: 30% broccoli, 15% bananas, 10% breakfast, 10% munching</p>
	</li>
	<li>
	<p>Topic B: 20% puppies, 20% kittens, 20% cute, 15% hamster</p>
	</li>
</ul>

<ul class="list_style_type_none">
	<li>
	<p>Document 1 and 2: 100% Topic A</p>
	</li>
	<li>
	<p>Document 3 and 4: 100% Topic B</p>
	</li>
	<li>
	<p>Document 5: 60% Topic A, 40% Topic B</p>
	</li>
</ul>

<p>Thus, topics are nothing but a mixture of keywords with a probability distribution, and documents are made up of a mixture of topics, again with a probability distribution. A topic model only gives a collection of keywords per topic. What exactly the topic represents and what it should be named is typically left to human interpretation in an LDA model. Here, we might look at Topic A and say, “it is about food.” Likewise, for topic B, we might say, “it is about pets.”</p>

<p>How does LDA achieve this? LDA assumes that the documents under consideration are produced from a mixture of topics. It further assumes the following process generates these documents: at the start, we have a list of topics with a probability distribution. For every topic, there’s an associated list of words with a probability distribution. We sample <em>k</em> topics from topic distribution. For each of the <em>k</em> topics selected, we sample words from the corresponding distribution. This is how each document in the collection is generated.</p>

<p>Now, given a set of documents, LDA tries to backtrack the generation process and figure out what topics would generate these documents in the first place. The topics are called “latent” because they’re hidden and must be discovered. How does LDA do this backtracking? It does so by factorizing a document-term matrix (M) that keeps count of words across all documents. It has all the <em>m</em> documents D<sub>1</sub>, D<sub>2</sub>, D<sub>3</sub> … D<sub><em>m</em></sub> arranged along the rows and all the <em>n</em> words W<sub>1</sub>,W<sub>2</sub>, ..,W<sub><em>n</em></sub> in the corpus vocabulary arranged as columns. M[<em>i</em>,<em>j</em>] is the frequency count of word W<sub><em>j</em></sub> in Document D<sub><em>i</em></sub>. <a data-type="xref" href="#document_term_matrix_left_parenthesismr">Figure 7-4</a> shows one such matrix for a hypothetical corpus consisting of five documents, with a vocabulary of six words.</p>

<figure><div id="document_term_matrix_left_parenthesismr" class="figure"><img alt="Document-term matrix (M)" src="Images/pnlp_0704.png" width="1117" height="385"/>
<h6><span class="label">Figure 7-4. </span>Document–term matrix (M)</h6>
</div></figure>

<p>Note that if each word in the vocabulary represents a unique dimension and the total vocabulary is of size <em>n</em>, then the <em>i</em><sup>th</sup> row of this matrix is a vector that represents the <em>i</em><sup>th</sup> document in this <em>n</em>-dimensional space. LDA factorizes M into two submatrices: M1 and M2. M1 is a document–topics matrix and M2 is a topic–terms matrix, with dimensions (M, K) and (K, N), respectively. With four topics (K1–K4), the submatrices for M may look like the ones shown in <a data-type="xref" href="#factorized_matrices">Figure 7-5</a>. Here, <em>k</em> is the number of topics we’re interested in finding.<a contenteditable="false" data-primary="latent Dirichlet allocation (LDA)" data-startref="ch07_term13" data-type="indexterm" id="idm45969594426360"/><a contenteditable="false" data-primary="LDA (latent Dirichlet allocation)" data-startref="ch07_term14" data-type="indexterm" id="idm45969594424968"/></p>

<figure><div id="factorized_matrices" class="figure"><img alt="Factorized matrices" src="Images/pnlp_0705.png" width="1117" height="758"/>
<h6><span class="label">Figure 7-5. </span>Factorized matrices</h6>
</div></figure>

<div data-type="tip"><h6>Tip</h6>
<p><em>k</em>, the number of topics, is a hyperparameter. The optimal value for <em>k</em> is found by trial and error.</p>
</div>

<p>These submatrices can then be used to understand the topic structure of a document and the keywords a topic is made up of. Now that we have some idea of what happens behind the scenes when we train a topic model, let’s look at how to build one.</p>

<section data-type="sect2" data-pdf-bookmark="Training a Topic Model: An Example"><div class="sect2" id="training_a_topic_model_an_example">
<h2>Training a Topic Model: An Example</h2>

<p><a contenteditable="false" data-primary="topic modeling" data-secondary="training models" data-type="indexterm" id="ch07_term15"/>We’ve seen the intuition behind LDA. How do we build one ourselves? Here, we’ll use an LDA implementation from the Python library gensim [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594415576-marker" href="ch07.xhtml#idm45969594415576">21</a>] and the CMU Book Summary Dataset [<a data-type="noteref" href="ch07.xhtml#footnote_7_5">11</a>] we used earlier for demonstrating how to create a search engine. The notebook associated with this section (<em>Ch5/TopicModeling.ipynb</em>) contains more details. The following code snippet shows how to train a topic model using LDA:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">nltk.tokenize</code> <code class="kn">import</code> <code class="n">word_tokenize</code>
<code class="kn">from</code> <code class="nn">nltk.corpus</code> <code class="kn">import</code> <code class="n">stopwords</code>
<code class="kn">from</code> <code class="nn">gensim.models</code> <code class="kn">import</code> <code class="n">LdaModel</code>
<code class="kn">from</code> <code class="nn">gensim.corpora</code> <code class="kn">import</code> <code class="n">Dictionary</code>
<code class="kn">from</code> <code class="nn">pprint</code> <code class="kn">import</code> <code class="n">pprint</code>

<code class="c1">#tokenize, remove stopwords, non-alphabetic words, lowercase</code>
<code class="k">def</code> <code class="nf">preprocess</code><code class="p">(</code><code class="n">textstring</code><code class="p">):</code>
   <code class="n">stops</code> <code class="o">=</code>  <code class="nb">set</code><code class="p">(</code><code class="n">stopwords</code><code class="o">.</code><code class="n">words</code><code class="p">(</code><code class="s1">'english'</code><code class="p">))</code>
   <code class="n">tokens</code> <code class="o">=</code> <code class="n">word_tokenize</code><code class="p">(</code><code class="n">textstring</code><code class="p">)</code>
   <code class="k">return</code> <code class="p">[</code><code class="n">token</code><code class="o">.</code><code class="n">lower</code><code class="p">()</code> <code class="k">for</code> <code class="n">token</code> <code class="ow">in</code> <code class="n">tokens</code> <code class="k">if</code> <code class="n">token</code><code class="o">.</code><code class="n">isalpha</code><code class="p">()</code> 
          <code class="ow">and</code> <code class="n">token</code> <code class="ow">not</code> <code class="ow">in</code> <code class="n">stops</code><code class="p">]</code>

<code class="n">data_path</code> <code class="o">=</code> <code class="s2">"/PATH/booksummaries/booksummaries.txt"</code>
<code class="n">summaries</code> <code class="o">=</code> <code class="p">[]</code>
<code class="k">for</code> <code class="n">line</code> <code class="ow">in</code> <code class="nb">open</code><code class="p">(</code><code class="n">data_path</code><code class="p">,</code> <code class="n">encoding</code><code class="o">=</code><code class="s2">"utf-8"</code><code class="p">):</code>
   <code class="n">temp</code> <code class="o">=</code> <code class="n">line</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s2">"</code><code class="se">\t</code><code class="s2">"</code><code class="p">)</code>
   <code class="n">summaries</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">preprocess</code><code class="p">(</code><code class="n">temp</code><code class="p">[</code><code class="mi">6</code><code class="p">]))</code>

<code class="c1"># Create a dictionary representation of the documents.</code>
<code class="n">dictionary</code> <code class="o">=</code> <code class="n">Dictionary</code><code class="p">(</code><code class="n">summaries</code><code class="p">)</code>
<code class="c1"># Filter infrequent or too frequent words.</code>
<code class="n">dictionary</code><code class="o">.</code><code class="n">filter_extremes</code><code class="p">(</code><code class="n">no_below</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code> <code class="n">no_above</code><code class="o">=</code><code class="mf">0.5</code><code class="p">)</code>
<code class="n">corpus</code> <code class="o">=</code> <code class="p">[</code><code class="n">dictionary</code><code class="o">.</code><code class="n">doc2bow</code><code class="p">(</code><code class="n">summary</code><code class="p">)</code> <code class="k">for</code> <code class="n">summary</code> <code class="ow">in</code> <code class="n">summaries</code><code class="p">]</code>
<code class="c1"># Make a index to word dictionary.</code>
<code class="n">temp</code> <code class="o">=</code> <code class="n">dictionary</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>  <code class="c1"># This is only to "load" the dictionary.</code>
<code class="n">id2word</code> <code class="o">=</code> <code class="n">dictionary</code><code class="o">.</code><code class="n">id2token</code>
<code class="c1"># Train the topic model</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">LdaModel</code><code class="p">(</code><code class="n">corpus</code><code class="o">=</code><code class="n">corpus</code><code class="p">,</code> <code class="n">id2word</code><code class="o">=</code><code class="n">id2word</code><code class="p">,</code><code class="n">iterations</code><code class="o">=</code><code class="mi">400</code><code class="p">,</code> <code class="n">num_topics</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>
<code class="n">top_topics</code> <code class="o">=</code> <code class="nb">list</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">top_topics</code><code class="p">(</code><code class="n">corpus</code><code class="p">))</code>
<code class="n">pprint</code><code class="p">(</code><code class="n">top_topics</code><code class="p">)</code></pre>

<p>If we visually inspect the topics, one of them shows words such as police, case, murdered, killed, death, body, etc. While topics themselves will not get names in a topic model, in looking at the keywords, we may infer that this relates to the topic of crime/thriller novels.</p>

<p>How do you evaluate the results? Given the topic–term matrix for LDA, we sort each topic from highest to lowest term weights and then select the first <em>n</em> terms for each topic. We then measure the <em>coherence</em><a contenteditable="false" data-primary="coherence" data-type="indexterm" id="idm45969594407672"/> for terms in each topic, which essentially measures how similar these words are to one another. Additionally, in this example, we made a few choices for the model parameters, such as number of iterations, number of topics, and so on, and did not do any fine-tuning. The notebook associated with this section (<em>Ch7/TopicModeling.ipynb</em>) shows how to evaluate the coherence of topic models.</p>

<p>As with any real-world project, we need to experiment with different parameters and topic models before choosing a final model to deploy. Gensim’s tutorial on LDA<a contenteditable="false" data-primary="gensim library" data-secondary="tutorial on LDA" data-type="indexterm" id="idm45969594230744"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594229240-marker" href="ch07.xhtml#idm45969594229240">22</a>] provides more information on how to build, tune, and evaluate a topic<a contenteditable="false" data-primary="topic modeling" data-secondary="training models" data-startref="ch07_term15" data-type="indexterm" id="idm45969594227912"/> model.</p>

<div data-type="tip"><h6>Tip</h6>
<p>Removing words with low frequency or keeping only those words that are nouns and verbs are some ways of improving a topic model. If the corpus is big, divide it into batches of fixed sizes and run topic modeling for each batch. The best output comes from the intersection of topics from each batch.</p>
</div>
</div></section>

<section data-type="sect2" data-pdf-bookmark="What’s Next?"><div class="sect2" id="whatapostrophes_nextquestion_mark">
<h2>What’s Next?</h2>

<p>Now that we know how to build a topic model, how exactly can we use it? In our experience, some of the use cases for topic models are<a contenteditable="false" data-primary="topic modeling" data-secondary="use cases" data-type="indexterm" id="ch07_term113"/>:</p>

<ul>
	<li>
	<p>Summarizing documents, tweets, etc., in the form of keywords based on learned topic distributions</p>
	</li>
	<li>
	<p>Detecting social media trends over a period of time</p>
	</li>
	<li>
	<p>Designing recommender systems for text</p>
	</li>
</ul>

<p>Also, the distribution of topics for a given document can be used as a feature vector for text classification.</p>

<p>Although there is clearly a range of use cases for topic models in industry projects, there are a few challenges associated with their use. The evaluation and interpretation of topic models is still challenging, and there’s no consensus on it yet. Parameter tuning for topic models can also take a lot of time. In the above example, we provided the number of topics manually. As mentioned previously, there’s no straightforward procedure to know the number of topics; we explore with multiple values based on our estimates about the topics in the dataset. Another thing to keep in mind is that models like LDA typically work only with long documents and perform poorly on short documents, such as a corpus of tweets.</p>

<p>Despite all these challenges, topic models are an important tool in any NLP engineer’s toolbox, and they have a wider reach in terms of where they can be used. We hope we gave you enough information to help you identify its suitable use cases at your workplace. An interested reader can start at [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594215160-marker" href="ch07.xhtml#idm45969594215160">23</a>] to delve deeper into this topic. Let’s move on to the next topic of this chapter: text summarization.<a contenteditable="false" data-primary="topic modeling" data-startref="ch07_term12" data-type="indexterm" id="idm45969594213624"/><a contenteditable="false" data-primary="topic modeling" data-secondary="use cases" data-startref="ch07_term113" data-type="indexterm" id="idm45969594212280"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Text Summarization"><div class="sect1" id="text_summarization">
<h1>Text Summarization</h1>

<p><em>Text summarization</em><a contenteditable="false" data-primary="text summarization" data-type="indexterm" id="ch07_term114"/> refers to the task of creating a summary of a longer piece of text. The goal of this task is to create a coherent summary that captures the key ideas in the text. It’s useful to do a quick read of large documents, store only relevant information, and facilitate better retrieval of information. NLP research on the problem of automatic text summarization was actively pursued by different research groups around the world starting in the early 2000s as a part of the Document Understanding Conference<a contenteditable="false" data-primary="Document Understanding Conference series" data-type="indexterm" id="idm45969594207000"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594205736-marker" href="ch07.xhtml#idm45969594205736">24</a>] series. This series of conferences held competitions to solve several subtasks within the larger realm of text summarization. Some of them are listed below:</p>

<dl>
	<dt>Extractive versus abstractive summarization</dt>
	<dd><a contenteditable="false" data-primary="text summarization" data-secondary="extractive" data-type="indexterm" id="idm45969594202872"/><a contenteditable="false" data-primary="text summarization" data-secondary="abstractive" data-type="indexterm" id="idm45969594201496"/><a contenteditable="false" data-primary="abstractive summarization" data-type="indexterm" id="idm45969594200120"/><a contenteditable="false" data-primary="extractive summarization" data-type="indexterm" id="idm45969594199000"/>Extractive summarization refers to selecting important sentences from a piece of text and showing them together as a summary. Abstractive summarization refers to the task of generating an abstract of the text; i.e., instead of picking sentences from within the text, a new summary is generated.</dd>
	<dt><a contenteditable="false" data-primary="text summarization" data-secondary="query-focused" data-type="indexterm" id="idm45969594197160"/><a contenteditable="false" data-primary="query-focused summarization" data-type="indexterm" id="idm45969594195784"/><a contenteditable="false" data-primary="text summarization" data-secondary="query-independent" data-type="indexterm" id="idm45969594194664"/>Query-focused versus query-independent summarization</dt>
	<dd>Query-focused summarization refers to creating the summary of the text depending on the user query, whereas query-independent summarization creates a general summary.</dd>
	<dt><a contenteditable="false" data-primary="text summarization" data-secondary="single-document" data-type="indexterm" id="idm45969594192216"/><a contenteditable="false" data-primary="text summarization" data-secondary="multi-document" data-type="indexterm" id="idm45969594190840"/><a contenteditable="false" data-primary="multi-document summarization" data-type="indexterm" id="idm45969594189464"/><a contenteditable="false" data-primary="single-document summarization" data-type="indexterm" id="idm45969594188344"/>Single-document versus multi-document summarization</dt>
	<dd>As the names indicate, single-document summarization is the task of creating a summary from a single document, whereas multi-document summarization creates a summary from a collection of documents.</dd>
</dl>

<p>We’ll look at some use cases to help you understand how these can be applied to actual tasks.</p>

<section data-type="sect2" data-pdf-bookmark="Summarization Use Cases"><div class="sect2" id="summarization_use_cases">
<h2>Summarization Use Cases</h2>

<p><a contenteditable="false" data-primary="summarization" data-see="text summarization" data-type="indexterm" id="idm45969594184040"/><a contenteditable="false" data-primary="text summarization" data-secondary="use cases" data-type="indexterm" id="ch07_term20"/>In our experience, the most common use case for text summarization is a single-document, query-independent, extractive summarization. This is typically used to create short summaries of longer documents for human readers or a machine (e.g., in a search engine to index summaries instead of full texts). A well-known example of such a summarizer in action in a real-world product is the autotldr bot on Reddit<a contenteditable="false" data-primary="Reddit autotldr bot" data-type="indexterm" id="idm45969594180456"/><a contenteditable="false" data-primary="autotldr bot (Reddit)" data-type="indexterm" id="idm45969594179352"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594178120-marker" href="ch07.xhtml#idm45969594178120">25</a>], a screenshot of which is shown in <a data-type="xref" href="#screenshot_of_redditapostrophes_autotld">Figure 7-6</a>. The autotldr bot summarizes long Reddit posts by selecting and ranking the most important sentences in the post.</p>

<figure><div id="screenshot_of_redditapostrophes_autotld" class="figure"><img alt="Screenshot of Reddit’s autotldr bot" src="Images/pnlp_0706.png" width="1204" height="738"/>
<h6><span class="label">Figure 7-6. </span>Screenshot of Reddit’s autotldr bot</h6>
</div></figure>

<p>Two other use cases one of the authors implemented in their past workplaces are:</p>

<ul>
	<li>
	<p>An automatic sentence highlighter for news articles that colors “summary” sentences (i.e., sentences that capture the gist of the text) instead of creating full-length summaries.</p>
	</li>
	<li>
	<p>A text summarizer to index only the summaries of documents instead of the full content, with the goal of reducing the size of a search engine’s index.</p>
	</li>
</ul>

<p>You may encounter similar scenarios for implementing a text summarizer at your workplace. Let’s look at an example of how we can leverage existing libraries to implement a single-document, query-independent, extractive<a contenteditable="false" data-primary="text summarization" data-secondary="use cases" data-startref="ch07_term20" data-type="indexterm" id="idm45969594170120"/> summarizer.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Setting Up a Summarizer: An Example"><div class="sect2" id="setting_up_a_summarizer_an_example">
<h2>Setting Up a Summarizer: An Example</h2>

<p><a contenteditable="false" data-primary="text summarization" data-secondary="example setup" data-type="indexterm" id="ch07_term21"/>Research in this area has explored rule-based, supervised, and unsupervised approaches and, more recently, DL-based architectures. However, popular extractive summarization algorithms used in real-world scenarios use a graph-based sentence-ranking approach. Each sentence in a document is given a score based on its relation to other sentences in the text, and this is captured differently in different algorithms. The Top N sentences are then returned as a summary. Sumy<a contenteditable="false" data-primary="Sumy library" data-type="indexterm" id="idm45969594164232"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594163000-marker" href="ch07.xhtml#idm45969594163000">26</a>] is a Python library that contains implementations of several popular query-independent, extractive summarization algorithms. The code snippet below shows an example of how to use sumy’s implementation of a popular summarization algorithm, TextRank<a contenteditable="false" data-primary="TextRank" data-type="indexterm" id="idm45969594161352"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594160184-marker" href="ch07.xhtml#idm45969594160184">27</a>], to summarize a Wikipedia page:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sumy.parsers.html</code> <code class="kn">import</code> <code class="n">HtmlParser</code>
<code class="kn">from</code> <code class="nn">sumy.nlp.tokenizers</code> <code class="kn">import</code> <code class="n">Tokenizer</code>
<code class="kn">from</code> <code class="nn">sumy.summarizers.text_rank</code> <code class="kn">import</code> <code class="n">TextRankSummarizer</code>

<code class="n">url</code> <code class="o">=</code> <code class="s2">"https://en.wikipedia.org/wiki/Automatic_summarization"</code>
<code class="n">parser</code> <code class="o">=</code> <code class="n">HtmlParser</code><code class="o">.</code><code class="n">from_url</code><code class="p">(</code><code class="n">url</code><code class="p">,</code> <code class="n">Tokenizer</code><code class="p">(</code><code class="s2">"english"</code><code class="p">))</code>
<code class="n">summarizer</code> <code class="o">=</code> <code class="n">TextRankSummarizer</code><code class="p">()</code>
<code class="k">for</code> <code class="n">sentence</code> <code class="ow">in</code> <code class="n">summarizer</code><code class="p">(</code><code class="n">parser</code><code class="o">.</code><code class="n">document</code><code class="p">,</code> <code class="mi">5</code><code class="p">):</code>
    <code class="k">print</code><code class="p">(</code><code class="n">sentence</code><code class="p">)</code></pre>

<p>This library takes care of HTML parsing and tokenization for the given URL, then uses TextRank to choose the most important sentences as the summary of the text. Running this code shows the five most important sentences in the Wikipedia page on automatic summarization.</p>

<p>Sumy is not the only library with such implementations of summarization algorithms. Another popular library is gensim<a contenteditable="false" data-primary="gensim library" data-type="indexterm" id="idm45969593978952"/>, which implements an improvised version of TextRank [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969593977896-marker" href="ch07.xhtml#idm45969593977896">28</a>]. The following code snippet shows how to use gensim’s summarizer to summarize a given text:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">gensim.summarization</code> <code class="kn">import</code> <code class="n">summarize</code>
<code class="n">text</code> <code class="o">=</code> <code class="s2">"some text you want to summarize"</code>
<code class="k">print</code><code class="p">(</code><code class="n">summarize</code><code class="p">(</code><code class="n">text</code><code class="p">))</code></pre>

<p>Note that, unlike sumy, gensim<a contenteditable="false" data-primary="gensim library" data-secondary="text summarization with" data-type="indexterm" id="idm45969594116856"/> does not come with an HTML parser, so we’ll have to incorporate an HTML parsing step if we want to parse web pages. Gensim’s summarizer also allows us to experiment with the length of the summaries. We’ll leave the exploration of other summarization algorithms in sumy and further investigation of gensim as exercises for the reader.</p>

<p>So, now<a contenteditable="false" data-primary="text summarization" data-secondary="example setup" data-startref="ch07_term21" data-type="indexterm" id="idm45969594107208"/> we know how to implement a summarizer in our projects. However, there are a few things to keep in mind when using these libraries to deploy a working summarizer. Let’s take a look at some of them based on our experiences with building summarizers for various application scenarios.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Practical Advice"><div class="sect2" id="practical_advice-id00014">
<h2>Practical Advice</h2>
<p>If you encounter<a contenteditable="false" data-primary="text summarization" data-secondary="practical advice" data-type="indexterm" id="ch07_term22"/> a scenario where you have to deploy a summarizer as a product feature, there are a few things to keep in mind. It’s very likely that you’ll use one of the off-the-shelf summarizers like in the example above rather than implementing your own summarizer from scratch. However, if existing algorithms don’t suit your project scenario or if they perform poorly, you may have to develop your own summarizer. A more common reason to work on your own summarizer is if you’re in an R&amp;D organization, working toward pushing the state of the art in summarization systems. So, assuming you’re using off-the-shelf summarizers, how do you compare the multiple summarization algorithms available and choose the one that works best for your use case?</p>

<p>In research, summarization approaches are evaluated using a common dataset of reference summaries created by humans. Recall-Oriented Understudy for Gisting Evaluation (ROUGE)<a contenteditable="false" data-primary="Recall-Oriented Understudy for Gisting Evaluation (ROUGE)" data-type="indexterm" id="idm45969594099976"/><a contenteditable="false" data-primary="ROUGE (Recall-Oriented Understudy for Gisting Evaluation)" data-type="indexterm" id="idm45969594098904"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969594097704-marker" href="ch07.xhtml#idm45969594097704">29</a>] is a common set of metrics based on n-gram overlaps used for evaluating automatic summarization systems. However, such datasets may or may not suit your exact use case. Hence, the best way to compare different approaches is to create your own evaluation set or ask human annotators to rate the summaries produced by different algorithms in terms of coherence, accuracy of the summary, etc.</p>

<p>There are a few practical issues to keep in mind when deploying a summarizer:</p>

<ul>
	<li>
	<p>Pre-processing steps like sentence splitting (or HTML parsing in the above example) play a very important role in what comes out as output summary. Most libraries have built-in sentence splitters, but even those can do erroneous sentence splitting for different input data (e.g., what if there’s a news article with a letter quoted in the middle?). To our knowledge, there’s no one-stop solution for such issues, and you may need to develop custom solutions for the data formats you encounter in your project.</p>
	</li>
	<li>
	<p>Most summarization algorithms are sensitive to the size of the text given as input. For example, TextRank<a contenteditable="false" data-primary="TextRank" data-type="indexterm" id="idm45969594092904"/> runs in polynomial time, so it can easily take up a lot of computing time to generate summaries for larger pieces of text. You need to be aware of this limitation when using a summarizer with very large texts. A workaround could be to run the summarizer on partitions of the large text and stringing the summaries together. Another alternative could be to run the summarizer on the top M% and bottom N% of the text instead of the whole text (assuming that these parts contain the gist of a long document).</p>
	</li>
</ul>

<div data-type="tip"><h6>Tip</h6>
<p>Summarizers are sensitive to text length. So, it may make sense to run a summarizer on selected parts of the text.</p>
</div>

<p>So far, we’ve only seen examples of extractive summarization<a contenteditable="false" data-primary="extractive summarization" data-type="indexterm" id="idm45969594088984"/><a contenteditable="false" data-primary="text summarization" data-secondary="extractive" data-type="indexterm" id="idm45969594087912"/>. In comparison, abstractive summarization<a contenteditable="false" data-primary="abstractive summarization" data-type="indexterm" id="idm45969594086408"/><a contenteditable="false" data-primary="text summarization" data-secondary="abstractive" data-type="indexterm" id="idm45969593932200"/> is more of a research topic than a practical application. Three interesting use cases that come up frequently in abstractive summarization research are: news headline generation, news summary generation, and question answering. Deep learning and reinforcement learning approaches have shown some promising results for abstractive summarization in the recent past [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969593930472-marker" href="ch07.xhtml#idm45969593930472">30</a>]. Because this topic has so far been primarily a research bastion and is restricted to academics and organizations with dedicated AI teams, we won’t discuss it in further detail in this book. However, we hope this discussion gave you enough of an overview about summarization to get started with an MVP in case you need one. Now, let’s take a look at another interesting problem where NLP is useful: offering recommendations for textual data.<a contenteditable="false" data-primary="text summarization" data-startref="ch07_term114" data-type="indexterm" id="idm45969593928312"/><a contenteditable="false" data-primary="text summarization" data-secondary="practical advice" data-startref="ch07_term22" data-type="indexterm" id="idm45969593926968"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Recommender Systems for Textual Data"><div class="sect1" id="recommender_systems_for_textual_data">
<h1>Recommender Systems for Textual Data</h1>

<p><a contenteditable="false" data-type="indexterm" data-primary="textual data" id="ch07_term80"/><a contenteditable="false" data-primary="recommender systems" data-type="indexterm" id="ch07_term23"/>We’re all familiar with seeing related searches, related news articles, related jobs, related products, and other such features on the various websites we browse in our day-to-day lives, and it’s not unusual for clients to request them. How do these “related texts” features work?</p>

<p>News articles, job descriptions, product descriptions, and search queries all contain a lot of text. Hence, textual content and the similarities or relatedness between different texts is important to consider when developing recommender systems for textual data. A common approach to building recommendation systems is a method called <em>collaborative filtering</em><a contenteditable="false" data-primary="collaborative filtering" data-type="indexterm" id="idm45969593919560"/><a contenteditable="false" data-primary="filtering, collaborative" data-type="indexterm" id="idm45969593918456"/>. It shows recommendations to users based on their past history and on what users with similar profiles preferred in the past. For example, Netflix<a contenteditable="false" data-primary="Netflix" data-type="indexterm" id="idm45969593917048"/> recommendations use this type of approach at a large scale.</p>

<p>In contrast, there are content-based recommendation systems. An example of one such recommendation is the “related articles” feature on newspaper websites. Look at an example from CBC, a Canadian news website, shown in <a data-type="xref" href="#screenshot_showing_the_related_stories">Figure 7-7</a>.</p>



<p>Below the article text, we see a collection of related stories that are topically similar to the source article, which is titled “How Desmond Cole wrote a bestselling book about being black in Canada.” As you can see, the related stories cover black history and racism in Canada and list another article about Desmond Cole. How do we build such a feature based on content similarity among texts? One approach to building such a content-based recommendation system is to use a topic model like we saw earlier in this chapter. Texts similar to the current text in terms of topic distribution can be shown as “related” texts. However, the advent of neural text representations has changed the ways we can show such recommendations. Let’s take a look at how we can use a neural text representation to show related text recommendations<a contenteditable="false" data-primary="text recommendations" data-see="recommendations" data-type="indexterm" id="idm45969593912904"/>.</p>

<figure><div id="screenshot_showing_the_related_stories" class="figure"><img alt="Screenshot showing the related stories feature on cbc.ca [_29]" src="Images/pnlp_0707.png" width="624" height="517"/>
<h6><span class="label">Figure 7-7. </span>Screenshot showing the related stories feature on cbc.ca [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969593909576-marker" href="ch07.xhtml#idm45969593909576">31</a>]</h6>
</div></figure>

<section data-type="sect2" data-pdf-bookmark="Creating a Book Recommender System: An Example"><div class="sect2" id="creating_a_book_recommender_system_an_e">
<h2>Creating a Book Recommender System: An Example</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="recommender systems" data-secondary="examples" id="ch07_term78"/><a contenteditable="false" data-type="indexterm" data-primary="recommender systems" data-secondary="creating" id="ch07_term77"/>We’ve seen a few examples of neural network–based text representations (<a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a>) and how some of them can be useful for text classification (<a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>). One of the representations we saw was Doc2vec. The following code snippet shows how to use Doc2vec<a contenteditable="false" data-primary="Doc2vec model" data-secondary="serving recommendations with" data-type="indexterm" id="ch07_term25"/> for serving related book recommendations using the CMU Book Summary Dataset we used earlier in this chapter for topic modeling and the Python libraries NLTK (for tokenization) and gensim (for Doc2vec implementation):</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">nltk.tokenize</code> <code class="kn">import</code> <code class="n">word_tokenize</code>
<code class="kn">from</code> <code class="nn">gensim.models.doc2vec</code> <code class="kn">import</code> <code class="n">Doc2Vec</code><code class="p">,</code> <code class="n">TaggedDocument</code>

<code class="c1"># Read the dataset’s README to understand the data format.</code>
<code class="n">data_path</code> <code class="o">=</code> <code class="s2">"/DATASET_FOLDER_PATH/booksummaries.txt"</code>
<code class="n">mydata</code> <code class="o">=</code> <code class="p">{}</code> <code class="c1">#titles-summaries dictionary object</code>
<code class="k">for</code> <code class="n">line</code> <code class="ow">in</code> <code class="nb">open</code><code class="p">(</code><code class="n">data_path</code><code class="p">,</code> <code class="n">encoding</code><code class="o">=</code><code class="s2">"utf-8"</code><code class="p">):</code>
    <code class="n">temp</code> <code class="o">=</code> <code class="n">line</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s2">"</code><code class="se">\t</code><code class="s2">"</code><code class="p">)</code>
    <code class="n">mydata</code><code class="p">[</code><code class="n">temp</code><code class="p">[</code><code class="mi">2</code><code class="p">]]</code> <code class="o">=</code> <code class="n">temp</code><code class="p">[</code><code class="mi">6</code><code class="p">]</code>

<code class="c1"># Prepare the data for doc2vec, build and save a doc2vec model.</code>
<code class="n">d2vtrain</code> <code class="o">=</code> <code class="p">[</code><code class="n">TaggedDocument</code><code class="p">((</code><code class="n">word_tokenize</code><code class="p">(</code><code class="n">mydata</code><code class="p">[</code><code class="n">t</code><code class="p">])),</code> <code class="n">tags</code><code class="o">=</code><code class="p">[</code><code class="n">t</code><code class="p">])</code> 
                          <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">mydata</code><code class="o">.</code><code class="n">keys</code><code class="p">()]</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">Doc2Vec</code><code class="p">(</code><code class="n">vector_size</code><code class="o">=</code><code class="mi">50</code><code class="p">,</code> <code class="n">alpha</code><code class="o">=</code><code class="mf">0.025</code><code class="p">,</code> <code class="n">min_count</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code> <code class="n">dm</code> <code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">epochs</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code>
<code class="n">model</code><code class="o">.</code><code class="n">build_vocab</code><code class="p">(</code><code class="n">train_doc2vec</code><code class="p">)</code>
<code class="n">model</code><code class="o">.</code><code class="n">train</code><code class="p">(</code><code class="n">train_doc2vec</code><code class="p">,</code> <code class="n">total_examples</code><code class="o">=</code><code class="n">model</code><code class="o">.</code><code class="n">corpus_count</code><code class="p">,</code> 
  <code class="n">epochs</code><code class="o">=</code><code class="n">model</code><code class="o">.</code><code class="n">epochs</code><code class="p">)</code>
<code class="n">model</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="s2">"d2v.model"</code><code class="p">)</code>

<code class="c1"># Use the model to look for similar texts.</code>
<code class="n">model</code><code class="o">=</code> <code class="n">Doc2Vec</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="s2">"d2v.model"</code><code class="p">)</code>

<code class="c1"># This is a sentence from the summary of “Animal Farm” on Wikipedia:</code>
<code class="c1"># https://en.wikipedia.org/wiki/Animal_Farm</code>
<code class="n">sample</code> <code class="o">=</code> <code class="s2">"""</code>
<code class="s2">Napoleon enacts changes to the governance structure of the farm, replacing</code>
<code class="s2">meetings with a committee of pigs who will run the farm.</code>
<code class="s2"> """</code>
<code class="n">new_vector</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">infer_vector</code><code class="p">(</code><code class="n">word_tokenize</code><code class="p">(</code><code class="n">sample</code><code class="p">))</code>
<code class="n">sims</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">docvecs</code><code class="o">.</code><code class="n">most_similar</code><code class="p">([</code><code class="n">new_vector</code><code class="p">])</code> <code class="c1">#gives 10 most similar titles</code>
<code class="k">print</code><code class="p">(</code><code class="n">sims</code><code class="p">)</code></pre>

<p>This prints the output as:</p>

<pre data-type="programlisting">
[('Animal Farm', 0.6960548758506775), ("Snowball's Chance", 0.6280543208122253), 
('Ponni', 0.583295464515686), ('Tros of Samothrace', 0.5764356255531311), 
('Payback: Debt and the Shadow Side of Wealth', 0.5714253783226013),
('Settlers in Canada', 0.5685930848121643), ('Stone Tables', 
0.5614138245582581), ('For a New Liberty: The Libertarian Manifesto', 
0.5510331988334656), ('The God Boy', 0.5497804284095764), 
('Snuff', 0.5480046272277832)]</pre>

<p>Note that we just tokenized the text in this example and did not do any other pre-processing, nor did we do any model tuning. This is just an example of how we can approach the development of a recommendation system, not a detailed analysis. More recent approaches to implementing such systems use BERT or other such models to calculate document similarity. We also briefly mentioned text similarity–based search options in Elasticsearch earlier in this section; that’s another option for implementing a recommender system for our use case. We’ll leave exploring them further as an exercise for the reader.</p>

<p>Now that<a contenteditable="false" data-type="indexterm" data-primary="recommender systems" data-secondary="creating" data-startref="ch07_term77" id="idm45969593726680"/><a contenteditable="false" data-type="indexterm" data-primary="recommender systems" data-secondary="examples" data-startref="ch07_term78" id="idm45969593725032"/> we have an idea of how to build a recommendation system for textual data, let’s take a look at some practical advice for building such recommendation systems based on our past experiences.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Practical Advice"><div class="sect2" id="practical_advice-id00015">
<h2>Practical Advice</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="recommender systems" data-secondary="practical advice" id="ch07_term79"/>We just saw a simple example of a textual recommendation system. This kind of approach will work for some use cases, such as recommending related news articles. However, we may have to consider aspects beyond text in many applications where we need to provide more personalized recommendations or where other non-textual aspects of the item need to be considered. An example of such a case is similar listing recommendations in Airbnb<a contenteditable="false" data-primary="Airbnb" data-type="indexterm" id="idm45969593719016"/>, where they combine embedding-based neural text <span class="keep-together">representations</span> with other information, such as location, price, etc., to provide personalized recommendations [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969593716984-marker" href="ch07.xhtml#idm45969593716984">32</a>].</p>

<p>How do we know our recommendation system is working? In a real-world project, the impact of recommendations can be measured by performance indicators, such as user click-through rates, conversion into a purchase (if relevant), customer engagement on the website, etc. A/B tests<a contenteditable="false" data-primary="A/B testing" data-type="indexterm" id="idm45969593714360"/> where different groups of users are exposed to different recommendations are used to compare these performance indicators. A third (and perhaps more time consuming) way is to conduct carefully designed user studies where participants are shown specific recommendations and asked to rate them. Finally, if we have a small test set with appropriate recommendations for a given item, we can evaluate a recommendation system by comparing it to this test set. In our experience, a combination of these indicators, along with an analytics platform like Google Analytics<a contenteditable="false" data-primary="Google Analytics" data-type="indexterm" id="idm45969593712552"/>, is used in evaluating industry-scale recommendation systems.</p>

<p>Last but not least, our pre-processing decisions play a significant role in the recommendations served by our system. So, we need to know what we want before going ahead with an approach. In the example above, we just did plain tokenization. In the real world, it’s not uncommon to see lowercasing, removal of special characters, etc., as parts of the pre-processing pipeline.</p>

<p>This<a contenteditable="false" data-type="indexterm" data-primary="textual data" data-startref="ch07_term80" id="idm45969593710088"/> concludes our overview of text recommendation systems. We hope this provides you enough information to identify suitable use cases at your workplace and build recommendation systems for them. Let’s move to the next topic of this chapter: machine<a contenteditable="false" data-primary="recommender systems" data-startref="ch07_term23" data-type="indexterm" id="idm45969593708280"/><a contenteditable="false" data-type="indexterm" data-primary="recommender systems" data-secondary="practical advice" data-startref="ch07_term79" id="idm45969593706904"/> translation.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Machine Translation"><div class="sect1" id="machine_translation">
<h1>Machine Translation</h1>

<p><a contenteditable="false" data-primary="machine translation (MT)" data-type="indexterm" id="ch07_term27"/><a contenteditable="false" data-primary="translation" data-see="machine translation" data-type="indexterm" id="idm45969593701912"/>Machine translation (MT)—translating text from one language to another automatically—is one of the original problems of NLP research. Early MT systems employed rule-based approaches that required a lot of linguistic knowledge, including the grammars of source and target languages, to be explicitly coded along with resources like dictionaries between languages. This was followed by several years of research and application development using statistical methods that relied on the existence of lots and lots of parallel data between languages. Such datasets were usually collected from resources where texts were translated into multiple languages, such as European parliamentary proceedings. The past five years have seen explosive growth in DL-based neural MT approaches, which have become the state of the art in both research and production-scale MT systems. Google Translate<a contenteditable="false" data-primary="Google Translate" data-type="indexterm" id="idm45969593699512"/> is a popular example. However, owing to the amount of data and resources required to build them, research and development of such systems has been primarily the bastion of large organizations.</p>

<p>Clearly, MT is a large research area, and building MT systems seems like a large effort. Where is MT useful in the industry? Here are two example scenarios where MT may be required to develop solutions<a contenteditable="false" data-primary="machine translation (MT)" data-secondary="use cases" data-type="indexterm" id="idm45969593697432"/>:</p>

<ul>
	<li>
	<p>Our client’s products are used by people around the world who leave reviews on social media in multiple languages. Our client wants to know the general sentiment of those reviews. For this, instead of looking for sentiment analysis tools in multiple languages, one option is to use an MT system, translate all the reviews into one language, and run sentiment analysis for that language.</p>
	</li>
	<li>
	<p>We work with a lot of social media data (e.g., tweets) on a regular basis and notice that it’s unlike the kind of text we encounter in typical text documents. For example, consider the sentence, “am gud,” which, in formal, well-formed English is, “I am good.” (More details on how social media text differs from normal, well-formed text are in <a data-type="xref" href="ch08.xhtml#social_media">Chapter 8</a>.) MT can be used to map these two sentences by treating the conversion from “am gud” to “I am good” as an informal-to-grammatical English translation problem.</p>
	</li>
</ul>

<p>While we may or may not develop our own MT systems, there are many scenarios where we may need to implement an MT solution in our NLP projects. [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969593691272-marker" href="ch07.xhtml#idm45969593691272">33</a>] discusses some of the industry use cases of MT. So what should we do, then, if we face a similar situation? Let’s look at an example of how to set up an MT system in our project.</p>

<section data-type="sect2" data-pdf-bookmark="Using a Machine Translation API: An Example"><div class="sect2" id="using_a_machine_translation_api_an_exam">
<h2>Using a Machine Translation API: An Example</h2>

<p><a contenteditable="false" data-primary="translation APIs" data-type="indexterm" id="ch07_term227"/><a contenteditable="false" data-primary="APIs" data-secondary="MT" data-type="indexterm" id="ch07_term226"/><a contenteditable="false" data-primary="machine translation (MT)" data-secondary="with APIs" data-secondary-sortas="APIs" data-type="indexterm" id="ch07_term225"/>Building an MT system from scratch is a time- and resource-consuming exercise. A more common way to set up an MT system for a project is to use one of the pay-per-use translation services APIs provided by large research organizations such as Google<a contenteditable="false" data-primary="Google Translate" data-type="indexterm" id="idm45969593682680"/><a contenteditable="false" data-type="indexterm" data-primary="Google APIs" id="idm45969593681576"/> or Microsoft<a contenteditable="false" data-primary="Microsoft" data-secondary="translation API" data-type="indexterm" id="idm45969593680344"/>, which are powered by state-of-the-art neural MT models. The following code snippet shows how to use the Bing Translate API<a contenteditable="false" data-primary="Bing Translate API" data-type="indexterm" id="idm45969593678664"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969593677432-marker" href="ch07.xhtml#idm45969593677432">34</a>] (after obtaining the subscription key and the endpoint URL by registering) to translate from English to German:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code> <code class="nn">os</code><code class="o">,</code> <code class="nn">requests</code><code class="o">,</code> <code class="nn">uuid</code><code class="o">,</code> <code class="nn">json</code>

<code class="n">subscription_key</code> <code class="o">=</code> <code class="s2">"XXXXX"</code>
<code class="n">endpoint</code> <code class="o">=</code> <code class="s2">"YYYYY"</code>
<code class="n">path</code> <code class="o">=</code> <code class="s1">'/translate?api-version=3.0'</code>
<code class="n">params</code> <code class="o">=</code> <code class="s1">'&amp;to=de'</code> <code class="c1">#From English to German (de)</code>
<code class="n">constructed_url</code> <code class="o">=</code> <code class="n">endpoint</code> <code class="o">+</code> <code class="n">path</code> <code class="o">+</code> <code class="n">params</code>

<code class="n">headers</code> <code class="o">=</code> <code class="p">{</code>
    <code class="s1">'Ocp-Apim-Subscription-Key'</code><code class="p">:</code> <code class="n">subscription_key</code><code class="p">,</code>
    <code class="s1">'Content-type'</code><code class="p">:</code> <code class="s1">'application/json'</code><code class="p">,</code>
    <code class="s1">'X-ClientTraceId'</code><code class="p">:</code> <code class="nb">str</code><code class="p">(</code><code class="n">uuid</code><code class="o">.</code><code class="n">uuid4</code><code class="p">())</code>
<code class="p">}</code>

<code class="n">body</code> <code class="o">=</code> <code class="p">[{</code><code class="s1">'text'</code> <code class="p">:</code> <code class="s1">'How good is Machine Translation?'</code><code class="p">}]</code>
<code class="n">request</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">post</code><code class="p">(</code><code class="n">constructed_url</code><code class="p">,</code> <code class="n">headers</code><code class="o">=</code><code class="n">headers</code><code class="p">,</code> <code class="n">json</code><code class="o">=</code><code class="n">body</code><code class="p">)</code>
<code class="n">response</code> <code class="o">=</code> <code class="n">request</code><code class="o">.</code><code class="n">json</code><code class="p">()</code>

<code class="k">print</code><code class="p">(</code><code class="n">json</code><code class="o">.</code><code class="n">dumps</code><code class="p">(</code><code class="n">response</code><code class="p">,</code> <code class="n">sort_keys</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">indent</code><code class="o">=</code><code class="mi">4</code><code class="p">,</code> <code class="n">separators</code><code class="o">=</code><code class="p">(</code><code class="s1">','</code><code class="p">,</code> <code class="s1">': '</code><code class="p">)))</code></pre>

<p>This example requests a translation of the sentence “How good is Machine Translation?” from English to German. The output in JSON format is shown below:</p>
<!--
<p>[Json]</p>
-->
<pre data-type="programlisting" data-code-language="json">
<code class="p">[</code>
    <code class="p">{</code>
    <code class="nt">"detectedLanguage"</code><code class="p">:</code> <code class="p">{</code>
          <code class="nt">"language"</code><code class="p">:</code> <code class="s2">"en"</code><code class="p">,</code>
          <code class="nt">"score"</code><code class="p">:</code> <code class="mf">1.0</code>
    <code class="p">},</code>
    <code class="nt">"translations"</code><code class="p">:</code> <code class="p">[</code>
          <code class="p">{</code>
               <code class="nt">"text"</code><code class="p">:</code> <code class="s2">"Wie gut ist maschinelle Übersetzung?"</code><code class="p">,</code>
               <code class="nt">"to"</code><code class="p">:</code> <code class="s2">"de"</code>
          <code class="p">}</code>
    <code class="p">]</code>
    <code class="p">}</code>
<code class="p">]</code></pre>

<p>This shows the translated sentence in German as “Wie gut ist maschinelle Übersetzung?” We can use the service as we need it by calling the Bing Translate API. Similar setups exist for other providers of such services. Before concluding this topic, let’s take a look at some practical advice for readers who want to incorporate MT into an NLP project.<a contenteditable="false" data-primary="machine translation (MT)" data-secondary="with APIs" data-secondary-sortas="APIs" data-startref="ch07_term225" data-type="indexterm" id="idm45969590331016"/><a contenteditable="false" data-primary="APIs" data-secondary="MT" data-startref="ch07_term226" data-type="indexterm" id="idm45969610353224"/><a contenteditable="false" data-primary="translation APIs" data-startref="ch07_term227" data-type="indexterm" id="idm45969610387848"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Practical Advice"><div class="sect2" id="practical_advice-id00016">
<h2>Practical Advice</h2>

<p><a contenteditable="false" data-primary="machine translation (MT)" data-secondary="practical advice" data-type="indexterm" id="ch07_term28"/>First, as we explained earlier, don’t build your own MT system if you don’t have to. It’s more practical to make use of translation APIs. When using such APIs, it’s important to pay close attention to pricing policies. Considering the costs involved, it might be a good idea to store the translations of frequently used text (called a translation memory<a contenteditable="false" data-primary="translation memory" data-type="indexterm" id="idm45969610224440"/> or a translation cache<a contenteditable="false" data-primary="translation cache" data-type="indexterm" id="idm45969610196872"/>).</p>

<div data-type="tip"><h6>Tip</h6>
<p>Maintain a translation memory, which can be used for translations that repeat frequently.</p>
</div>

<p>When working with an entirely new language, or, say, a new domain where existing translation APIs do poorly, it makes sense to start with a domain knowledge–based, rule-based translation system addressing the restricted scenario we’re dealing with. Another approach to addressing such data-scarce scenarios is to augment our <span class="keep-together">training</span> data by doing “back translation<a contenteditable="false" data-primary="back translation" data-type="indexterm" id="idm45969610153976"/>.” Let’s say we want to translate from English<a contenteditable="false" data-primary="English" data-type="indexterm" id="idm45969610199560"/> to the Navajo language. English is a popular language for MT, while Navajo<a contenteditable="false" data-primary="Navajo" data-type="indexterm" id="idm45969610096152"/> is not, but we do have a few examples of English–Navajo translation. In such a case, we can build an MT model between Navajo and English, then use this system to translate a few Navajo sentences into English. At this point, these machine-translated Navajo–English pairs can be added as additional training data to the English–Navajo MT system. This results in a translation system with more examples to train on (even though some of these examples are synthetic). In general, though, if accuracy of translation is paramount, it might make sense to form a hybrid MT system that combines the neural models with rules and some form of post-processing.</p>

<div data-type="tip"><h6>Tip</h6>
<p>Data augmentation is a useful approach to collect more training data for building an MT system.</p>
</div>

<p>MT is a large area of research with dedicated annual conferences, journals, and data-driven competitions where academics and industry groups involved in MT research compete and evaluate their systems. We’ve only scratched the surface to give you some idea about the topic. A collection of learning materials on MT [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610105096-marker" href="ch07.xhtml#idm45969610105096">35</a>] are available for readers interested in further study. With this overview of MT, let’s move on to the next topic of this chapter: question-answering systems.<a contenteditable="false" data-primary="machine translation (MT)" data-startref="ch07_term27" data-type="indexterm" id="idm45969610109416"/><a contenteditable="false" data-primary="machine translation (MT)" data-secondary="practical advice" data-startref="ch07_term28" data-type="indexterm" id="idm45969610112312"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Question-Answering Systems"><div class="sect1" id="question_answering_systems">
<h1>Question-Answering Systems</h1>

<p><a contenteditable="false" data-primary="question-answering (QA) systems" data-type="indexterm" id="ch07_term29"/>When searching online with a search engine such as Google<a contenteditable="false" data-primary="Google" data-secondary="search engine" data-type="indexterm" id="idm45969610130856"/> or Bing<a contenteditable="false" data-primary="Bing (search engine)" data-type="indexterm" id="idm45969610137672"/>, for some of the queries, we see “answers” along with a bunch of search results. These answers can be a few words or a listing or definition. In <a data-type="xref" href="ch05.xhtml#information_extraction">Chapter 5</a>, we saw some examples of one such query to illustrate named entity recognition’s role in search. Let’s now go a little bit farther than that. Consider the screenshot in <a data-type="xref" href="#screenshot_for_the_query_quotation_mark">Figure 7-8</a> from Google search for the query “who invented penicillin.”</p>

<figure><div id="screenshot_for_the_query_quotation_mark" class="figure"><img alt="Screenshot for the query “who invented penicillin?”" src="Images/pnlp_0708.png" width="1156" height="692"/>
<h6><span class="label">Figure 7-8. </span>Screenshot for the query “who invented penicillin”</h6>
</div></figure>

<p>Here, the search engine performs an additional task of question answering along with information retrieval. If we follow the search engine pipeline described earlier with the aim of answering such a question, the processing steps look like the ones shown in <a data-type="xref" href="#answer_extraction">Figure 7-9</a>.</p>



<p>Clearly, NLP plays an important role in understanding the user query, deciding what kind of question it is and what kind of answer is needed, and identifying where the answers are in a given document after retrieving documents relevant to the query.</p>

<p>While this is an example of a large, generic search engine, we may also encounter scenarios where we have to implement a question-answering system for internal consumption, using a company’s data or some other custom setting. Following the pipeline approach mentioned earlier in <a data-type="xref" href="#search_and_information_retrieval">“Search and Information Retrieval”</a> can lead us toward a solution in such cases.</p>

<p>There may be other relatively simpler scenarios of question answering in the workplace, too. A common scenario is an FAQ-answering system. We saw how this works in <a data-type="xref" href="ch06.xhtml#chatbots">Chapter 6</a>. Let’s briefly discuss one more scenario, based on one of the author’s past experiences at their workplace.</p>

<figure><div id="answer_extraction" class="figure"><img alt="Answer extraction" src="Images/pnlp_0709.png" width="986" height="1163"/>
<h6><span class="label">Figure 7-9. </span>Answer extraction<a contenteditable="false" data-primary="answer extraction" data-type="indexterm" id="idm45969610056728"/></h6>
</div></figure>

<section data-type="sect2" data-pdf-bookmark="Developing a Custom Question-Answering System"><div class="sect2" id="developing_a_custom_question_answering">
<h2>Developing a Custom Question-Answering System</h2>

<p><a contenteditable="false" data-primary="question-answering (QA) systems" data-secondary="developing" data-type="indexterm" id="idm45969592632728"/>Let’s say we’re asked to develop a question-answering system that answers all user questions about computers. We’ve identified a few websites with question-and-answer discussions (e.g., Stack Overflow) and have a crawler in place. At this point, how can we get started with the first version of the question-answering system? One way to build an MVP is to start looking at the markup structure of the websites. Generally, the questions and answers are distinguished using different HTML elements. Collecting this information and using it specifically to build an index of question–answer pairs will get us started on a question-answering system for this task. The next step could be using text embeddings and performing a similarity-based search using Elasticsearch.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Looking for Deeper Answers"><div class="sect2" id="looking_for_deeper_answers">
<h2>Looking for Deeper Answers</h2>

<p>In the approaches described above, we would still expect the user question to have a significant amount of exact overlap with the indexed question and answer. However, DL-based text embeddings, which we’ve seen in different chapters throughout this book so far, are capable of going beyond exact matches and capturing semantic similarities. Such a neural question-answering approach looks for the answer span in a text by comparing the question’s embedding with that of the text’s subunits (words, sentences, and paragraphs). Question answering using deep neural networks<a contenteditable="false" data-primary="deep neural networks" data-type="indexterm" id="idm45969611257544"/><a contenteditable="false" data-primary="question answering (QA)" data-secondary="with deep neural networks" data-secondary-sortas="deep neural networks" data-type="indexterm" id="idm45969611215000"/> is very much an active area of research and is typically studied as a supervised ML problem using specific datasets designed for this task, such as the SQuAD<a contenteditable="false" data-primary="SQuAD dataset" data-type="indexterm" id="idm45969611157896"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610252600-marker" href="ch07.xhtml#idm45969610252600">36</a>] dataset. DeepQA<a contenteditable="false" data-primary="DeepQA library" data-type="indexterm" id="idm45969610245576"/><a contenteditable="false" data-primary="AllenNLP" data-secondary="DeepQA library" data-type="indexterm" id="idm45969611160408"/>, which is a part of Allen NLP [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610414408-marker" href="ch07.xhtml#idm45969610414408">37</a>], is a popular library for developing experimental question-answering systems using DL architectures.</p>

<p>Another approach to question answering is knowledge-based question answering<a contenteditable="false" data-primary="knowledge-based question answering" data-type="indexterm" id="idm45969610300536"/><a contenteditable="false" data-primary="question answering (QA)" data-secondary="knowledge-based" data-type="indexterm" id="idm45969610338344"/>, which relies on the presence of a huge knowledge database and a way to map user queries to the database. This is typically used for answering short, factual questions. Real-world question-answering systems like IBM Watson<a contenteditable="false" data-primary="IBM Watson" data-type="indexterm" id="idm45969593038536"/>, which beat human participants in the popular quiz show <em>Jeopardy!<a contenteditable="false" data-primary="Jeopardy!" data-type="indexterm" id="idm45969593632104"/></em>, use a combination of both approaches. Bing Answer Search API<a contenteditable="false" data-primary="Bing Answer Search API" data-type="indexterm" id="idm45969592075176"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969590192088-marker" href="ch07.xhtml#idm45969590192088">38</a>], which allows subscribed users to query the system for answers, is an example of a research system that follows such a hybrid approach.</p>

<p>Developing any such question-answering system that can model deeper knowledge at web scale requires a substantial amount of data and computing resources coupled with a lot of experimentation. It’s not yet a common scenario in a typical software company working on NLP projects, so we won’t discuss it further in this book. To get a historical overview of question answering along with the most recent developments in research, we recommend reading Chapter 25 of the upcoming edition of the popular NLP textbook, <em>Speech and Language Processing</em> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969593247208-marker" href="ch07.xhtml#idm45969593247208">39</a>]. If you want to implement a DL-based <a contenteditable="false" data-primary="question-answering (QA) systems" data-secondary="DL-based" data-type="indexterm" id="idm45969593633880"/><a contenteditable="false" data-primary="deep learning (DL)" data-secondary="question answering with" data-type="indexterm" id="idm45969593233448"/>question-answering system for your own dataset (e.g., internal documents in an organization), libraries such as CDQA-Suite<a contenteditable="false" data-primary="CDQA-Suite library" data-type="indexterm" id="idm45969593231800"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969593262392-marker" href="ch07.xhtml#idm45969593262392">40</a>] provide the backbone to get started.</p>

<p>As can be seen from this discussion, question answering is an area of search that has a wide-ranging array of solutions, ranging from simple and straightforward approaches like extracting markup, to complex, DL-based solutions. We hope this overview provided you with enough examples of the use cases you may encounter in your workplace to develop question-answering systems.<a contenteditable="false" data-primary="question-answering (QA) systems" data-startref="ch07_term29" data-type="indexterm" id="idm45969593260472"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Wrapping Up"><div class="sect1" id="wrapping_up-id00081">
<h1>Wrapping Up</h1>

<p>In this chapter, we saw how NLP plays a role in a range of problem scenarios, starting from search engines to question answering. We saw how some of the topics we learned earlier in the book can be used to address these problems. While these topics seem disparate at first glance, some of them are also related to one another—for example, search, recommendation systems, and question answering are all some form of information retrieval. Even summarization can be treated as such, as we retrieve relevant sentences from a given text. Additionally, all of them, except machine translation, typically do not require large, annotated datasets. Thus, we can see some <span class="keep-together">similarities</span> among these topics. Note that each of the topics we discussed are still active research questions in NLP, and a lot of new developments happen every day, so the treatment of topics in this chapter is not exhaustive. However, we hope this gave you enough of an overview to get started should you encounter a related use case at work.</p>

<p>With this, we’ve reached the end of the “Essentials” part of the book. In the next part, we’ll take a look at how all these different topics come together in specific domains.</p>
</div></section>
<div data-type="footnotes"><h5>Footnotes</h5></div><div data-type="footnotes"><h5>References</h5><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969595009240">[<a href="ch07.xhtml#idm45969595009240-marker">1</a>] Nayak, Pandu. <a href="https://oreil.ly/-syhq">“Understanding Searches Better than Ever Before”</a>. <em>The Keyword (blog)</em>, October 25, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_7_23">[<a href="ch07.xhtml#footnote_7_23-marker">2</a>] Brin, Sergey and Lawrence Page. “The Anatomy of a Large-Scale Hypertextual Web Search Engine.” <em>Computer Networks and ISDN Systems</em> 30.1–7 (1998): 107–117.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594960744">[<a href="ch07.xhtml#idm45969594960744-marker">3</a>] <a href="https://oreil.ly/P8cnm">Apache Nutch</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594958136">[<a href="ch07.xhtml#idm45969594958136-marker">4</a>] <a href="https://scrapy.org">Scrapy, a fast and powerful scraping and web crawling framework</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_7_3">[<a href="ch07.xhtml#footnote_7_3-marker">5</a>] <a href="https://oreil.ly/fTcCt">Apache Solr, an open source search engine</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594947816">[<a href="ch07.xhtml#idm45969594947816-marker">6</a>] <a href="https://www.elastic.co">Elasticsearch, an open source search engine</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594935816">[<a href="ch07.xhtml#idm45969594935816-marker">7</a>] Manning, Christopher D., Prabhakar Raghavan, and Hinrich Schütze. <em>Introduction to Information Retrieval</em>. Cambridge: Cambridge University Press, 2008. ISBN: 978-0-52186-571-5</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594914360">[<a href="ch07.xhtml#idm45969594914360-marker">8</a>] Tibshirani, Julie. <a href="https://oreil.ly/3K7_F">“Text similarity search with vector fields”</a>. <em>Elastic (blog),</em> August 27, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594903496">[<a href="ch07.xhtml#idm45969594903496-marker">9</a>] Elasticsearch. <a href="https://oreil.ly/4vM6S">“Function score query” documentation</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_7_27">[<a href="ch07.xhtml#footnote_7_27-marker">10</a>] <a href="https://oreil.ly/n4DJI">Amazon Kendra</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_7_5">[<a href="ch07.xhtml#footnote_7_5-marker">11</a>] Bamman, David and Noah Smith. <a href="https://oreil.ly/TEpOW">“CMU Book Summary Dataset”</a>, 2013.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594556952">[<a href="ch07.xhtml#idm45969594556952-marker">12</a>] <a href="https://oreil.ly/hyQOj">Amazon Elasticsearch Service</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594554504">[<a href="ch07.xhtml#idm45969594554504-marker">13</a>] <a href="https://oreil.ly/2eOjQ">Elastic on Azure</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594547032">[<a href="ch07.xhtml#idm45969594547032-marker">14</a>] Elasticsearch. <a href="https://oreil.ly/o_P9q">“Elasticsearch Learning to Rank: the documentation”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594545400">[<a href="ch07.xhtml#idm45969594545400-marker">15</a>] Mitra, Bhaskar and Nick Craswell. “An introduction to neural information retrieval.” <em>Foundations and Trends in Information Retrieval</em> 13.1 (2018): 1–126.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594539784">[<a href="ch07.xhtml#idm45969594539784-marker">16</a>] <a href="https://www.algolia.com">Search engine services by Algolia</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594537208">[<a href="ch07.xhtml#idm45969594537208-marker">17</a>] <a href="https://swiftype.com">Search engine services by Swiftype</a>, and <a href="https://oreil.ly/n4DJI">Amazon Kendra</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594534328">[<a href="ch07.xhtml#idm45969594534328-marker">18</a>] Gormley, Clinton and Zachary Tong. <a href="https://oreil.ly/cpIGq"><em>Elasticsearch: The Definitive Guide</em></a><em>.</em> Boston: O’Reilly, 2015. ISBN: 978-1-44935-854-9</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594507592">[<a href="ch07.xhtml#idm45969594507592-marker">19</a>] <a href="https://oreil.ly/xxC-O">“EH Topic Modeling II”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594495288">[<a href="ch07.xhtml#idm45969594495288-marker">20</a>] Keshet, Joseph. <a href="https://oreil.ly/KE20W">“Latent Dirichlet Allocation”</a>. Lecture from Advanced Techniques in Machine Learning (89654), Bar Ilan University, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594415576">[<a href="ch07.xhtml#idm45969594415576-marker">21</a>] RaRe Consulting. <a href="https://oreil.ly/hDr-a">“Genism: topic modelling for humans”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594229240">[<a href="ch07.xhtml#idm45969594229240-marker">22</a>] <a href="https://oreil.ly/I80VD">Gensim’s LDA tutorial</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594215160">[<a href="ch07.xhtml#idm45969594215160-marker">23</a>] Topic modeling is a broad area, with entire books written on the topic, so we won’t discuss how they work in this book. Interested readers can refer to the following article as a starting point: Blei, David M. “Probabilistic Topic Models.” <em>Communications of the ACM</em> 55.4 (2012): 77–84.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594205736">[<a href="ch07.xhtml#idm45969594205736-marker">24</a>] NIST. <a href="https://duc.nist.gov">Document Understanding Conference series</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594178120">[<a href="ch07.xhtml#idm45969594178120-marker">25</a>] Reddit. <a href="https://oreil.ly/WpFTr">autotldr bot</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594163000">[<a href="ch07.xhtml#idm45969594163000-marker">26</a>] <a href="https://oreil.ly/8OQ1l">Sumy, an automatic text summarizer</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594160184">[<a href="ch07.xhtml#idm45969594160184-marker">27</a>] Mihalcea, Rada and Paul Tarau. “TextRank: Bringing Order into Text.” <em>Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</em> (2004): 404–411.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969593977896">[<a href="ch07.xhtml#idm45969593977896-marker">28</a>] Mortensen, Ólavur. <a href="https://oreil.ly/wu1xO">“Text Summarization with Gensim”</a>. <em>RARE Technologies (blog)</em>, August 24, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969594097704">[<a href="ch07.xhtml#idm45969594097704-marker">29</a>] Wikipedia. <a href="https://oreil.ly/uBsUq">“ROUGE (metric)”</a>. Last updated September 3, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969593930472">[<a href="ch07.xhtml#idm45969593930472-marker">30</a>] Paulus, Romain, Caiming Xiong, and Richard Socher. <a href="https://oreil.ly/SDWDy">“Your TLDR by an ai: a Deep Reinforced Model for Abstractive Summarization”</a>. <em>Salesforce Research (blog)</em>, 2017.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969593909576">[<a href="ch07.xhtml#idm45969593909576-marker">31</a>] Patrick, Ryan B. <a href="https://oreil.ly/X-txd">“How Desmond Cole Wrote a Bestselling Book about Being Black in Canada”</a>. <em>CBC</em>, February 27, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969593716984">[<a href="ch07.xhtml#idm45969593716984-marker">32</a>] Grbovic, Mihajlo et al. <a href="https://oreil.ly/C0pWw">“Listing Embeddings in Search Ranking”</a>. <em>Airbnb Engineering &amp; Data Science (blog)</em>, March 13, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969593691272">[<a href="ch07.xhtml#idm45969593691272-marker">33</a>] Way, Andy. “Traditional and Emerging Use-Cases for Machine Translation.” <em>Proceedings of Translating and the Computer</em> 35 (2013): 12.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969593677432">[<a href="ch07.xhtml#idm45969593677432-marker">34</a>] Azure Cognitive Services. <a href="https://oreil.ly/9NV4W">Translator Text API v3.0</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610105096">[<a href="ch07.xhtml#idm45969610105096-marker">35</a>] <a href="http://mt-class.org">Machine Translation courses</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610252600">[<a href="ch07.xhtml#idm45969610252600-marker">36</a>] SQuAD2.0. <a href="https://oreil.ly/XHL2-">“The Stanford Question Answering Dataset”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610414408">[<a href="ch07.xhtml#idm45969610414408-marker">37</a>] Allen Institute for AI. <a href="https://oreil.ly/v1bKA">AllenNLP</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969590192088">[<a href="ch07.xhtml#idm45969590192088-marker">38</a>] Microsoft. <a href="https://oreil.ly/J7Nkz">Project Answer Search API</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969593247208">[<a href="ch07.xhtml#idm45969593247208-marker">39</a>] Jurafsky, Dan and James H. Martin. <a href="https://oreil.ly/Ta16f"><em>Speech and Language Processing</em></a>, Third Edition (Draft). 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969593262392">[<a href="ch07.xhtml#idm45969593262392-marker">40</a>] <a href="https://oreil.ly/uxXnj">CDQA-Suite, a library to help build a QA system for your dataset</a>. Last accessed June 15, 2020.</p></div></div></section></div>



  </body>
</html>