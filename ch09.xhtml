<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<link href="Styles/Style00.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style01.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style02.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style03.css" rel="stylesheet" type="text/css" />
<style type="text/css" title="ibis-book">
    @charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0 !important}#sbo-rt-content div.preface p.byline+p.byline{margin:0 !important}#sbo-rt-content div.sect1&gt;p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1&gt;p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]&gt;div&gt;h1,#sbo-rt-content section[data-type="preface"]&gt;div&gt;h1,#sbo-rt-content section[data-type="appendix"]&gt;div&gt;h1,#sbo-rt-content section[data-type="glossary"]&gt;div&gt;h1,#sbo-rt-content section[data-type="bibliography"]&gt;div&gt;h1,#sbo-rt-content section[data-type="index"]&gt;div&gt;h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content div.figure h6,#sbo-rt-content figure h6,#sbo-rt-content figure figcaption{font-size:.9rem !important;text-align:center;font-weight:normal !important;font-style:italic;font-family:serif !important;text-transform:none !important;letter-spacing:normal !important;color:#000;padding-top:.25em !important;margin-top:0 !important;page-break-before:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]&gt;div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:2em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content p[data-type="footnote"]{font-size:90% !important;line-height:1.2em !important;margin-left:2.5em !important;text-indent:-2.3em !important}#sbo-rt-content p[data-type="footnote"] sup{display:inline-block !important;position:static !important;width:2em !important;text-align:right !important;font-size:100% !important;padding-right:.5em !important}#sbo-rt-content p[data-type="footnote"] a[href$="-marker"]{font-family:sans-serif !important;font-size:90% !important;color:#8e0012 !important}#sbo-rt-content p[data-type="footnote"] a[data-type="xref"]{margin:0 !important;padding:0 !important;text-indent:0 !important}#sbo-rt-content a[data-type="noteref"]{font-family:sans-serif !important;color:#8e0012;margin-left:0;padding-left:0}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dl{margin-bottom:1.5em !important}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important;line-height:1.25rem;font-style:italic}#sbo-rt-content dd{margin:10px 0 .25em 1.5em !important;line-height:1.65em !important}#sbo-rt-content dd p{padding:0 !important;margin:0 0 10px !important}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul&gt;li,#sbo-rt-content ol ul,#sbo-rt-content ol ul&gt;li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul&gt;li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul&gt;li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul&gt;li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol&gt;li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol&gt;li,#sbo-rt-content ul ol,#sbo-rt-content ul ol&gt;li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol&gt;li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol&gt;li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol&gt;li&gt;ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol&gt;li&gt;ol&gt;li&gt;ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div[data-type="tip"] figure h6,#sbo-rt-content div[data-type="note"] figure h6,#sbo-rt-content div[data-type="warning"] figure h6,#sbo-rt-content div[data-type="caution"] figure h6,#sbo-rt-content div[data-type="important"] figure h6{font-family:serif !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content table li{margin:10px 0 0 .25em !important}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:top;font-size:80%}#sbo-rt-content th{vertical-align:bottom}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller;word-break:break-all}#sbo-rt-content table.border tbody&gt;tr:last-child&gt;td{border-bottom:transparent}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content div[data-type="equation"] math{font-size:calc(.35em + 1vw)}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index h3{padding:.25em;margin-top:1em !important;background-color:#F0F0F0}#sbo-rt-content div.index li{line-height:130%;list-style-type:none}#sbo-rt-content div.index a.indexterm{color:#8e0012 !important}#sbo-rt-content div.index ul{margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.index ul ul{margin-left:2em !important;margin-top:0 !important}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content pre.break-code,#sbo-rt-content code.break-code,#sbo-rt-content .break-code pre,#sbo-rt-content .break-code code{word-break:break-all}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content .width-10,#sbo-rt-content figure.width-10 img{width:10% !important}#sbo-rt-content .width-20,#sbo-rt-content figure.width-20 img{width:20% !important}#sbo-rt-content .width-30,#sbo-rt-content figure.width-30 img{width:30% !important}#sbo-rt-content .width-40,#sbo-rt-content figure.width-40 img{width:40% !important}#sbo-rt-content .width-50,#sbo-rt-content figure.width-50 img{width:50% !important}#sbo-rt-content .width-60,#sbo-rt-content figure.width-60 img{width:60% !important}#sbo-rt-content .width-70,#sbo-rt-content figure.width-70 img{width:70% !important}#sbo-rt-content .width-80,#sbo-rt-content figure.width-80 img{width:80% !important}#sbo-rt-content .width-90,#sbo-rt-content figure.width-90 img{width:90% !important}#sbo-rt-content .width-full,#sbo-rt-content .width-100{width:100% !important}#sbo-rt-content .sc{text-transform:none !important}#sbo-rt-content .right{float:none !important}#sbo-rt-content a.totri-footnote{padding:0 !important}#sbo-rt-content figure.width-10,#sbo-rt-content figure.width-20,#sbo-rt-content figure.width-30,#sbo-rt-content figure.width-40,#sbo-rt-content figure.width-50,#sbo-rt-content figure.width-60,#sbo-rt-content figure.width-70,#sbo-rt-content figure.width-80,#sbo-rt-content figure.width-90{width:auto !important}#sbo-rt-content p img,#sbo-rt-content pre img{width:1.25em;line-height:1em;margin:0 .15em -.2em}#sbo-rt-content figure.no-frame div.border-box{border:none}#sbo-rt-content .right{text-align:right !important}
    </style>
<style type="text/css" id="font-styles">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }</style>
<style type="text/css" id="font-family">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }</style>
<style type="text/css" id="column-width">#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }</style>

<style type="text/css">body{margin:1em;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}body{background-color:transparent!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style></head>
<body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 9. E-Commerce and Retail"><div class="chapter" id="e_commerce_and_retail">
<h1><span class="label">Chapter 9. </span>E-Commerce and Retail</h1>

<blockquote class="right">
<p class="right"><em>Today’s new marketplaces must nurture</em><br/> <em>and manage perfect competition to thrive.</em></p>
<p data-type="attribution" style="text-align:right"><em>Jeff Jordan, Andreessen Horowitz</em></p>
</blockquote>

<p>In today’s world, e-commerce has become synonymous<a contenteditable="false" data-type="indexterm" data-primary="Jordan, Jeff" id="idm45969588077432"/><a contenteditable="false" data-type="indexterm" data-primary="Horowitz, Andreessen" id="idm45969588076328"/><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" id="ch09_term1"/> with shopping. An enriched customer experience compared to what a physical retail store offers has fueled this growth of e-commerce. Worldwide retail e-commerce sales in 2019 were $3.5 trillion and are projected to reach $6.5 trillion by 2022 [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969588073464-marker" href="ch09.xhtml#idm45969588073464">1</a>]. Recent advancements in ML and NLP have played a major role in this rapid growth.</p>

<p>Visit the home page of any e-retailer, and you’ll find a lot of information in the form of text and images. A significant portion of this information consists of text in the form of product descriptions, reviews, etc. Retailers strive to utilize this information intelligently to deliver customer delight and build competitive advantage. An e-commerce portal faces a range of text-related problems that can be solved by NLP techniques. We saw different kinds of NLP problems and solutions in the previous section (Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a> through <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch07.xhtml#topics_in_brief">7</a>). In this chapter, we’ll give an overview of how NLP problems in the e-commerce domain can be addressed using what we’ve learned in this book so far. We’ll discuss some of the key NLP tasks in this domain, including search, building a product catalog, collecting reviews, and providing <span class="keep-together">recommendations.</span></p> 

<p><a data-type="xref" href="#nlp_applications_in_e_commerce">Figure 9-1</a> shows some of these e-commerce tasks. Let’s start with an overview of them.</p>

<figure><div id="nlp_applications_in_e_commerce" class="figure">
<img src="Images/pnlp_0901.png" alt="NLP applications in e-commerce" width="859" height="500"/>
<h6><span class="label">Figure 9-1. </span>NLP applications in e-commerce<a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="NLP applications" id="idm45969588064104"/></h6>
</div></figure>

<section data-type="sect1" data-pdf-bookmark="E-Commerce Catalog"><div class="sect1" id="e_commerce_catalog">
<h1>E-Commerce Catalog</h1>

<p><a contenteditable="false" data-type="indexterm" data-primary="catalogs" id="ch09_term3"/>Any large e-commerce<a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="catalogs" id="ch09_term2"/> enterprise needs an easy-to-access <a contenteditable="false" data-type="indexterm" data-primary="product catalogs" data-see="catalogs" id="idm45969588057464"/>product catalog. A product catalog is a database of the products that the enterprise deals or a user can purchase. This contains product description attributes as well as images for each product. Better product descriptions with relevant information help the customer choose the right product through the catalog. Such information can also help in product search and recommendations. Imagine a recommendation engine that automatically knows that you like the color blue! That’s certainly not possible unless and until the engine notices that most of your recent purchases or searches were on apparel of the color blue. The first thing needed to achieve this is identifying that “blue” is associated with the products as a color attribute. Extracting such information automatically is called <em>attribute extraction</em><a contenteditable="false" data-type="indexterm" data-primary="attribute extraction" id="idm45969588054856"/>. Attribute extraction from product descriptions can guarantee that all the relevant product information is properly indexed and displayed for each product, improving product discoverability.</p>

<section data-type="sect2" data-pdf-bookmark="Review Analysis"><div class="sect2" id="review_analysi">
<h2>Review Analysis</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="review analysis" id="idm45969588051816"/>The most notable part of an e-commerce platform is the user reviews section for every product. Reviews provide a different perspective of the product that cannot be obtained from the product attributes alone, such as quality, usability, comparisons with other products, and delivery feedback. All reviews may not be useful, or they might not come from trusted users. Further, it’s hard to process multiple reviews for a given product manually. NLP techniques provide an overall perspective for all reviews by performing tasks such as sentiment analysis, review summarization, identifying review helpfulness, and so on. We saw one example of NLP for review analysis in <a data-type="xref" href="ch05.xhtml#information_extraction">Chapter 5</a> when we discussed keyphrase extraction. We’ll see other use cases later in this chapter.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Product Search"><div class="sect2" id="product_search">
<h2>Product Search</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="product search" id="idm45969588047096"/><a contenteditable="false" data-type="indexterm" data-primary="search" data-secondary="product" id="idm45969588045992"/><a contenteditable="false" data-type="indexterm" data-primary="search" data-secondary="focused" id="idm45969588044616"/>Search systems in e-commerce are different compared to general search engines like Google, Bing, and Yahoo. An e-commerce search engine is closely tied to the products available and the different kinds of information associated with them. For instance, in a regular search engine, we’re dealing largely with free-form text data (like news articles or blogs) as opposed to structured sales and review data for e-commerce. We might search for “red checkered shirt for a wedding,” and the e-commerce search engine should be able to fetch it. Similar forms of focused search can also be seen on travel websites for flight and hotel bookings, such as Airbnb<a contenteditable="false" data-type="indexterm" data-primary="Airbnb" id="idm45969588042440"/> and TripAdvisor<a contenteditable="false" data-type="indexterm" data-primary="TripAdvisor" id="idm45969588041208"/>. The specific nature of the information associated with each type of e-commerce business calls for a customized pipeline of information processing, extraction, and search.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Product Recommendations"><div class="sect2" id="product_recommendations">
<h2>Product Recommendations</h2>

<p>Without a <a contenteditable="false" data-type="indexterm" data-primary="recommendations" data-secondary="product" id="idm45969588037896"/><a contenteditable="false" data-type="indexterm" data-primary="recommender systems" data-secondary="e-commerce" id="idm45969588036488"/><a contenteditable="false" data-type="indexterm" data-primary="product recommendations" id="idm45969588035112"/>recommendation engine, any e-commerce platform would be incomplete. A customer likes when the platform intelligently understands their choices and suggests products to buy next. It actually helps the customer organize their thoughts about shopping and helps to achieve better utility. Recommendations of discounted items, same-brand products, or products with favorite attributes can really engage the customer on the website and make them spend more time. This directly increases the possibility of the customers buying those products. In addition to transaction-based recommendation facilities, there is a rich set of algorithms that are developed based on product content information and reviews that are textual in nature. NLP is used to build such recommendation systems.</p>

<p>With this overview, we’re all set to explore the role of NLP in e-commerce in more detail. Let’s start with how it’s used in building search<a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="catalogs" data-startref="ch09_term2" id="idm45969588032504"/><a contenteditable="false" data-type="indexterm" data-primary="catalogs" data-startref="ch09_term3" id="idm45969588030856"/> for e-commerce.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Search in E-Commerce"><div class="sect1" id="search_in_e_commerce">
<h1>Search in E-Commerce</h1>

<p><a contenteditable="false" data-type="indexterm" data-primary="search engines" data-secondary="in e-commerce" data-secondary-sortas="e-commerce" id="ch09_term6"/><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="search" id="ch09_term5"/>Customers visit an e-commerce website to find and purchase their desired products quickly. Ideally, a search feature should enable the customer to reach the right product with the least number of clicks. The search needs to be fast and precise and fetch results that closely match customers’ needs. A good search mechanism positively impacts the conversion rate, which directly impacts the revenue of the e-retailer. Globally, on average, only 4.3% of user search attempts convert to a purchase. By some estimates, 34% of results in search on the top 50 portals do not produce useful results [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969588022984-marker" href="ch09.xhtml#idm45969588022984">2</a>], and there’s often a large scope for improvement.</p>

<p>In <a data-type="xref" href="ch07.xhtml#topics_in_brief">Chapter 7</a>, we discussed how general search engines work and where NLP is useful. However, for e-commerce, the search engine needs to be more fine-tuned to the business needs. Search in e-commerce is closed domain—i.e., the search engine <span class="keep-together">typically</span> fetches items from within the product information, rather than from a generic set of documents or content on the open web (like Google or Bing). The underlying product information is built on the product catalog, attributes, and reviews. Search works on different facets of this information, like color, style, or category. This kind of search in e-commerce is generally called “faceted search,” which is the focus of this section.</p>

<p><a contenteditable="false" data-type="indexterm" data-primary="faceted search" id="ch09_term7"/><a contenteditable="false" data-type="indexterm" data-primary="search" data-secondary="faceted" id="ch09_term8"/>Faceted search is a specialized variant of search that allows the customer to navigate in a streamlined way with filters. For example, if we’re planning to buy a TV, then we might look for filters like brand, price, TV size, etc. In e-commerce websites, users are presented with a set of search filters depending on the product. Figures <a data-type="xref" data-xrefstyle="select:labelnumber" href="#faceted_search_on_amazondotcom">9-2</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="#faceted_search_on_walmartdotcom">9-3</a> illustrate search in e-commerce through Amazon and Walmart.</p>


<p>The left-most section of both images depicts a set of filters (alternatively, “facets”<a contenteditable="false" data-type="indexterm" data-primary="facets" id="idm45969588011240"/>) that allows the customer to guide their search in a way that matches their buying needs. In <a data-type="xref" href="#faceted_search_on_amazondotcom">Figure 9-2</a>, we see a search for television models, so the filters show aspects such as resolution and display size. Along with such custom filters, there are also some general features that are valid for many such product searches, such as brand, price range, and mode of shipping, as shown in <a data-type="xref" href="#faceted_search_on_walmartdotcom">Figure 9-3</a>. These filters are explicit dimensions to perceive the product. And this guided search enables the user to arrange the search results on their own to get more control over shopping, rather than having to sift through a lot of results to get what they’re looking for.</p>

<figure><div id="faceted_search_on_amazondotcom" class="figure">
<img src="Images/pnlp_0902.png" alt="Faceted search on Amazon.com" width="1258" height="723"/>
<h6><span class="label">Figure 9-2. </span>Faceted search on <a contenteditable="false" data-type="indexterm" data-primary="Amazon" data-secondary="faceted search on" id="idm45969588005400"/><a class="orm:hideurl" href="http://Amazon.com">Amazon.com</a></h6>
</div></figure>

<figure><div id="faceted_search_on_walmartdotcom" class="figure">
<img src="Images/pnlp_0903.png" alt="Faceted search on Walmart.com" width="1442" height="839"/>
<h6><span class="label">Figure 9-3. </span>Faceted search on <a contenteditable="false" data-type="indexterm" data-primary="Walmart" id="idm45969588001160"/><a class="orm:hideurl" href="http://Walmart.com">Walmart.com</a></h6>
</div></figure>


<p>These filters are the key that defines the faceted search. However, they may not always be readily available for all products. Some reasons for that are:</p>
<ul>
<li>
	<p>The seller didn’t upload all the required information while listing the product on the e-commerce website. This is typically the case when a new e-commerce business ramps up and aggressively promotes quick onboarding of various sellers. To achieve this, they often allow the sellers to list without having quality checks in place for the product metadata.</p></li>
<li>
	<p>Some of the filters are difficult to obtain, or the seller may not have the complete information to provide—for example, the caloric value of a food product, which is typically derived from the nutrient information provided on the product case. E-retailers don’t expect this information to be provided by the seller, but it’s crucial because it may capture important customer signals that are directly related to the conversation of that product sale.</p></li>
</ul>

<p>Faceted search can be built with most popular search engine backends like Solr and Elasticsearch. Besides regular text search, different facet attributes are also added to the search query. Elasticsearch<a contenteditable="false" data-type="indexterm" data-primary="Elasticsearch" data-secondary="DSL" id="idm45969587995128"/>’s DSL also comes with a built-in faceted search <span class="keep-together">interface</span> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587992872-marker" href="ch09.xhtml#idm45969587992872">3</a>].</p>
<div data-type="tip"><h6>Tip</h6>


<p>In an e-commerce setting, we also need to account for business needs other than relevance in terms of facets and text. For instance, products that are part of a promotion or sale may be bumped up in results. This can be built by utilizing features like Elasticsearch boosting.</p>
</div>

<p>Apart from search algorithms, there are many nuances associated with faceted search, and we’ll focus on these for the rest of this chapter.<a contenteditable="false" data-type="indexterm" data-primary="faceted search" data-startref="ch09_term7" id="idm45969587989432"/><a contenteditable="false" data-type="indexterm" data-primary="search" data-secondary="faceted" data-startref="ch09_term8" id="idm45969587988056"/> The issues mentioned above relate to the problem we’ll discuss<a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="search" data-startref="ch09_term5" id="idm45969587986280"/><a contenteditable="false" data-type="indexterm" data-primary="search engines" data-secondary="in e-commerce" data-secondary-sortas="e-commerce" data-startref="ch09_term6" id="idm45969587984552"/> in the next section: building an e-commerce catalog.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Building an E-Commerce Catalog"><div class="sect1" id="building_an_e_commerce_catalog">
<h1>Building an E-Commerce Catalog</h1>

<p><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="catalogs" id="ch09_term11"/><a contenteditable="false" data-type="indexterm" data-primary="catalogs" id="ch09_term10"/>As we saw earlier in this chapter, building an informative catalog is one of the primary problems in e-commerce. It can be split into several subproblems:</p>
<ul>
<li>
	<p>Attribute extraction</p></li>
<li>
	<p>Product categorization and taxonomy creation</p></li>
<li>
	<p>Product enrichment</p></li>
<li>
	<p>Product deduplication and matching</p></li>
</ul>

<p>Let’s take a look at each of these in this section.</p>

<section data-type="sect2" data-pdf-bookmark="Attribute Extraction"><div class="sect2" id="attribute_extraction">
<h2>Attribute Extraction</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="attribute extraction" id="ch09_term12"/>Attributes are properties that define a product. For example, in <a data-type="xref" href="#faceted_search_on_amazondotcom">Figure 9-2</a>, we saw brand, resolution, TV size, etc., as relevant attributes. An accurate display of these attributes will provide a complete overview of the product on the e-commerce website so that the customer can make an informed choice. A rich set of attributes relates directly to the improvement of clicks and click-through rates, which influence the product’s sale. <a data-type="xref" href="#product_obtained_by_a_set_of_filters_or">Figure 9-4</a> shows an example of a product description obtained by a set of filters or attributes.</p>


<p>As you can see, attributes like {clothing, color, size} are basically what defines this product to a customer. Each of these attributes can have multiple values, as shown in the figure. In this example, color takes seven values. However, directly obtaining attributes from the sellers for all products is difficult. Moreover, the quality of the attributes should be consistent enough to allow a customer to have the correct and relevant information about a product.</p>

<figure><div id="product_obtained_by_a_set_of_filters_or" class="figure">
<img src="Images/pnlp_0904.png" alt="Product obtained by a set of filters or attributes" width="420" height="423"/>
<h6><span class="label">Figure 9-4. </span>Product obtained by a set of filters or attributes</h6>
</div></figure>

<p>Traditionally, e-commerce websites employed manual labeling or crowdsourcing techniques to obtain the attributes. This is typically done by third-party companies or crowdsourcing platforms (e.g., Mechanical Turk<a contenteditable="false" data-type="indexterm" data-primary="Mechanical Turk" id="idm45969587964024"/>), where specific questions about each product are asked and the crowd workers are expected to answer them. Sometimes, the questions are framed in a multiple-choice way to restrict the answer into a set of values. But generally, it’s expensive and not scalable with the increase in the volume of products. That’s where techniques from machine learning step in. This is a challenging task because it requires an understanding of the context of the information present in the product. For example, look at the two product descriptions shown in <a data-type="xref" href="#cases_where_quotation_markpinkquotation">Figure 9-5</a>.</p>


<p>Pink is a popular brand with younger women. Similarly, pink is a very common color of apparel. Hence, in the first case, Pink is a brand name attribute, whereas in the other case, pink is just a color. In <a data-type="xref" href="#cases_where_quotation_markpinkquotation">Figure 9-5</a>, we see that the backpack is from the brand “Pink” with a color of neon red, whereas the sweatshirt is of the color pink. Cases like these and many more are prevalent and pose a challenging task for a computer to solve.</p>

<figure><div id="cases_where_quotation_markpinkquotation" class="figure">
<img src="Images/pnlp_0905.png" alt="Cases where “pink” is the attribute value for two different attributes" width="1442" height="1585"/>
<h6><span class="label">Figure 9-5. </span>Cases where “pink” is the attribute value for two different attributes</h6>
</div></figure>

<p>If we can obtain a set of attributes in some structured data format, then the search mechanism can accurately utilize them to retrieve results according to customer needs. The algorithms that extract the attribute information from various product descriptions are generally called <em>attribute extraction algorithms</em><a contenteditable="false" data-type="indexterm" data-primary="attribute extraction" data-secondary="algorithms" id="idm45969587956120"/>. These algorithms take a collection of textual data as input and produce the attribute-value pairs as output. There are two types of attribute extraction algorithms: <em>direct</em> and <em>derived</em>.</p>

<p><em>Direct attribute extraction algorithms</em><a contenteditable="false" data-type="indexterm" data-primary="attribute extraction" data-secondary="direct" id="idm45969587952952"/><a contenteditable="false" data-type="indexterm" data-primary="direct attribute extraction" id="idm45969587951608"/> assume the presence of the attribute value in the input text. For example, “Sony XBR49X900E 49-Inch 4K Ultra HD Smart LED TV (2017 Model)” contains the brand “Sony.” A brand is typically an attribute that’s expected to be present in the product title in most cases. On the other hand, <em>derived attribute extraction algorithms</em><a contenteditable="false" data-type="indexterm" data-primary="attribute extraction" data-secondary="derived" id="idm45969587949704"/><a contenteditable="false" data-type="indexterm" data-primary="derived attribute extraction" id="idm45969587948360"/> do not assume that the attribute of interest is present in the input text. They derive that information from the context. Gender is one such attribute that is usually not present in the product title, but from the input text, the algorithm can identify if the product is specifically for men or women. Consider the product description: “YunJey Short Sleeve Round Neck Triple Color Block Stripe T-Shirt Casual Blouse.” The product is for women, but the gender “female” is not explicitly mentioned in the product description or title. In this case, the gender has to be inferred from the text (for instance, from the product description).</p>

<section data-type="sect3" data-pdf-bookmark="Direct attribute extraction"><div class="sect3" id="direct_attribute_extraction">
<h3>Direct attribute extraction</h3>

<p><a contenteditable="false" data-type="indexterm" data-primary="attribute extraction" data-secondary="direct" id="ch09_term14"/><a contenteditable="false" data-type="indexterm" data-primary="direct attribute extraction" id="ch09_term13"/>Typically, the direct attribute extraction is modeled as a sequence-to-sequence labeling problem. A sequence labeling model takes a sequence (e.g., of words) as input and outputs another sequence of the same length. In <a data-type="xref" href="ch05.xhtml#information_extraction">Chapter 5</a>, we briefly touched on this kind of problem in the notebook on training a named entity recognizer. Following a similar approach, let’s take a look at how direct attribute extraction algorithms work.</p>

<p>Our training data will be of the form shown in <a data-type="xref" href="#training_data_format_for_direct_attribu">Figure 9-6</a>, for an example product titled, “The Green Pet Shop Self Cooling Dog Pad.”</p>
<figure><div id="training_data_format_for_direct_attribu" class="figure">
<img src="Images/pnlp_0906.png" alt="Training data format for direct attribute extraction" width="1133" height="122"/>
<h6><span class="label">Figure 9-6. </span>Training data format for direct attribute extraction</h6>
</div></figure>

<p>Here, what we have to extract is “The Green Pet Shop,” which is indicated by the -attribute tags, whereas the rest of it is indicated by an O (Other) tag. Getting labeled data in BIO is crucial for any direct attribute extraction process. We should also have data that represents various categories (e.g., B-Attribute1, B-Attribute2, etc.).</p>

<p>There are two broad ways to collect this data. A simpler one would be to use regular expressions on existing text descriptions with brands and attributes and use that dataset. This is akin to weak supervision. We can also get a subset of the data labeled by human annotators. With such labeled data, a rich set of features needs to be extracted to train an ML model. Ideally, the input features should capture the attribute characteristics and locational and contextual information. Here’s a list of some of the features that can capture all three of these aspects. We can develop more complex features along similar lines and perform analysis to understand if they’re significant in improving performance. Some common features for this task are:</p>
<dl>
<dt>Characteristic features<a contenteditable="false" data-type="indexterm" data-primary="characteristic features" id="idm45969587933256"/></dt>
<dd>These are typically token-based features, such as the letter case of the token, length of the token, and its character composition.</dd>
<dt>Locational features<a contenteditable="false" data-type="indexterm" data-primary="locational features" id="idm45969587931112"/></dt>
<dd>These features capture the positional aspect of the token in the input sequence, such as the number of tokens before the given token or the ratio of the token position and the total length of the sequence.</dd>
<dt>Contextual features<a contenteditable="false" data-type="indexterm" data-primary="contextual features" id="idm45969587928920"/></dt>
<dd>These features mostly encode information about the neighboring tokens, such as the identity of the preceding/succeeding token, POS tag of the token, whether the preceding token is a conjunction, etc.</dd>
</dl>

<p>Once the features are generated and output tags are encoded properly, we get the sequence pairs for training the model. At this point, the training process is similar to that of an NER system. Even though the pipeline looks simple and similar to NER systems, there are challenges with these feature-generation schemes and modeling techniques because of domain-specific knowledge. Further, it’s a challenge to obtain large enough datasets that cover a range of attributes.</p>

<p>To deal with such data sparsity and other feature incompleteness issues, some approaches suggest the use of a sequence of word embeddings in the input. The input sequence will be passed to the model as is, and it’s supposed to predict the output sequence. Recent efforts include deep recurrent structures like RNN<a contenteditable="false" data-type="indexterm" data-primary="recurrent neural networks (RNNs)" id="idm45969587925832"/><a contenteditable="false" data-type="indexterm" data-primary="RNNs (recurrent neural networks)" id="idm45969587924072"/> or LSTM-CRF<a contenteditable="false" data-type="indexterm" data-primary="long short-term memory networks (LSTMs)" data-secondary="LSTM-CRF" id="idm45969587922872"/><a contenteditable="false" data-type="indexterm" data-primary="LSTM-CRF" id="idm45969587921448"/> to perform the seq2seq labeling task [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587920216-marker" href="ch09.xhtml#idm45969587920216">4</a>]. We saw how word embeddings and RNNs are useful in NLP in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch03.xhtml#text_representation">3</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a>. This is another example of where such representations can be useful. <a data-type="xref" href="#characteristic_performance_improvement">Figure 9-7</a> shows an example of how one such DL model [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_9_19-marker" href="ch09.xhtml#footnote_9_19">5</a>] performs better than the typical ML<a contenteditable="false" data-type="indexterm" data-primary="direct attribute extraction" data-startref="ch09_term13" id="idm45969587913224"/><a contenteditable="false" data-type="indexterm" data-primary="attribute extraction" data-secondary="direct" data-startref="ch09_term14" id="idm45969587911816"/><a contenteditable="false" data-type="indexterm" data-primary="deep learning (DL)" data-secondary="attribute extraction with" id="idm45969587910168"/> models.</p>

<figure><div id="characteristic_performance_improvement" class="figure">
<img src="Images/pnlp_0907.png" alt="Characteristic performance improvement in the LSTM framework for attribute extraction [_19]" width="968" height="172"/>
<h6><span class="label">Figure 9-7. </span>Characteristic performance improvement in the LSTM framework for attribute extraction [<a data-type="noteref" href="ch09.xhtml#footnote_9_19">5</a>]</h6>
</div></figure>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Indirect attribute extraction"><div class="sect3" id="indirect_attribute_extraction">
<h3>Indirect attribute extraction</h3>

<p><a contenteditable="false" data-type="indexterm" data-primary="indirect attribute extraction" id="ch09_term16"/><a contenteditable="false" data-type="indexterm" data-primary="attribute extraction" data-secondary="indirect" id="ch09_term15"/>Indirect attributes are attributes that are not directly mentioned in the description. These attributes, however, can be inferred from other direct attributes or the overall description. For instance, gender- or age-specific words can be inferred from the text. A phrase like “Suit for your baby aged 1–5 years” implies that the product is for toddlers. Due to the absence of explicit mentions, a sequence labeling approach won’t work.</p>

<p>For indirect attribute classification, we use text classification, since instead of extracting information, we can infer high-level classes (i.e., indirect attributes) from the overall input. Recall the example of “YunJae Short Sleeve Round Neck Triple Color Block Stripe T-Shirt Casual Blouse.” For this case, we represent the whole input string using any of the sentence representation methods from <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a>. We can also create features, such as the presence of class-specific words, character n-grams, and word n-grams. Then, we can train a model to classify the input to an indirect attribute label. In this example here, for the “gender” attribute, we should use men, women, unisex, and child as different class labels.</p>
<div data-type="tip"><h6>Tip</h6>

<p>For the models that use deep recurrent structures, the amount of data needed is typically much more than what’s needed when less-complex ML models such as CRF and HMM are used. The more data there is, the better the deep models learn. This is common to all DL models, as we saw in earlier chapters, but for e-commerce, getting a large set of well-sampled, annotated data is very expensive. Hence, it needs to be taken care of before we to build any sophisticated models.</p>
</div>

<p>So far, we’ve discussed attribute extraction from textual data and the various recent approaches that extend this to multimodal attribute extraction, incorporating various modalities such as title, description, image, reviews, etc., about the product [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_9_9-marker" href="ch09.xhtml#footnote_9_9">6</a>].</p>

<p>In the next sections, we’ll talk about expanding techniques similar to the ones we applied to product attributes to other facets of e-commerc<a contenteditable="false" data-type="indexterm" data-primary="attribute extraction" data-startref="ch09_term12" id="idm45969587893768"/><a contenteditable="false" data-type="indexterm" data-primary="attribute extraction" data-secondary="indirect" data-startref="ch09_term15" id="idm45969587892392"/><a contenteditable="false" data-type="indexterm" data-primary="indirect attribute extraction" data-startref="ch09_term16" id="idm45969587890744"/>e and retail.</p>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Product Categorization and Taxonomy"><div class="sect2" id="product_categorization_and_taxonomy">
<h2>Product Categorization and Taxonomy</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="classification" data-secondary="product categorization and taxonomy" id="ch09_term20"/><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="product categorization and taxonomy" id="ch09_term19"/><a contenteditable="false" data-type="indexterm" data-primary="product categorization and taxonomy" id="ch09_term916"/><a contenteditable="false" data-type="indexterm" data-primary="categorization, product" id="ch09_term17"/><a contenteditable="false" data-type="indexterm" data-primary="taxonomy, product" id="ch09_term18"/>Product categorization is a process of dividing products into groups. These groups can be defined based on similarity—e.g., products of the same brand or products of the same type can be grouped together. Generally, e-commerce has pre-defined broad categories of products, such as electronics, personal care products, and foods. When a new product arrives, it should be categorized into the taxonomy before it’s put in the catalog. <a data-type="xref" href="#a_typical_category_hierarchyem_dashtaxo">Figure 9-8</a> shows a taxonomy for the electronics category with a hierarchy of granular subcategories.</p>

<p>We can further define successively smaller groups with stricter definitions of products, such as laptops and tablets inside the computer category. For a more contextual example, this book will have a level category of technical books, while it’s subcategories will be related to AI or natural language processing. This task is a lot like the text classification we covered in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>.</p>
<figure><div id="a_typical_category_hierarchyem_dashtaxo" class="figure">
<img src="Images/pnlp_0908.png" alt="A typical category hierarchy—taxonomy of a product" width="1260" height="1043"/>
<h6><span class="label">Figure 9-8. </span>A typical category hierarchy—taxonomy of a product</h6>
</div></figure>

<p>A good taxonomy and properly linked products can be critical because it allows an e-commerce site to:</p>
<ul>
<li>
	<p>Show products similar to the product searched</p></li>
<li>
	<p>Provide better recommendations</p></li>
<li>
	<p>Select appropriate bundles of products for better deals for the customer</p></li>
<li>
	<p>Replace old products with new ones</p></li>
<li>
	<p>Show price comparisons of different products in the same category</p></li>
</ul>

<p>This categorization process is typically manual to start at small scale, but as the variety of products increases, it gets harder and harder to process them manually. At scale, this categorization is typically posed as a classification task where the algorithm takes information from a variety of sources and applies the classification technique to solve it [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587868840-marker" href="ch09.xhtml#idm45969587868840">7</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587867400-marker" href="ch09.xhtml#idm45969587867400">8</a>].</p>

<p>Specifically, there are cases where algorithms take input as the title or description and classify the product into a suitable category when all the categories are known. This again falls into the typical case of text classification. In this way, the categorization process can be automated. Once the category is determined, it’s extended directly to the relevant attribute extraction process that we discussed earlier. It’s logical that a product will be passed to the attribute extraction process only when its category is discovered.</p>

<p>The accuracy of the algorithm can be improved when both images and text can be used to solve the problem. Images can be passed to a convolutional neural network for generating image embedding, and the text sequence can be encoded via LSTM, both of which, in turn, can be concatenated and passed to any classifier for the final output [<a data-type="noteref" href="ch09.xhtml#footnote_9_9">6</a>].</p>

<p>Building a taxonomy tree is an extensive process. Placing the products at the right level in the taxonomy can be done via a hierarchical text classification. A hierarchical text classification in context is nothing more than applying classification models in hierarchy according to levels in a taxonomy.</p>

<p>Generally simple rule-based classification methods are used mainly for the high-level categories. They can use a dictionary-based matching as a start. Subcategories that are complex and require deeper context to determine the right taxonomic level are dealt with by ML classification techniques such as SVM or decision tree [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_9_13-marker" href="ch09.xhtml#footnote_9_13">9</a>]. <a data-type="xref" href="#taxonomy_tree_with_different_levels_lef">Figure 9-9</a> shows various taxonomy levels for a specific product example.</p>
<figure><div id="taxonomy_tree_with_different_levels_lef" class="figure">
<img src="Images/pnlp_0909.png" alt="Taxonomy tree with different levels [_13]" width="1080" height="956"/>
<h6><span class="label">Figure 9-9. </span>Taxonomy tree with different levels [<a data-type="noteref" href="ch09.xhtml#footnote_9_13">9</a>]</h6>
</div></figure>

<p class="pagebreak-before">For a new e-commerce platform, creating a product taxonomy via product categorization can be an insurmountable task. Building rich content requires a huge amount of relevant data, manual interventions, and category experts’ domain knowledge. All these can be expensive for a nascent e-commerce platform. However, there are some APIs<a contenteditable="false" data-type="indexterm" data-primary="APIs" data-secondary="product categorization and taxonomy" id="idm45969587855848"/> offered by Semantics3<a contenteditable="false" data-type="indexterm" data-primary="Semantics3" id="idm45969587854280"/>, eBay<a contenteditable="false" data-type="indexterm" data-primary="eBay" id="idm45969587853016"/>, and Lucidworks<a contenteditable="false" data-type="indexterm" data-primary="Lucidworks" id="idm45969587851752"/> that can help with the process.</p>

<p>These APIs typically build on large catalog content of various big retailers and provide the intelligence inside to categorize a product by scanning its unique product code. Small-scale e-commerce can use the power of such cloud APIs for bootstrapping taxonomy creation and categorization. <a data-type="xref" href="#semantics3_terminal_snapshot">Figure 9-10</a> shows a snapshot of one such API from Semantics3 [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587848744-marker" href="ch09.xhtml#idm45969587848744">10</a>]. Their API helps categorize a product from its name.</p>
<figure><div id="semantics3_terminal_snapshot" class="figure">
<img src="Images/pnlp_0910.png" alt="Semantics3 terminal snapshot" width="720" height="762"/>
<h6><span class="label">Figure 9-10. </span>Semantics3 terminal snapshot</h6>
</div></figure>

<p>Once a significant amount of product information has been gathered, it’s advisable to use custom rule-based systems. Some of these APIs<a contenteditable="false" data-type="indexterm" data-primary="APIs" data-secondary="product categorization and taxonomy" id="idm45969587844312"/> also support user-defined rules, as well as product enrichment and deduplication, which we’ll cover in the next<a contenteditable="false" data-type="indexterm" data-primary="product categorization and taxonomy" data-startref="ch09_term916" id="idm45969587842616"/><a contenteditable="false" data-type="indexterm" data-primary="categorization, product" data-startref="ch09_term17" id="idm45969587841368"/><a contenteditable="false" data-type="indexterm" data-primary="taxonomy, product" data-startref="ch09_term18" id="idm45969587839912"/><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="product categorization and taxonomy" data-startref="ch09_term19" id="idm45969587838536"/><a contenteditable="false" data-type="indexterm" data-primary="classification" data-secondary="product categorization and taxonomy" data-startref="ch09_term20" id="idm45969587836872"/> <span class="keep-together">sections.</span></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Product Enrichment"><div class="sect2" id="product_enrichment">
<h2>Product Enrichment</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="product enrichment" id="ch09_term22"/><a contenteditable="false" data-type="indexterm" data-primary="product enrichment" id="ch09_term21"/>For better search and recommendations, it’s important to gather richer product information. Some potential sources of this information are short and long titles, product images, and product descriptions. But this information is often either incorrect or incomplete. For example, a misleading title can hamper the faceted search in an e-commerce platform. Improving a product title will not only improve the click-through rate in search, but also the conversion rate in terms of product purchase.</p>

<p>In the example shown in <a data-type="xref" href="#example_of_a_clumsy_product_title_and_a">Figure 9-11</a>, the product title is too long and contains words like iPad, iPhone, and Samsung, which can easily mislead the search. The full title is “Stylus Pen LIBERRWAY 10 Pack of Pink Purple Black Green Silver Stylus Universal Touch Screen Capacitive Stylus for Kindle Touch ipad iphone 6/6s 6Plus 6s Plus Samsung S5 S6 S7 Edge S8 Plus Note.” This text is too complicated even for a human to parse and make sense of, let alone a machine. Such cases are ideal for product <span class="keep-together">enrichment.</span></p>
<figure><div id="example_of_a_clumsy_product_title_and_a" class="figure">
<img src="Images/pnlp_0911.png" alt="Example of a clumsy product title and an ideal case for product enrichment" width="1442" height="642"/>
<h6><span class="label">Figure 9-11. </span>Example of a clumsy product title and an ideal case for product enrichment</h6>
</div></figure>

<p>First, we’ll go through the problem scenario shown in <a data-type="xref" href="#example_of_a_clumsy_product_title_and_a">Figure 9-11</a>. When different taxonomic and enrichment levels are filled, at least to an acceptable threshold (typically defined by the retail platform itself), then we can attempt to make the product title more expressive and accurate.</p>

<p class="pagebreak-before">The process can start with direct string matching. It’s also necessary to filter out tokens that are not part of the product’s attribute values. In the example, the product is a stylus, and iPad and iPhone are not part of its attribute values. These tokens are misleading and can affect the quality of faceted search. Hence, such tokens should be removed from the product title, unless they’re important to indicate domain-specific context for the product.</p>

<p>Ideally, a pre-defined template for the product titles helps maintain consistency across products. A good approach is to build a template composed of attributes from the taxonomy tree. The product category or type could be the first token in the product title—e.g., “iPad” or “Macbook.” That will follow lower-level or granular attributes from the taxonomy tree, such as brand, size, color, etc. So, the combined title would be: “iPad 64GB - Space Grey.” Attributes from the leaf of the taxonomy can be omitted to keep the product title simple.</p>

<p>Product enrichment is typically seen as a larger and more continuous process than just improving product titles in any online retail setup. Apart from taxonomic levels, there are other ways to define the enrichment levels. Most of them are based on the importance of the attribute information. [<a data-type="noteref" href="ch09.xhtml#footnote_9_13">9</a>] has defined these taxonomies, shown in <a data-type="xref" href="#table_showing_the_categorization_of_var">Figure 9-12</a>. Mandatory attributes are part of every product, while nice-to-have attributes provide a high level of detail that can be missing.</p>
<figure><div id="table_showing_the_categorization_of_var" class="figure">
<img src="Images/pnlp_0912.png" alt="Table showing the categorization of various enrichment levels [_13]" width="764" height="301"/>
<h6><span class="label">Figure 9-12. </span>Table showing the categorization of various enrichment levels [<a data-type="noteref" href="ch09.xhtml#footnote_9_13">9</a>]</h6>
</div></figure>

<p>Next, we’ll turn our attention to product duplication<a contenteditable="false" data-type="indexterm" data-primary="product enrichment" data-startref="ch09_term21" id="idm45969587814312"/><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="product enrichment" data-startref="ch09_term22" id="idm45969587812936"/> and matching.</p>
</div></section>

<section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Product Deduplication and Matching"><div class="sect2" id="product_deduplication_and_matching">
<h2 class="less_space">Product Deduplication and Matching</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="product deduplication and matching" id="ch09_term23"/><a contenteditable="false" data-type="indexterm" data-primary="product deduplication and matching" id="ch09_term24"/>Products are often added to the platform by third-party sellers, and different sellers can refer to the same product by different names. They seldom follow the same terminology, which can result in the same product getting listed with multiple titles and product images. For example, “Garmin nuvi 2699LMTHD GPS Device” and “nuvi 2699LMTHD Automobile Portable GPS Navigator” refer to the same product.</p>

<p>In addition to product categorization and attribute extraction, product deduplication is also an important aspect of e-commerce. Identifying duplicate products is also a challenging task, and we’ll discuss ways to handle this problem via attribute match, title match, and image match.</p>

<section data-type="sect3" data-pdf-bookmark="Attribute match"><div class="sect3" id="attribute_match">
<h3>Attribute match</h3>

<p><a contenteditable="false" data-type="indexterm" data-primary="attribute match" id="idm45969587803048"/>If two products are the same, then the values of various attributes must be the same. Hence, once the attributes are extracted, we compare values for attributes for both of the products in question. Ideally, maximum overlap of the attributes will indicate strong product matching. In order to match the attribute values, we can use string matching [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587801352-marker" href="ch09.xhtml#idm45969587801352">11</a>]. Two strings can be matched via exact character match or using string similarity metrics. String similarity metrics are typically built to take care of slight spelling mistakes, abbreviations, etc.</p>

<p>Abbreviations are a big problem in product-related data. The same word can be represented in multiple accepted abbreviations. They should be mapped to a consistent form (discussed in <a data-type="xref" href="#product_enrichment">“Product Enrichment”</a>) or form agnostic rules formulated to tackle the problem. An intuitive rule to tackle abbreviations while matching two words could be matching the first and last characters and checking whether those characters belong to the shorter or longer word.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Title match"><div class="sect3" id="title_match">
<h3>Title match</h3>

<p><a contenteditable="false" data-type="indexterm" data-primary="title match" id="ch09_term25"/>One product can often have multiple title variants. Below are some title variants for the same GPS navigator, sold by different sellers:</p>
<ul class="list_style_type_none">
<li>
	<p>Garmin nuvi 2699LMTHD GPS Device</p></li>
<li>
	<p>nuvi 2699LMTHD Automobile Portable GPS Navigator</p></li>
<li>
	<p>Garmin nuvi 2699LMTHD — GPS navigator — automotive 6.1 in</p></li>
<li>
	<p>Garmin Nuvi 2699lmthd Gps Device</p></li>
<li>
	<p>Garmin nuvi 2699LMT HD 6” GPS with Lifetime Maps and HD Traffic <span class="keep-together">(010–01188–00)</span></p></li>
</ul>

<p>To retrieve all such instances, a matching mechanism is needed to identify them as the same. A simple method could be to compare bigrams and trigrams among these titles. It’s also possible to generate title-level features (such as counts of common bigrams and trigrams) and then calculate the Euclidean distance between them. We could use sentence-level embedding and a pair of textual phrases simultaneously to learn a distance metric that improves matching accuracy [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587788152-marker" href="ch09.xhtml#idm45969587788152">12</a>]. This can also be done with a neural network architecture called the Siamese network<a contenteditable="false" data-type="indexterm" data-primary="Siamese networks" id="idm45969587786808"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587785608-marker" href="ch09.xhtml#idm45969587785608">13</a>]. The Siamese <span class="keep-together">network</span> takes two sequences simultaneously and learns to generate the embeddings in such a way that, if the sequences are similar, they appear<a contenteditable="false" data-type="indexterm" data-primary="title match" data-startref="ch09_term25" id="idm45969587783432"/> closer to each other in the embedding space, else farther.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Image match"><div class="sect3" id="image_match">
<h3>Image match</h3>

<p><a contenteditable="false" data-type="indexterm" data-primary="image match" id="idm45969587780200"/>Finally, there could still be irregularities (e.g., abbreviations or domain-specific word usage) in attributes and titles, which are difficult to align with one another. In those cases, product images can serve as rich source information for product matching and deduplication. For image matching, pixel-to-pixel match, feature map matching, or even advanced image-matching techniques like Siamese networks are popular [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587778536-marker" href="ch09.xhtml#idm45969587778536">14</a>], and when applied in this setting can reduce the amount of product duplication. Most of the algorithms are based on the principles of computer vision approaches and depend on image quality and other size-related particulars.</p>
<div data-type="tip"><h6>Tip</h6>


<p><a contenteditable="false" data-type="indexterm" data-primary="A/B testing" id="idm45969587776216"/>A/B testing is a good method of measuring the results and effectiveness of different algorithms in the e-commerce world. For procedures like attribute extraction, product enrichment and A/B testing different models will lead to an impact on business metrics. These metrics can be direct or indirect sales, click-through rates, time spent on one web page, etc., and an improvement in relevant metrics shows that a model works better.</p>
</div>

<p>In a practical setting, all these algorithms are used in conjunction, and their results are combined to deduplicate the products. In the next few sections, we’ll discuss NLP for analyzing product reviews, which are a fundamental part of any online shopping<a contenteditable="false" data-type="indexterm" data-primary="catalogs" data-startref="ch09_term10" id="idm45969587773624"/><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="catalogs" data-startref="ch09_term11" id="idm45969587772248"/><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="product deduplication and matching" data-startref="ch09_term23" id="idm45969587770600"/><a contenteditable="false" data-type="indexterm" data-primary="product deduplication and matching" data-startref="ch09_term24" id="idm45969587768984"/> experience.</p>
</div></section>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Review Analysis"><div class="sect1" id="review_analys">
<h1>Review Analysis</h1>

<p><a contenteditable="false" data-type="indexterm" data-primary="review analysis" id="ch09_term27"/><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="review analysis" id="ch09_term28"/>Reviews are an integral part of any e-commerce portal. They capture direct feedback from customers about products. It’s important to leverage this abundant information and create important signals to send feedback to the e-commerce system so that it can use them to further improve the customer experience. Moreover, reviews can be viewed by all customers, and they directly affect the sales of the products. In this section, we’ll delve deeper into the different facets of review sentiment analysis.</p>

<section data-type="sect2" data-pdf-bookmark="Sentiment Analysis"><div class="sect2" id="sentiment_analysis">
<h2>Sentiment Analysis</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis" id="ch09_term30"/>We covered generic sentiment analysis as a classification task in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>. But there are various nuances when it comes to sentiment analysis for e-commerce reviews. <a data-type="xref" href="#analysis_of_customer_reviews_ratingscom">Figure 9-13</a> shows a screenshot of customer reviews of iPhone X on Amazon. Most of us are familiar with seeing such aspect-level reviews on e-commerce websites—this is where you can slice and dice reviews based on aspects and attributes.</p>
<figure><div id="analysis_of_customer_reviews_ratingscom" class="figure">
<img src="Images/pnlp_0913.png" alt="Analysis of customer reviews: ratings, keywords, and sentiments" width="1118" height="832"/>
<h6><span class="label">Figure 9-13. </span>Analysis of customer reviews: ratings, keywords, and sentiments</h6>
</div></figure>

<p>As you can see, 67% of the reviews have a rating of five stars (i.e., the highest), and 22% of the reviews have the lowest rating of one star. It’s important for an e-commerce company to know what leads customers to give bad ratings. To illustrate this point, <a data-type="xref" href="#a_positive_and_a_negative_review">Figure 9-14</a> shows two examples of extreme reviews of the same product.</p>
<figure><div id="a_positive_and_a_negative_review" class="figure">
<img src="Images/pnlp_0914.png" alt="A positive and a negative review" width="1442" height="316"/>
<h6><span class="label">Figure 9-14. </span>A positive and a negative review</h6>
</div></figure>

<p>Certainly, both of these reviews contain some information about the product, which gives the retailer cues about what customers are thinking. Specifically, negative reviews are more important to understand. In <a data-type="xref" href="#a_positive_and_a_negative_review">Figure 9-14</a>, look at the first review where the customer states that there are issues with phones that are being shipped. It’s mostly related to the defective screen, which the retailer should take care of. In <span class="keep-together">contrast,</span> the positive review expresses generic positive sentiment rather than explicitly pointing out what aspects the user really liked. Hence, it’s crucial to have a full understanding of the reviews. By nature, they’re in the text and mostly in an unstructured format, full of unforced errors such as spelling mistakes, incorrect sentence constructions, incomplete words, and abbreviations. This makes review analysis even more challenging.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>


<p>Typically, a review contains more than one sentence. It’s advisable to break a review into sentences and pass each sentence as one data point. This is also relevant for sentence-wise aspect tagging, aspect-wise sentiment analysis, etc.</p>
</div>

<p>Ratings are considered to be directly proportional to the overall sentiment of the reviews. There are cases where the user mistakenly rates the product poorly but gives a positive review. Understanding emotions directly from the text will help retailers rectify these anomalies during analysis. But in most cases, a review doesn’t talk about just one aspect of the product but tries to cover most aspects of it, ultimately reflecting everything in the review rating.</p>

<p>Take another look at the iPhone X review screenshot in <a data-type="xref" href="#analysis_of_customer_reviews_ratingscom">Figure 9-13</a>. Look at the section where it reads: “Read reviews that mention.” These are nothing but the important keywords Amazon has found may help customers navigate better when skimming through the reviews. This clearly indicates that there are certain aspects customers are talking about. It could be user experience, manufacturing aspects, price, or something else. How can we know what the customer’s emotions or feedback are? So far, we’ve provided only a high-level index of emotion for the entire review, but that won’t allow us to dig down deeper to understand it better. This necessitates an aspect-level understanding of the reviews. These aspects could be pre-defined or extracted from the review data itself. Based on that, the approaches will be supervised or unsupervised<a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis" data-startref="ch09_term30" id="idm45969587742856"/> accordingly.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Aspect-Level Sentiment Analysis"><div class="sect2" id="aspect_level_sentiment_analysis">
<h2>Aspect-Level Sentiment Analysis</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="aspect-based sentiment analysis" id="ch09_term32"/><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis" data-secondary="aspect-level" id="ch09_term31"/>Before we start the discussion of various techniques for aspect-level sentiment analysis, we need to understand what an aspect is. An <em>aspect</em><a contenteditable="false" data-type="indexterm" data-primary="aspects" id="idm45969587736104"/> is a semantically rich, concept-centric collection of words that indicates certain properties or characteristics of the product. For example, in <a data-type="xref" href="#aspect_level_ratings_on_reviews_given_i">Figure 9-15</a>, we’ll see the kind of aspects a travel website might have: location, value, and cleanliness.</p>

<p>This isn’t constrained only to the inherent attributes of the product, but also to anything and everything related to the supply, presentation, delivery, return, quality, etc., around the product. Typically, a clear distinguishing of these aspects is difficult unless already assumed.</p>

<p>If the retailer has a clear understanding of the product’s aspects, then finding aspects falls under the supervised category of algorithms. There’s a common technique for using seed words or seed lexicons<a contenteditable="false" data-type="indexterm" data-primary="seed words or seed lexicons" id="idm45969587732216"/>, which essentially hints at the crucial tokens that could be present under a particular aspect. For example, regarding user experience as an aspect for iPhone X, seed words could be screen resolution, touch, response time, etc. Again, it’s up to the retailer at what level of granularity they’d like to operate. For example, screen quality alone could be a more granular aspect. In the next sections, we’ll look at supervised and unsupervised techniques of aspect-level sentiment <span class="keep-together">analysis.</span></p>

<section data-type="sect3" data-pdf-bookmark="Supervised approach"><div class="sect3" id="supervised_approach">
<h3>Supervised approach</h3>

<p><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis" data-secondary="supervised approach" id="idm45969587728136"/>A supervised approach depends mainly on seed words. It tries to identify the presence of these seed words in a sentence. If it identifies a particular seed word in a sentence, it tags the sentence with the corresponding aspect. Once all the sentences are tagged to any of the aspects, the sentiment analysis has to be done at a sentence level. Now, since we already have an additional tag for each sentence, sentences having one tag can be filtered, and sentiments for them can be aggregated to understand the customer’s feedback for that aspect. For example, all review sentences related to screen quality, touch, and response time can be grouped together.</p>

<p>For a change, let’s look at an example from a travel website in <a data-type="xref" href="#aspect_level_ratings_on_reviews_given_i">Figure 9-15</a>, where the aspect-level sentiment analysis is apparent. As you see, there are specific ratings for location, check-in, value, and cleanliness, which are semantic concepts rightfully extracted from the data to present a more detailed view of the reviews.</p>
<figure class="width-90"><div id="aspect_level_ratings_on_reviews_given_i" class="figure">
<img src="Images/pnlp_0915.png" alt="Aspect-level ratings on reviews given in a travel website" width="1344" height="1554"/>
<h6><span class="label">Figure 9-15. </span>Aspect-level ratings on reviews given on a travel website</h6>
</div></figure>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Unsupervised approach"><div class="sect3" id="unsupervised_approach">
<h3>Unsupervised approach</h3>

<p><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis" data-secondary="unsupervised " id="ch09_term33"/>As it’s understood, arranging a good-quality seed lexicon is difficult, so there are unsupervised ways of detecting aspects. Topic modeling<a contenteditable="false" data-type="indexterm" data-primary="topic modeling" id="idm45969587717848"/> is a useful technique in identifying latent topics present in a document. We can think of these topics as aspects in our case. Imagine if we can group sentences that are talking about the same aspect. That’s exactly what a topic modeling algorithm<a contenteditable="false" data-type="indexterm" data-primary="topic modeling" data-secondary="algorithms" id="idm45969587716344"/> does. One of the most popular topic modeling approaches is the latent Dirichlet algorithm (LDA)<a contenteditable="false" data-type="indexterm" data-primary="latent Dirichlet allocation (LDA)" id="idm45969587714728"/><a contenteditable="false" data-type="indexterm" data-primary="LDA (latent Dirichlet allocation)" id="idm45969587713656"/>. We covered LDA in more detail in <a data-type="xref" href="ch07.xhtml#topics_in_brief">Chapter 7</a>.</p>

<p>In a similar fashion, we can pre-define the number of aspects we expect out of the set of sentences. The topic modeling algorithm also outputs the probability of each word to be in all the topics (here, aspects). Hence, it’s also possible to group words that have a high chance of belonging to a certain aspect and call them characteristic words for that particular aspect. This will ultimately help annotate the unannotated aspects.</p>

<p>Further, a more unsupervised approach can be performed by creating sentence representation and then performing clustering as opposed to LDA. In our experience, the latter sometimes gives better results when there are fewer review <span class="keep-together">sentences.</span> In the next section, we’ll see how we can predict ratings for all of these aspects and provide a more granular view of user<a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis" data-secondary="aspect-based" data-startref="ch09_term31" id="idm45969587709240"/><a contenteditable="false" data-type="indexterm" data-primary="aspect-based sentiment analysis" data-startref="ch09_term32" id="idm45969587707592"/><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis" data-secondary="unsupervised" data-startref="ch09_term33" id="idm45969587706312"/> preferences.</p>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Connecting Overall Ratings to Aspects"><div class="sect2" id="connecting_overall_ratings_to_aspects">
<h2>Connecting Overall Ratings to Aspects</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="review analysis" data-secondary="connecting overall ratings to aspects" id="ch09_term35"/><a contenteditable="false" data-type="indexterm" data-primary="aspects" data-secondary="connecting overall ratings to" id="ch09_term34"/>We’ve already seen how we can detect the sentiment for each aspect. Typically, users also give an overall rating. The idea here is to connect that rating to individual aspect-level sentiment. For this, we use a technique called latent rating regression analysis (LARA)<a contenteditable="false" data-type="indexterm" data-primary="latent rating regression analysis (LARA)" id="idm45969587698824"/><a contenteditable="false" data-type="indexterm" data-primary="LARA (latent rating regression analysis)" id="idm45969587697624"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_9_2-marker" href="ch09.xhtml#footnote_9_2">15</a>]. Details of LARA implementation are outside the scope of this book, but here’s an example of the system generating aspect-level ratings for a hotel review. The table shown in <a data-type="xref" href="#aspect_wise_sentiment_prediction_using">Figure 9-16</a> from [<a data-type="noteref" href="ch09.xhtml#footnote_9_2">15</a>] gives some details on these aspect-based ratings.</p>
<figure class="no-frame"><div id="aspect_wise_sentiment_prediction_using" class="figure">
<img src="Images/pnlp_0916.png" alt="Aspect-wise sentiment prediction using LARA" width="1359" height="1053"/>
<h6><span class="label">Figure 9-16. </span>Aspect-wise sentiment prediction using LARA</h6>
</div></figure>

<p>We can assume that the final rating is nothing but a weighted combination of individual aspect-level sentiments. The objective will be estimating the weights and the aspect-level sentiment together. It’s also possible to perform these two operations sequentially—i.e., first determining the aspect-level sentiment and then the weights.</p>

<p>These weights on top of various sentiments present for each aspect will ultimately indicate how much importance a reviewer places on that specific topic. It’s possible that a customer is extremely unhappy with some aspect, but maybe that aspect isn’t their priority. This information is crucial for e-retailers to have before they take any action. More details of this implementation are covered in [<a data-type="noteref" href="ch09.xhtml#footnote_9_2">15</a>].</p>

<div data-type="tip"><h6>Tip</h6>
<p>User information is also key in handling reviews. Imagine a scenario where a popular user, as opposed to a less-popular user, writes a good review. The user matters! While performing the review analysis, a “user weight”<a contenteditable="false" data-type="indexterm" data-primary="user weights" id="idm45969587686856"/> can be defined for all users based on their ratings (generally given by other peers) and can be used in all calculations to discount the reviewer bias.</p>
</div>

<p>We’ll now go deeper into an example algorithm to understand<a contenteditable="false" data-type="indexterm" data-primary="aspects" data-secondary="connecting overall ratings to" data-startref="ch09_term34" id="idm45969587684808"/><a contenteditable="false" data-type="indexterm" data-primary="review analysis" data-secondary="connecting overall ratings to aspects" data-startref="ch09_term35" id="idm45969587683064"/> aspects.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Understanding Aspects"><div class="sect2" id="understanding_aspects">
<h2>Understanding Aspects</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="aspects" data-secondary="understanding" id="ch09_term36"/>It’s a business objective for retailers to analyze a particular aspect of a product and how various sentiments and opinions have been reflected in reviews. Similarly, a user might be interested in a specific aspect of a product and may want to scan through all the reviews on it. Hence, once we derive all the aspects and tag each sentence with them, it’s possible to group the sentences by aspects. But given the huge volume of reviews an e-commerce website encounters, there will still be a lot of sentences under an aspect. Here, a summarization algorithm<a contenteditable="false" data-type="indexterm" data-primary="summarization algorithms" id="idm45969587677112"/> may save the day. Think about a situation where we need to take an action regarding an aspect but we don’t have the capacity to go through all the sentences regarding that particular aspect. We’d need an automatic algorithm that can pick and choose the best representative sentences for that aspect.</p>

<p>LexRank<a contenteditable="false" data-type="indexterm" data-primary="LexRank" id="idm45969587675176"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587673912-marker" href="ch09.xhtml#idm45969587673912">16</a>] is an algorithm, similar to PageRank, that assumes each sentence is a node and connects via sentence similarity. Once done, it picks the most central sentences out of it and presents an extractive summary of the sentences under an aspect. An example pipeline for review analysis, covering overall and aspect-level sentiments, is shown in <a data-type="xref" href="#the_complete_flowchart_of_review_analys">Figure 9-17</a>.</p>


<p>In this pipeline, we start with a set of reviews. After applying review-level aspect detection, we can run sentiment analysis for every aspect as well as aggregate them based on aspects. After aggregation, summarization algorithms such as LexRank can be used to summarize them. In the end, we can take away the overall sentiment for an aspect of a product as well as get a summary of opinions explaining the sentiment.</p>

<figure><div id="the_complete_flowchart_of_review_analys" class="figure">
<img src="Images/pnlp_0917.png" alt="The complete flowchart of review analysis: overall sentiments, aspect-level sentiments, and aspect-wise significant reviews" width="978" height="1220"/>
<h6><span class="label">Figure 9-17. </span>The complete flowchart of review analysis<a contenteditable="false" data-type="indexterm" data-primary="review analysis" data-secondary="example pipeline" id="idm45969587668312"/>: overall sentiments, aspect-level sentiments, and aspect-wise significant reviews</h6>
</div></figure>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>A complete understanding of a product can only be achieved by both user reviews<a contenteditable="false" data-type="indexterm" data-primary="user reviews" id="idm45969587665672"/> and editorial reviews<a contenteditable="false" data-type="indexterm" data-primary="editorial reviews" id="idm45969587664248"/>. Editorial reviews are generally provided by expert users or domain experts. These reviews are more reliable and can be shown at the top of the review section. But on the other hand, general user reviews reveal the true picture of the product experience from all users’ perspectives. Hence, melding editorial reviews with general user reviews is important. That may be achieved by mixing both kinds of reviews in the top section and ranking them accordingly.</p>
</div>

<p>We’ve seen how review analysis can be done from the perspective of aspects, sentiment, and ratings. In the next sections, we’ll briefly cover the nuances of personalization<a contenteditable="false" data-type="indexterm" data-primary="review analysis" data-startref="ch09_term27" id="idm45969587661768"/><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="review analysis" data-startref="ch09_term28" id="idm45969587660392"/><a contenteditable="false" data-type="indexterm" data-primary="aspects" data-secondary="understanding" data-startref="ch09_term36" id="idm45969587658744"/> for e-commerce.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Recommendations for E-Commerce"><div class="sect1" id="recommendations_for_e_commerce">
<h1>Recommendations for E-Commerce</h1>

<p><a contenteditable="false" data-type="indexterm" data-primary="recommendations" data-secondary="for e-commerce" data-secondary-sortas="e-commerce" id="ch09_term40"/><a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="recommendations for" id="ch09_term39"/>In <a data-type="xref" href="ch07.xhtml#topics_in_brief">Chapter 7</a>, we discussed various techniques for recommendations using textual data. Along with product search and review analysis, product recommendation<a contenteditable="false" data-type="indexterm" data-primary="product recommendations" data-seealso="recommendations" id="idm45969587650184"/> is another main pillar in e-commerce. In <a data-type="xref" href="#comprehensive_study_of_techniques_for_v">Figure 9-18</a>, we show a comprehensive study on the different algorithms used as well as the data utilization required for recommendations in various scenarios [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587647400-marker" href="ch09.xhtml#idm45969587647400">17</a>].</p>
<figure><div id="comprehensive_study_of_techniques_for_v" class="figure">
<img src="Images/pnlp_0918.png" alt="Comprehensive study of techniques for various e-commerce recommendation scenarios" width="1029" height="1418"/>
<h6><span class="label">Figure 9-18. </span>Comprehensive study of techniques for various e-commerce <a contenteditable="false" data-type="indexterm" data-primary="recommendations" data-secondary="techniques for" id="idm45969587644456"/>recommendation scenarios</h6>
</div></figure>

<p>In e-commerce, products are recommended based on a user’s purchase profile: fashionista, book lover, enjoyer of popular products, etc. These purchase profiles can be inferred from the user’s behavior on the platform. Imagine a user has interacted with a set of products in the platform via viewing or clicking or purchasing them. These interactions contain information that can help decide the set of products the user will be interested in next. This can be achieved by neighborhood-based methods where we look for similar products (in terms of attributes, purchase history, customers who purchased them, etc.) and provide them in the form of recommendations.</p>

<p>Clicks, purchase history, etc., are mainly numerical data, whereas e-commerce also has a huge amount of textual data that can be utilized in product recommendations. Along with numerical sources, the recommendation algorithm can include product descriptions in text to induce better understanding about those products and provide more similar products that match with even more granular attributes. For example, the clothing material (e.g., 52% cotton, 48% polyester) mentioned in a product description could be important textual information to consider while looking for similar apparel.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>


<p>Recommendation engines<a contenteditable="false" data-type="indexterm" data-primary="recommendation engines" data-seealso="recommender systems" id="idm45969587639512"/><a contenteditable="false" data-type="indexterm" data-primary="recommender systems" data-secondary="e-commerce" id="idm45969587638104"/> deal with information from various sources. Proper matching of various data tables and consistency of the information across various data sources is important to maintain. For example, while collating the information about product attributes and product transaction history, the consistency of the information should be checked carefully. Complementary and substitute data can give indications about data quality. One should check for anomalous behavior while working with multifarious data sources, as in the case of e-commerce recommendation.</p>
</div>

<p>Reviews contain a lot of nuanced information and user opinions about products, which can guide product recommendations. Imagine a user providing feedback regarding the screen size of a mobile device (e.g., “I would have preferred a smaller screen”). The specific feedback<a contenteditable="false" data-type="indexterm" data-primary="feedback" data-secondary="from customers" data-see="review analysis" data-secondary-sortas="customers" id="idm45969587635208"/> from the user for a specific attribute of the product can provide a strong signal to filter the set of related products to make the recommendation more useful to the user. We’ll look at a detailed case study relating to this and see how we can potentially build a recommendation system for e-commerce leveraging product reviews. Reviews are not only useful for finding better products for recommendation but can also reveal the interrelationships between various products via nuanced feedback from customers.</p>

<section data-type="sect2" data-pdf-bookmark="A Case Study: Substitutes and Complements"><div class="sect2" id="a_case_study_substitutes_and_complement">
<h2>A Case Study: Substitutes and Complements</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="recommendations" data-secondary="case study" id="ch09_term41"/><a contenteditable="false" data-type="indexterm" data-primary="recommender systems" id="idm45969587629112"/>Recommender systems are built on the idea of “similar” products. This similarity can be defined as content based or user profile based. There’s another way of identifying item interrelationships specifically in an e-commerce setting.</p>

<p><em>Complements</em> are products that are typically bought together<a contenteditable="false" data-type="indexterm" data-primary="complements" id="idm45969587626856"/>. On the other hand, there are pairs that are bought in lieu of the other, and they’re known as substitute<a contenteditable="false" data-type="indexterm" data-primary="substitutes" id="idm45969587625496"/> pairs. Even though the economic definition is much more rigorous, these lines of thought typically capture the behavioral aspect of product purchase. Sometimes, due to huge disparities in individual user behavior, it’s difficult to infer the interrelationships between products from them. But in aggregation, these user interactions can reveal interesting properties about substitution and complementarity between products. There are several ways [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587623800-marker" href="ch09.xhtml#idm45969587623800">18</a>] we can identify substitutes and complements using user interaction data, but here, we’ll focus on an approach that relies primarily on the reviews as a form of textual information present in the products.</p>

<p>Julian McAuley<a contenteditable="false" data-type="indexterm" data-primary="McAuley, Julian" id="idm45969587622296"/> has presented [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_9_6-marker" href="ch09.xhtml#footnote_9_6">19</a>] a comprehensive way of understanding product interrelationships in a framework where the query product is given and the framework returns the ranked products, both substitutes and complements, (see <a data-type="xref" href="#substitutes_and_complements_based_on_pr">Figure 9-19</a>). We’ll discuss this application as a case study in the context of <span class="keep-together">e-commerce.</span></p>
<figure><div id="substitutes_and_complements_based_on_pr" class="figure">
<img src="Images/pnlp_0919.png" alt="Substitutes and complements based on product reviews [_6]" width="1376" height="1351"/>

<h6><span class="label">Figure 9-19. </span><a contenteditable="false" data-type="indexterm" data-primary="review analysis" data-secondary="substitutes and complements based on" id="idm45969587615736"/><a contenteditable="false" data-type="indexterm" data-primary="substitutes" id="idm45969587614344"/><a contenteditable="false" data-type="indexterm" data-primary="complements" id="idm45969587613240"/>Substitutes and complements based on product reviews [<a data-type="noteref" href="ch09.xhtml#footnote_9_6">19</a>]</h6>
</div></figure>

<section data-type="sect3" data-pdf-bookmark="Latent attribute extraction from reviews"><div class="sect3" id="latent_attribute_extraction_from_review">
<h3>Latent attribute extraction from reviews</h3>

<p><a contenteditable="false" data-type="indexterm" data-primary="latent attribute extraction" id="ch09_term44"/><a contenteditable="false" data-type="indexterm" data-primary="review analysis" data-secondary="latent attribute extraction from" id="ch09_term43"/><a contenteditable="false" data-type="indexterm" data-primary="attribute extraction" data-secondary="latent" id="ch09_term42"/>Typically, as we’ve discussed, reviews contain specific information about product attributes. Explicit extraction of attributes from reviews may have limitations in representation, as we need to define an explicit ontology, so instead, we learn them via a latent vector representation. The details of latent factor models are outside the scope of this book, but an interested reader can find the relevant material at [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587604072-marker" href="ch09.xhtml#idm45969587604072">20</a>].</p>

<p>Each product is associated with a review. One review can discuss or mention various opinions regarding aspects related to the product. While these topics are latent and can’t be identified distinctly, we can obtain a distribution of the share of discussion on various attributes as they’re discussed in the review. This distribution can be modeled on all the reviews related to that product using popular topic models like LDA<a contenteditable="false" data-type="indexterm" data-primary="LDA (latent Dirichlet allocation)" id="idm45969587601784"/><a contenteditable="false" data-type="indexterm" data-primary="latent Dirichlet allocation (LDA)" id="idm45969587600664"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587599416-marker" href="ch09.xhtml#idm45969587599416">21</a>]. This provides a vectorial representation, or “topic vector<a contenteditable="false" data-type="indexterm" data-primary="topic vectors" id="idm45969587598168"/>,” which tells us how a particular product has been discussed in reviews. This representation can be thought of as a feature representation (from the usual ML terminology) of the product itself.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Product linking"><div class="sect3" id="product_linking">
<h3>Product linking</h3>

<p>The next<a contenteditable="false" data-type="indexterm" data-primary="product linking" id="idm45969587594648"/> task is to understand how the two products are linked. We already obtained topic vectors, which capture the intrinsic properties of the product in a latent attribute space. Now, given a pair of products, we want to create a combined feature vector out of the respective topic vectors for the products and then predict if there’s any relationship between them. This can be viewed as a binary classification problem where the features have to be obtained from the respective topic vectors for the product pair. We call this process “link prediction<a contenteditable="false" data-type="indexterm" data-primary="link prediction" id="idm45969587592824"/>,” similar to [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969587591592-marker" href="ch09.xhtml#idm45969587591592">22</a>].</p>

<p>To ensure that the topic vector is expressive enough to predict a link or relationship between a product pair, the objectives of obtaining topic vectors and link prediction can be solved jointly rather than one after the other—i.e., we learn topic vectors<a contenteditable="false" data-type="indexterm" data-primary="topic hierarchy" id="idm45969587589640"/> for each product as well as the function to combine them for a product pair.</p>

<p><a data-type="xref" href="#topic_vector_and_topic_hierarchy_expres">Figure 9-20</a> depicts the interpretation of a topic vector after it’s learned, which is covered in detail in [<a data-type="noteref" href="ch09.xhtml#footnote_9_6">19</a>]. It shows how a topic vector becomes expressive enough to capture the intrinsic attributes of the product. Hierarchical dependence also emerges from such a representation, which in a way depicts the taxonomy that the product belongs to.</p>

<p>This case study shows that reviews contain useful information that reveals various interrelationships between products. Such latent representation, which has more expressivity than exact extraction of attributes from reviews, has shown to be efficient not only for the link prediction task, but also for revealing meaningful notions about the product taxonomy. Such representation can be useful for making better product recommendations via better product linking and obtaining more similar<a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-secondary="recommendations for" data-startref="ch09_term39" id="idm45969587585000"/><a contenteditable="false" data-type="indexterm" data-primary="recommendations" data-secondary="for e-commerce" data-secondary-sortas="e-commerce" data-startref="ch09_term40" id="idm45969587583352"/><a contenteditable="false" data-type="indexterm" data-primary="recommendations" data-secondary="case study" data-startref="ch09_term41" id="idm45969587581432"/> products.</p>

<figure><div id="topic_vector_and_topic_hierarchy_expres" class="figure">
<img src="Images/pnlp_0920.png" alt="Topic vector and topic hierarchy express how different taxonomic identities and relations are captured in reviews [_6]" width="1420" height="271"/>
<h6><span class="label">Figure 9-20. </span>Topic vector and topic hierarchy express how different taxonomic identities and relations are captured in reviews [<a data-type="noteref" href="ch09.xhtml#footnote_9_6">19</a>]</h6>
</div></figure>


</div></section>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Wrapping Up"><div class="sect1" id="wrapping_up-id00083">
<h1>Wrapping Up</h1>

<p>A primary driver behind the e-commerce industry’s immense success has been massive data collection and adaptation of data-driven decisions. NLP techniques have played a significant role in improving user experience and driving more revenue in e-commerce and retail industries.</p>

<p>In this chapter, we covered different aspects of NLP in e-commerce. We started with an introduction on faceted search, then delved deep into product attributes. These areas are closely linked to product enrichment and categorization. We then covered review analysis and product recommendations for e-commerce. Most of the examples and the setting in this chapter are product commerce, but the same techniques can be used in other areas as well, such as travel and food. We hope this chapter will be a good starting point for baking NLP and intelligence into your domain.<a contenteditable="false" data-type="indexterm" data-primary="e-commerce and retail" data-startref="ch09_term1" id="idm45969587573512"/><a contenteditable="false" data-type="indexterm" data-primary="retail" data-see="e-commerce and retail" id="idm45969587572040"/></p>
</div></section>
<div data-type="footnotes"><h5>Footnotes</h5></div><div data-type="footnotes"><h5>References</h5><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969588073464">[<a href="ch09.xhtml#idm45969588073464-marker">1</a>] Clement, J. “<a href="https://oreil.ly/RyAAZ">Global Retail E-commerce Sales 2014–2023”</a>. <em>Statista</em>, March 19, 2010.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969588022984">[<a href="ch09.xhtml#idm45969588022984-marker">2</a>] Fletcher, Iain. “<a href="https://oreil.ly/mfr4s">How to Increase E-commerce Conversion with Site Search”</a>. <em>Search and Content Analytics (blog)</em>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587992872">[<a href="ch09.xhtml#idm45969587992872-marker">3</a>] Elasticsearch DSL. <a href="https://oreil.ly/KdKVS">Faceted Search</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587920216">[<a href="ch09.xhtml#idm45969587920216-marker">4</a>] Huang, Zhiheng, Wei Xu, and Kai Yu. <a href="https://oreil.ly/iE4ag">“Bidirectional LSTM-CRF Models for Sequence Tagging”</a>. 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_9_19">[<a href="ch09.xhtml#footnote_9_19-marker">5</a>] Majumder, B. P., Aditya Subramanian, Abhinandan Krishnan, Shreyansh Gandhi, and Ajinkya More. <a href="https://oreil.ly/nvrly">“Deep Recurrent Neural Networks for Product Attribute Extraction in eCommerce”</a>. 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_9_9">[<a href="ch09.xhtml#footnote_9_9-marker">6</a>] Logan IV, Robert L., Samuel Humeau, and Sameer Singh. <a href="https://oreil.ly/Jt11M">“Multimodal Attribute Extraction”</a>. 2017.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587868840">[<a href="ch09.xhtml#idm45969587868840-marker">7</a>] Popescu, Ana-Maria, and Oren Etzioni. “Extracting Product Features and Opinion from Reviews.” <em>Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing</em> (2005): 339–346.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587867400">[<a href="ch09.xhtml#idm45969587867400-marker">8</a>] Wang, Tao, Yi Cai, Ho-fung Leung, Raymond YK Lau, Qing Li, and Huaqing Min. “Product Aspect Extraction Supervised with Online Domain Knowledge.” <em>Knowledge-Based Systems</em> 71 (2014): 86–100.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_9_13">[<a href="ch09.xhtml#footnote_9_13-marker">9</a>] Trietsch, R. C. “Product Attribute Value Classification from Unstructured Text in E-Commerce.” (master’s thesis, Eindhoven University of Technology, 2016).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587848744">[<a href="ch09.xhtml#idm45969587848744-marker">10</a>] <a href="https://oreil.ly/UkKcp">“Product Classification with AI: How Machine Learning Sped Up Logistics for Aeropost”</a>. <em>Semantics3 (blog)</em>, June 25, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587801352">[<a href="ch09.xhtml#idm45969587801352-marker">11</a>] Cheatham, Michelle, and Pascal Hitzler. “String Similarity Metrics For Ontology Alignment.” <em>International Semantic Web Conference</em>. Berlin: Springer, 2013: 294–309</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587788152">[<a href="ch09.xhtml#idm45969587788152-marker">12</a>] Bilenko, Mikhail and Raymond J. Mooney. “Adaptive Duplicate Detection Using Learnable String Similarity Measures.” <em>Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (2003): 39–48.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587785608">[<a href="ch09.xhtml#idm45969587785608-marker">13</a>] Neculoiu, Paul, Maarten Versteegh, and Mihai Rotaru. “Learning Text Similarity with Siamese Recurrent Networks.” <em>Proceedings of the First Workshop on Representation Learning for NLP</em> (2016): 148–157.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587778536">[<a href="ch09.xhtml#idm45969587778536-marker">14</a>] Zagoruyko, Sergey and Nikos Komodakis. “Learning to Compare Image Patches via Convolutional Neural Networks.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em> (2015): 4353–4361.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_9_2">[<a href="ch09.xhtml#footnote_9_2-marker">15</a>] Wang, Hongning, Yue Lu, and Chengxiang Zhai. “Latent Aspect Rating Analysis on Review Text Data: A Rating Regressions Approach.” <em>Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (2010): 783–792.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587673912">[<a href="ch09.xhtml#idm45969587673912-marker">16</a>] Erkan, Günes and Dragomir R. Radev. “LexRank: Graph-Based Lexical Centrality as Salience in Text Summarization.” <em>Journal of Artificial Intelligence Research</em> 22 (2004): 457–479.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587647400">[<a href="ch09.xhtml#idm45969587647400-marker">17</a>] Sarwar, Badrul, George Karypis, Joseph Konstan, and John Riedl. “Analysis of Recommendation Algorithms for E-Commerce.” <em>Proceedings of the 2nd ACM Conference on Electronic Commerce</em> (2000): 158–167.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587623800">[<a href="ch09.xhtml#idm45969587623800-marker">18</a>] Misra, Subhasish, Arunita Das, Bodhisattwa Majumder, and Amlan Das. “System for calculating competitive interrelationships in item-pairs.” US Patent Application 15/834,054, filed April 25, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_9_6">[<a href="ch09.xhtml#footnote_9_6-marker">19</a>] McAuley, Julian, Rahul Pandey, and Jure Leskovec. “Inferring Networks of Substitutable and Complementary Products.” <em>Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (2015): 785–794.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587604072">[<a href="ch09.xhtml#idm45969587604072-marker">20</a>] McAuley, Julian and Jure Leskovec. “Hidden Factor and Hidden Topics: Understanding Rating Dimensions with Review Text.” <em>Proceedings of the 7th ACM Conference on Recommender Systems</em> (2013): 165–172.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587599416">[<a href="ch09.xhtml#idm45969587599416-marker">21</a>] Blei, David M., Andrew Y. Ng, and Michael I. Jordan. “Latent Dirichlet Allocation.” <em>Journal of Machine Learning Research</em> 3 (2003): 993–1022.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969587591592">[<a href="ch09.xhtml#idm45969587591592-marker">22</a>] Menon, Aditya Krishna and Charles Elkan. “Link Prediction via Matrix Factorization.” <em>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em>. Berlin: Springer, 2011: 437–452</p></div></div></section></div>



  </body>
</html>