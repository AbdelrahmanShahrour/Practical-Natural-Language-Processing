<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<link href="Styles/Style00.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style01.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style02.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style03.css" rel="stylesheet" type="text/css" />
<style type="text/css" title="ibis-book">
    @charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0 !important}#sbo-rt-content div.preface p.byline+p.byline{margin:0 !important}#sbo-rt-content div.sect1&gt;p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1&gt;p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]&gt;div&gt;h1,#sbo-rt-content section[data-type="preface"]&gt;div&gt;h1,#sbo-rt-content section[data-type="appendix"]&gt;div&gt;h1,#sbo-rt-content section[data-type="glossary"]&gt;div&gt;h1,#sbo-rt-content section[data-type="bibliography"]&gt;div&gt;h1,#sbo-rt-content section[data-type="index"]&gt;div&gt;h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content div.figure h6,#sbo-rt-content figure h6,#sbo-rt-content figure figcaption{font-size:.9rem !important;text-align:center;font-weight:normal !important;font-style:italic;font-family:serif !important;text-transform:none !important;letter-spacing:normal !important;color:#000;padding-top:.25em !important;margin-top:0 !important;page-break-before:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]&gt;div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:2em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content p[data-type="footnote"]{font-size:90% !important;line-height:1.2em !important;margin-left:2.5em !important;text-indent:-2.3em !important}#sbo-rt-content p[data-type="footnote"] sup{display:inline-block !important;position:static !important;width:2em !important;text-align:right !important;font-size:100% !important;padding-right:.5em !important}#sbo-rt-content p[data-type="footnote"] a[href$="-marker"]{font-family:sans-serif !important;font-size:90% !important;color:#8e0012 !important}#sbo-rt-content p[data-type="footnote"] a[data-type="xref"]{margin:0 !important;padding:0 !important;text-indent:0 !important}#sbo-rt-content a[data-type="noteref"]{font-family:sans-serif !important;color:#8e0012;margin-left:0;padding-left:0}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dl{margin-bottom:1.5em !important}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important;line-height:1.25rem;font-style:italic}#sbo-rt-content dd{margin:10px 0 .25em 1.5em !important;line-height:1.65em !important}#sbo-rt-content dd p{padding:0 !important;margin:0 0 10px !important}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul&gt;li,#sbo-rt-content ol ul,#sbo-rt-content ol ul&gt;li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul&gt;li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul&gt;li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul&gt;li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol&gt;li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol&gt;li,#sbo-rt-content ul ol,#sbo-rt-content ul ol&gt;li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol&gt;li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol&gt;li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol&gt;li&gt;ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol&gt;li&gt;ol&gt;li&gt;ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div[data-type="tip"] figure h6,#sbo-rt-content div[data-type="note"] figure h6,#sbo-rt-content div[data-type="warning"] figure h6,#sbo-rt-content div[data-type="caution"] figure h6,#sbo-rt-content div[data-type="important"] figure h6{font-family:serif !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content table li{margin:10px 0 0 .25em !important}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:top;font-size:80%}#sbo-rt-content th{vertical-align:bottom}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller;word-break:break-all}#sbo-rt-content table.border tbody&gt;tr:last-child&gt;td{border-bottom:transparent}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content div[data-type="equation"] math{font-size:calc(.35em + 1vw)}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index h3{padding:.25em;margin-top:1em !important;background-color:#F0F0F0}#sbo-rt-content div.index li{line-height:130%;list-style-type:none}#sbo-rt-content div.index a.indexterm{color:#8e0012 !important}#sbo-rt-content div.index ul{margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.index ul ul{margin-left:2em !important;margin-top:0 !important}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content pre.break-code,#sbo-rt-content code.break-code,#sbo-rt-content .break-code pre,#sbo-rt-content .break-code code{word-break:break-all}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content .width-10,#sbo-rt-content figure.width-10 img{width:10% !important}#sbo-rt-content .width-20,#sbo-rt-content figure.width-20 img{width:20% !important}#sbo-rt-content .width-30,#sbo-rt-content figure.width-30 img{width:30% !important}#sbo-rt-content .width-40,#sbo-rt-content figure.width-40 img{width:40% !important}#sbo-rt-content .width-50,#sbo-rt-content figure.width-50 img{width:50% !important}#sbo-rt-content .width-60,#sbo-rt-content figure.width-60 img{width:60% !important}#sbo-rt-content .width-70,#sbo-rt-content figure.width-70 img{width:70% !important}#sbo-rt-content .width-80,#sbo-rt-content figure.width-80 img{width:80% !important}#sbo-rt-content .width-90,#sbo-rt-content figure.width-90 img{width:90% !important}#sbo-rt-content .width-full,#sbo-rt-content .width-100{width:100% !important}#sbo-rt-content .sc{text-transform:none !important}#sbo-rt-content .right{float:none !important}#sbo-rt-content a.totri-footnote{padding:0 !important}#sbo-rt-content figure.width-10,#sbo-rt-content figure.width-20,#sbo-rt-content figure.width-30,#sbo-rt-content figure.width-40,#sbo-rt-content figure.width-50,#sbo-rt-content figure.width-60,#sbo-rt-content figure.width-70,#sbo-rt-content figure.width-80,#sbo-rt-content figure.width-90{width:auto !important}#sbo-rt-content p img,#sbo-rt-content pre img{width:1.25em;line-height:1em;margin:0 .15em -.2em}#sbo-rt-content figure.no-frame div.border-box{border:none}#sbo-rt-content .right{text-align:right !important}
    </style>
<style type="text/css" id="font-styles">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }</style>
<style type="text/css" id="font-family">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }</style>
<style type="text/css" id="column-width">#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }</style>

<style type="text/css">body{margin:1em;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}body{background-color:transparent!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style></head>
<body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 2. NLP Pipeline"><div class="chapter" id="nlp_pipeline">
<h1><span class="label">Chapter 2. </span>NLP Pipeline</h1>

<blockquote class="right">
<p class="right"><em>The whole is more than the sum of its parts. It is more correct to say that the whole is something else than the sum of its parts, because summing up is a meaningless procedure, whereas the whole-part relationship is meaningful.</em></p>
<p data-type="attribution" style="text-align:right"><em>Kurt Koffka</em></p>
</blockquote>

<p><a contenteditable="false" data-primary="Koffka, Kurt" data-type="indexterm" id="idm45969611422712"/>In the previous chapter, we saw examples of some common<a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="pipeline" data-see="pipeline" data-type="indexterm" id="idm45969611421256"/> NLP applications that we might encounter in everyday life. If we were asked to build such an application, think about how we would approach doing so at our organization. We would normally walk through the requirements and break the problem down into several sub-problems, then try to develop a step-by-step procedure to solve them. Since language processing is involved, we would also list all the forms of text processing needed at each step. This step-by-step processing of text is known as a<a contenteditable="false" data-primary="pipeline" data-type="indexterm" id="ch02_term1"/> <em>pipeline</em>. It is the series of steps involved in building any NLP model. These steps are common in every NLP project, so it makes sense to study them in this chapter. Understanding some common procedures in any NLP pipeline will enable us to get started on any NLP problem encountered in the workplace. Laying out and developing a text-processing pipeline is seen as a starting point for any NLP application development process. In this chapter, we will learn about the various steps involved and how they play important roles in solving the NLP problem and we’ll see a few guidelines about when and how to use which step. In later chapters, we’ll discuss specific pipelines for various NLP tasks (e.g., Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a>–<a data-type="xref" data-xrefstyle="select:labelnumber" href="ch07.xhtml#topics_in_brief">7</a>).</p>

<p><a data-type="xref" href="#figure_2_1_generic_nlp_pipeline">Figure 2-1</a> shows the main components of a generic pipeline for modern-day, data-driven NLP system development. The key stages<a contenteditable="false" data-primary="pipeline" data-secondary="key stages" data-type="indexterm" id="ch02_term2"/> in the pipeline are as follows:</p>

<ol>
	<li>
	<p>Data acquisition</p>
	</li>
	<li>
	<p>Text cleaning</p>
	</li>
	<li>
	<p>Pre-processing</p>
	</li>
	<li>
	<p>Feature engineering</p>
	</li>
	<li>
	<p>Modeling</p>
	</li>
	<li>
	<p>Evaluation</p>
	</li>
	<li>
	<p>Deployment</p>
	</li>
	<li>
	<p>Monitoring and model updating</p>
	</li>
</ol>

<figure><div id="figure_2_1_generic_nlp_pipeline" class="figure"><img alt="Generic NLP pipeline" src="Images/pnlp_0201.png" width="1288" height="409"/>
<h6><span class="label">Figure 2-1. </span>Generic NLP pipeline</h6>
</div></figure>

<p><a contenteditable="false" data-primary="pipeline" data-secondary="key stages" data-startref="ch02_term2" data-type="indexterm" id="idm45969611401016"/><a contenteditable="false" data-primary="pipeline" data-secondary="generic components" data-type="indexterm" id="idm45969611399368"/>The first step in the process of developing any NLP system is to collect data relevant to the given task. Even if we’re building a rule-based system, we still need some data to design and test our rules. The data we get is seldom clean, and this is where text cleaning comes into play. After cleaning, text data often has a lot of variations and needs to be converted into a canonical form. This is done in the pre-processing step. This is followed by feature engineering, where we carve out indicators that are most suitable for the task at hand. These indicators are converted into a format that is understandable by modeling algorithms. Then comes the modeling and evaluation phase, where we build one or more models and compare and contrast them using a relevant evaluation metric(s). Once the best model among the ones evaluated is chosen, we move toward deploying this model in production. Finally, we regularly monitor the performance of the model and, if need be, update it to keep up its <span class="keep-together">performance.</span></p>

<p>Note that, in the real world, the process may not always be linear as it’s shown in the pipeline in <a data-type="xref" href="#figure_2_1_generic_nlp_pipeline">Figure 2-1</a>; it often involves going back and forth between individual steps (e.g., between feature extraction and modeling, modeling and evaluation, and so on). Also, there are loops in between, most commonly going from evaluation to pre-processing, feature engineering, modeling, and back to evaluation. There is also an overall loop that goes from monitoring to data acquisition, but this loop happens at the project level.</p>

<p>Note that exact step-by-step procedures may depend on the specific task at hand. For example, a text-classification system may require a different feature extraction step compared to a text-summarization system. We will focus on application-specific pipeline stages in subsequent chapters in the book. Also, depending on the phase of the project, different steps can take different amounts of time. In the initial phases, most of the time is used in modeling and evaluation, whereas once the system matures, feature engineering can take far more time.</p>

<p>For the rest of this chapter, we’ll look at the individual stages of the pipeline in detail along with examples. We’ll describe some of the most common procedures at each stage and discuss some use cases to illustrate them. Let’s start with the first step: data acquisition<a contenteditable="false" data-primary="data acquisition" data-type="indexterm" id="ch02_term3"/>.</p>

<section data-type="sect1" data-pdf-bookmark="Data Acquisition"><div class="sect1" id="data_acquisition">
<h1>Data Acquisition</h1>

<p>Data is the heart of any ML system. In most industrial projects, it is often the data that becomes the bottleneck. In this section, we’ll discuss various strategies for gathering relevant data for an NLP project.</p>

<p>Let’s say we’re asked to develop an NLP system to identify whether an incoming customer query (for example, using a chat interface) is a sales inquiry or a customer care inquiry. Depending on the type of query, it should be automatically routed to the right team. How can one go about building such a system? Well, the answer depends on the type and amount of data we have to work with.</p>

<p>In an ideal setting, we’ll have the required datasets with thousands—maybe even millions—of data points. In such cases, we don’t have to worry about data acquisition. For example, in the scenario we just described, we have historic queries fro
m previous years, which sales and support teams responded to. Further, the teams tagged these queries as sales, support, or other. So, not only do we have the data, but we also have the labels. However, in many AI projects, one is not so lucky. Let’s look at what we can do in a less-than-ideal scenario.</p>

<p>If we have little or no data, we can start by looking at patterns in the data that indicate if the incoming message is a sales or support query. We can then use regular expressions and other heuristics to match these patterns to separate sales queries from support queries. We evaluate this solution by collecting a set of queries from both categories and calculating what percentage of the messages were correctly identified by our system. Say we get OK-ish numbers. We would like to improve the system <span class="keep-together">performance.</span></p>

<p>Now we can start thinking about using NLP techniques. For this, we need <a contenteditable="false" data-primary="labeled data" data-type="indexterm" id="idm45969612750984"/>labeled data, a collection of queries where each one is labeled with sales or support. How can we get such data?</p>

<dl class="less_space pagebreak-before">
<dt class="less_space">Use a public dataset<a contenteditable="false" data-primary="public datasets" data-type="indexterm" id="idm45969612748088"/></dt>
	<dd><p>We could see if there are any public datasets<a contenteditable="false" data-primary="datasets" data-secondary="public" data-type="indexterm" id="idm45969612746376"/> available that we can leverage. Take a look at the compilation by Nicolas Iderhoff [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612744872-marker" href="ch02.xhtml#idm45969612744872">1</a>] or search Google’s specialized search engine for datasets [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612743320-marker" href="ch02.xhtml#idm45969612743320">2</a>]. If you find a suitable dataset that’s similar to the task at hand, great! Build a model and evaluate. If not, then what?</p></dd>
<dt>Scrape<a contenteditable="false" data-primary="scraping data" data-type="indexterm" id="idm45969612741400"/> data</dt>
	<dd><p>We could find a source of relevant data on the internet—for example, a consumer or discussion forum where people have posted queries (sales or support). Scrape the data from there and get it labeled by human annotators.</p>
	<p>For many industrial settings, gathering data from external sources does not suffice because the data doesn’t contain nuances like product names or product-specific user behavior and thus might be very different from the data seen in production environments. This is when we’ll have to start looking for data inside the organization.</p></dd>
<dt>Product intervention</dt>
	<dd><p>In most industrial settings, AI models<a contenteditable="false" data-primary="product intervention" data-type="indexterm" id="idm45969612737512"/> seldom exist by themselves. They’re developed mostly to serve users via a feature or product. In all such cases, the AI team should work with the product team to collect more and richer data by developing better instrumentation in the product. In the tech world, this is called <em>product intervention</em>.</p>
	<p>Product intervention is often the best way to collect data for building intelligent applications in industrial settings. Tech giants like <a contenteditable="false" data-primary="Google" data-secondary="data acquisition" data-type="indexterm" id="idm45969612734952"/>Google, <a contenteditable="false" data-primary="Facebook" data-secondary="data acquisition" data-type="indexterm" id="idm45969612733448"/>Facebook, Microsoft<a contenteditable="false" data-primary="Microsoft" data-secondary="data acquisition" data-type="indexterm" id="idm45969612731912"/>, Netflix<a contenteditable="false" data-primary="Netflix" data-type="indexterm" id="idm45969612730376"/>, etc., have known this for a long time and have tried to collect as much data as possible from as many users as possible.</p></dd>
<dt>Data augmentation</dt>
	<dd><p>While instrumenting products is a great way to collect data, it takes time. Even if you instrument the product today, it can take anywhere between three to six months to collect a decent-sized, comprehensive dataset. So, can we do something in the meantime?</p></dd>
</dl>

	<p>NLP has a bunch of techniques through which we can take a small dataset and use some tricks to create more data. These tricks are also called <em>data augmentation<a contenteditable="false" data-primary="data augmentation" data-type="indexterm" id="ch02_term4"/></em>, and they try to exploit language properties to create text that is syntactically similar to source text data. They may appear as hacks, but they work very well in practice. Let’s look at some of them:</p>
	
	<dl>
	  <dt>Synonym<a contenteditable="false" data-primary="synonym replacement" data-type="indexterm" id="idm45969612724024"/> replacement</dt> 
		  <dd><p>Randomly choose “k” words in a sentence that are not stop words. Replace these words with their synonyms. For synonyms, we can use Synsets in Wordnet<a contenteditable="false" data-primary="Synsets in Wordnet" data-type="indexterm" id="idm45969612721976"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612720744-marker" href="ch02.xhtml#idm45969612720744">3</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612719528-marker" href="ch02.xhtml#idm45969612719528">4</a>].</p></dd>
	  <dt><a contenteditable="false" data-primary="back translation" data-type="indexterm" id="idm45969612717864"/>Back translation</dt>
		  <dd><p>Say we have a sentence, S1, in English. We use a machine-translation library like Google Translate to translate it into some other language—say, German. Let the corresponding sentence in German be S2. Now, we’ll use the machine-translation library again to translate back to English. Let the output sentence be S3.</p>
		<p>We’ll find that S1 and S3 are very similar in meaning but are slight variations of each other. Now we can add S3 to our dataset. This trick works beautifully for text classification. <a data-type="xref" href="#back_translation">Figure 2-2</a> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_2_11-marker" href="ch02.xhtml#footnote_2_11">5</a>] shows an example of back translation in action.</p>

	<figure><div id="back_translation" class="figure"><img alt="Back translation" src="Images/pnlp_0202.png" width="1377" height="563"/>
	<h6><span class="label">Figure 2-2. </span><a contenteditable="false" data-primary="back translation" data-type="indexterm" id="idm45969612710680"/>Back translation</h6>
	</div></figure>
	</dd>
	 <dt><a contenteditable="false" data-primary="TF-IDF–based word replacement" data-type="indexterm" id="idm45969612708872"/>TF-IDF–based word replacement</dt>
		 <dd><p>Back translation can lose certain words that are crucial to the sentence. In [<a data-type="noteref" href="ch02.xhtml#footnote_2_11">5</a>], the authors use <a href="https://oreil.ly/jeUJ8">TF-IDF</a>, a concept we’ll introduce in <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a>, to handle this.</p></dd>
	 <dt><a contenteditable="false" data-primary="bigram flipping" data-type="indexterm" id="idm45969612704184"/>Bigram flipping</dt> 
		 <dd><p>Divide the sentence into bigrams. Take one bigram at random and flip it. For example: “I am going to the supermarket.” Here, we take the bigram “going to” and replace it with the flipped one: “to going.”</p></dd>
	 <dt><a contenteditable="false" data-primary="replacing entities" data-type="indexterm" id="idm45969612701864"/>Replacing entities</dt>
		 <dd><p>Replace entities like person name, location, organization, etc., with other entities in the same category. That is, replace person name with another person name, city with another city, etc. For example, in “I live in California,” replace “California” with “London.”</p></dd>
	 <dt>Adding <a contenteditable="false" data-primary="noise" data-secondary="adding to data" data-type="indexterm" id="idm45969612699352"/>noise to data</dt>
		 <dd><p>In many NLP applications, the incoming data contains spelling mistakes. This is primarily due to characteristics of the platform where the data is being generated (for example<a contenteditable="false" data-primary="Twitter" data-type="indexterm" id="idm45969612697016"/>, Twitter). In such cases, we can add a bit of noise to data to train robust models. For example, randomly choose a word in a sentence and replace it with another word that’s closer in spelling to the first word. Another source of noise is the “fat finger” problem<a contenteditable="false" data-primary="fat-finger problem" data-type="indexterm" id="idm45969612695496"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_2_28-marker" href="ch02.xhtml#footnote_2_28">6</a>] on mobile keyboards. Simulate a QWERTY keyboard error by replacing a few characters with their neighboring characters on the QWERTY keyboard.</p></dd>
	 <dt>Advanced techniques</dt>
		 <dd><p>There are other advanced techniques and systems that can augment text data. Some of the notable ones are:</p>
		  <dl>
			 <dt>Snorkel<a contenteditable="false" data-primary="Snorkel software" data-type="indexterm" id="idm45969612690296"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612689032-marker" href="ch02.xhtml#idm45969612689032">7</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612687752-marker" href="ch02.xhtml#idm45969612687752">8</a>, 52]</dt> 
				 <dd><p>This is a system for building training data automatically, without manual labeling. Using Snorkel, a large training dataset can be “created”—without manual labeling—using heuristics and creating synthetic data by transforming existing data and creating new data samples. This approach was shown to work well at Google in the recent past [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612685448-marker" href="ch02.xhtml#idm45969612685448">9</a>].</p></dd>
			 <dt><a contenteditable="false" data-primary="EDA (Easy Data Augmentation)" data-type="indexterm" id="idm45969612683592"/>Easy Data Augmentation (EDA<a contenteditable="false" data-primary="Easy Data Augmentation (EDA)" data-type="indexterm" id="idm45969612682120"/>) [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_2_21-marker" href="ch02.xhtml#footnote_2_21">10</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612679032-marker" href="ch02.xhtml#idm45969612679032">11</a>] and NLPAug<a contenteditable="false" data-primary="NLPAug" data-type="indexterm" id="idm45969612676872"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612675672-marker" href="ch02.xhtml#idm45969612675672">12</a>]</dt> 		
				 <dd><p>These two libraries are used to create synthetic samples for NLP. They provide implementation of various data augmentation techniques, including some techniques that we discussed previously.</p></dd>
			 <dt>Active learning<a contenteditable="false" data-primary="active learning" data-type="indexterm" id="idm45969612673112"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612671848-marker" href="ch02.xhtml#idm45969612671848">13</a>]</dt> 
				 <dd><p>This is a specialized paradigm of ML where the learning algorithm can interactively query a data point and get its label. It is used in scenarios where there is an abundance of unlabeled data but manually labeling is expensive. In such cases, the question becomes: for which data points should we ask for labels to maximize learning while keeping the labeling cost low?</p></dd>
			 </dl>
			 </dd>
			</dl>


		

<p>In order for most of the techniques we discussed in this section to work well, one key requirement is a clean dataset to start with, even if it’s not very big. In our experience, data augmentation techniques can work really well. Further, in day-to-day ML practice, datasets come from heterogeneous sources. A combination of public datasets, labeled datasets, and augmented datasets are used for building early-stage production models, as we often may not have large datasets for our custom scenarios to start with. <a contenteditable="false" data-primary="data augmentation" data-startref="ch02_term4" data-type="indexterm" id="idm45969612668472"/><a contenteditable="false" data-primary="data acquisition" data-startref="ch02_term3" data-type="indexterm" id="idm45969612667096"/>Once we have the data we want for a given task, we proceed to the next step: text cleaning.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Text Extraction and Cleanup"><div class="sect1" id="text_extraction_and_cleanup">
<h1>Text Extraction and Cleanup</h1>

<p><a contenteditable="false" data-primary="text extraction and cleanup" data-type="indexterm" id="ch02_term7"/>Text extraction and cleanup refers to the process of extracting raw text from the input data by removing all the other non-textual information, such as markup, metadata, etc., and converting the text to the required encoding format. Typically, this depends on the format of available data in the organization (e.g., static data from PDF, HTML or text, some form of continuous data stream, etc.), as shown in <a data-type="xref" href="#left_parenthesisaright_parenthesispdf_i">Figure 2-3</a>.</p>

<p>Text extraction is a standard data-wrangling step, and we don’t usually employ any NLP-specific techniques during this process. However, in our experience, it is an important step that has implications for all other aspects of the NLP pipeline. Further, it can also be the most time-consuming part of a project. While the design of text-extraction tools is beyond the scope of this book, we’ll look at a few examples to illustrate different issues involved in this step in this section. We’ll also touch on some of the important aspects of text extraction from various sources as well as cleanup to make them consumable in downstream pipelines.</p>

<figure><div id="left_parenthesisaright_parenthesispdf_i" class="figure"><img alt="(a) PDF Invoice [_24] (b) HTML texts (c) text embedded in an image [_29]" src="Images/pnlp_0203.png" width="1440" height="1614"/>
<h6><span class="label">Figure 2-3. </span>(a) PDF invoice, [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612658168-marker" href="ch02.xhtml#idm45969612658168">14</a>] (b) HTML texts, and (c) text embedded in an image [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612656520-marker" href="ch02.xhtml#idm45969612656520">15</a>]</h6>
</div></figure>

<section data-type="sect2" data-pdf-bookmark="HTML Parsing and Cleanup"><div class="sect2" id="html_parsing_and_cleanup">
<h2>HTML Parsing and Cleanup</h2>

<p><a contenteditable="false" data-primary="HTML parsing and cleanup" data-type="indexterm" id="ch02_term8"/>Say we’re working on a project where we’re building a forum search engine for programming questions. We’ve identified Stack Overflow<a contenteditable="false" data-primary="Stack Overflow web pages: text extraction from" data-type="indexterm" id="idm45969612650296"/> as a source and decided to extract question and best-answer pairs from the website. How can we go through the text-extraction step in this case? If we observe the HTML markup of a typical Stack Overflow question page, we notice that questions and answers have special tags associated with them. We can utilize this information while extracting text from the HTML page. While it may seem like writing our own HTML parser is the way to go, for most cases we encounter, it’s more feasible to utilize existing libraries such as <a contenteditable="false" data-primary="Beautiful Soup library" data-type="indexterm" id="idm45969612648424"/>Beautiful Soup [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612647192-marker" href="ch02.xhtml#idm45969612647192">16</a>] and Scrapy<a contenteditable="false" data-primary="Scrapy" data-type="indexterm" id="idm45969612645912"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612644680-marker" href="ch02.xhtml#idm45969612644680">17</a>], which provide a range of utilities to parse web pages. The following code snippet shows how to use Beautiful Soup to address the problem described here, extracting a question and its best-answer pair from a Stack Overflow web page:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>
<code class="n">myurl</code> <code class="o">=</code> <code class="s2">"https://stackoverflow.com/questions/415511/ </code><code class="se">\</code>
<code class="s2">  how-to-get-the-current-time-in-python"</code>
<code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="n">myurl</code><code class="p">)</code><code class="o">.</code><code class="n">read</code><code class="p">()</code>
<code class="n">soupified</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s2">"html.parser"</code><code class="p">)</code>
<code class="n">question</code> <code class="o">=</code> <code class="n">soupified</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s2">"div"</code><code class="p">,</code> <code class="p">{</code><code class="s2">"class"</code><code class="p">:</code> <code class="s2">"question"</code><code class="p">})</code>
<code class="n">questiontext</code> <code class="o">=</code> <code class="n">question</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s2">"div"</code><code class="p">,</code> <code class="p">{</code><code class="s2">"class"</code><code class="p">:</code> <code class="s2">"post-text"</code><code class="p">})</code>
<code class="k">print</code><code class="p">(</code><code class="s2">"Question: </code><code class="se">\n</code><code class="s2">"</code><code class="p">,</code> <code class="n">questiontext</code><code class="o">.</code><code class="n">get_text</code><code class="p">()</code><code class="o">.</code><code class="n">strip</code><code class="p">())</code>
<code class="n">answer</code> <code class="o">=</code> <code class="n">soupified</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s2">"div"</code><code class="p">,</code> <code class="p">{</code><code class="s2">"class"</code><code class="p">:</code> <code class="s2">"answer"</code><code class="p">})</code>
<code class="n">answertext</code> <code class="o">=</code> <code class="n">answer</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s2">"div"</code><code class="p">,</code> <code class="p">{</code><code class="s2">"class"</code><code class="p">:</code> <code class="s2">"post-text"</code><code class="p">})</code>
<code class="k">print</code><code class="p">(</code><code class="s2">"Best answer: </code><code class="se">\n</code><code class="s2">"</code><code class="p">,</code> <code class="n">answertext</code><code class="o">.</code><code class="n">get_text</code><code class="p">()</code><code class="o">.</code><code class="n">strip</code><code class="p">())</code></pre>

<p>Here, we’re relying on our knowledge of the structure of an HTML document to extract what we want from it. This code shows the output as follows:</p>

<pre data-type="programlisting">
Question:
What is the module/method used to get the current time?
Best answer:
 Use:
&gt;&gt;&gt; import datetime
&gt;&gt;&gt; datetime.datetime.now()
datetime.datetime(2009, 1, 6, 15, 8, 24, 78915)

&gt;&gt;&gt; print(datetime.datetime.now())
2009-01-06 15:08:24.789150

And just the time:
&gt;&gt;&gt; datetime.datetime.now().time()
datetime.time(15, 8, 24, 78915)

&gt;&gt;&gt; print(datetime.datetime.now().time())
15:08:24.789150

See the documentation for more information.
To save typing, you can import the datetime object from the datetime module:
&gt;&gt;&gt; from datetime import datetime

Then remove the leading datetime. from all of the above.</pre>

<p>In this example, we had a specific need: extracting a question and its answer. In some scenarios—for example, extracting postal addresses from web pages—we would get all the text (instead of only parts of it) from the web page first, before doing anything else. Typically, all HTML libraries have some function that can strip off all HTML tags and return only the content between the tags. But this often results in noisy output, and you may end up seeing a lot of JavaScript in the extracted content as well. In such cases, we should look to extract content between only those tags that typically contain text in web pages.<a contenteditable="false" data-primary="HTML parsing and cleanup" data-startref="ch02_term8" data-type="indexterm" id="idm45969612035512"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Unicode Normalization"><div class="sect2" id="unicode_normalization">
<h2>Unicode Normalization</h2>

<p>As we develop code for cleaning up HTML tags, we may also encounter various Unicode characters, including symbols, emojis, and other graphic characters. A handful of Unicode characters are shown in <a data-type="xref" href="#unicode_characters_left_square_bracket">Figure 2-4</a>.</p>

<figure><div id="unicode_characters_left_square_bracket" class="figure"><img alt="Unicode characters [_25]" src="Images/pnlp_0204.png" width="1442" height="591"/>
<h6><span class="label">Figure 2-4. </span>Unicode characters<a contenteditable="false" data-primary="Unicode characters" data-type="indexterm" id="idm45969612029480"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612028216-marker" href="ch02.xhtml#idm45969612028216">18</a>]</h6>
</div></figure>

<p>To parse such non-textual symbols and special characters, we use Unicode <a contenteditable="false" data-primary="normalization" data-secondary="Unicode" data-type="indexterm" id="idm45969612026376"/>normalization. This means that the text we see should be converted into some form of binary representation to store in a computer. This process is known as <em>text encoding<a contenteditable="false" data-primary="text encoding" data-type="indexterm" id="idm45969612024408"/></em>. Ignoring encoding issues can result in processing errors further in the pipeline.</p>

<p>There are several encoding schemes, and the default encoding can be different for different operating systems. Sometimes (more commonly than you think), especially when dealing with text in multiple languages, social media data, etc., we may have to convert between these encoding schemes during the text-extraction process. Refer to [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969612022408-marker" href="ch02.xhtml#idm45969612022408">19</a>] for an introduction to how language is represented on computers and what difference an encoding scheme makes. Here is an example of Unicode handling:</p>

<pre data-type="programlisting">
text = ’I love <img id="c523" src="Images/1f355_pizza.png" width="129" height="154"/>!  Shall we book a <img id="c529" src="Images/1f695_taxi.png" width="154" height="100"/> to gizza?’
Text = text.encode("utf-8")
print(Text)</pre>

<p>which outputs:</p>

<pre data-type="programlisting">
b'I love Pizza \xf0\x9f\x8d\x95!  Shall we book a cab \xf0\x9f\x9a\x95 
  to get pizza?'</pre>

<p>This processed text is machine readable and can be used in downstream pipelines. We address issues regarding handling Unicode characters with this same example in more detail in <a data-type="xref" href="ch08.xhtml#social_media">Chapter 8</a>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Spelling Correction"><div class="sect2" id="spelling_correction">
<h2>Spelling Correction</h2>

<p><a contenteditable="false" data-primary="spelling correction" data-type="indexterm" id="ch02_term9"/>In the world of fast typing and fat-finger typing [<a data-type="noteref" href="ch02.xhtml#footnote_2_28">6</a>], incoming text data often has spelling errors. This can be prevalent in search engines, text-based chatbots deployed on mobile devices, social media, and many other sources. While we remove HTML tags and handle Unicode characters, this remains a unique problem that may hurt the linguistic understanding of the data, and shorthand text messages in social microblogs often hinder language processing and context understanding. Two such examples follow:</p>

<pre data-type="programlisting">
<strong>Shorthand typin<a contenteditable="false" data-primary="shorthand" data-type="indexterm" id="idm45969612010552"/>g:</strong> Hllo world! I am back!
<strong>Fat finger problem<a contenteditable="false" data-primary="fat-finger problem" data-type="indexterm" id="idm45969612008872"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_2_51-marker" href="ch02.xhtml#footnote_2_51">20</a>]:</strong> I pronise that I will not bresk the silence again!</pre>

<p>While shorthand typing is prevalent in chat interfaces, fat-finger problems are common in search engines and are mostly unintentional. Despite our understanding of the problem, we don’t have a robust method to fix this, but we still can make good attempts to mitigate the issue. Microsoft released a REST API<a contenteditable="false" data-primary="Microsoft REST API" data-type="indexterm" id="idm45969612005000"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_2_45-marker" href="ch02.xhtml#footnote_2_45">21</a>] that can be used in Python for potential spell checking<a contenteditable="false" data-primary="spell checking" data-see="spelling correction" data-type="indexterm" id="idm45969612001992"/>:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code><code> </code><code class="nn">requests</code><code>
</code><code class="kn">import</code><code> </code><code class="nn">json</code><code>
</code><code>
</code><code class="n">api_key</code><code> </code><code class="o">=</code><code> </code><code class="s2">"</code><code class="s2">&lt;ENTER-KEY-HERE&gt;</code><code class="s2">"</code><code>
</code><code class="n">example_text</code><code> </code><code class="o">=</code><code> </code><code class="s2">"</code><code class="s2">Hollo, wrld</code><code class="s2">"</code><code> </code><code class="c1"># the text to be spell-checked</code><code>
</code><code>
</code><code class="n">data</code><code> </code><code class="o">=</code><code> </code><code class="p">{</code><code class="s1">'</code><code class="s1">text</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="n">example_text</code><code class="p">}</code><code>
</code><code class="n">params</code><code> </code><code class="o">=</code><code> </code><code class="p">{</code><code>
</code><code>    </code><code class="s1">'</code><code class="s1">mkt</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">en-us</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>    </code><code class="s1">'</code><code class="s1">mode</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">proof</code><code class="s1">'</code><code>
</code><code>    </code><code class="p">}</code><code>
</code><code class="n">headers</code><code> </code><code class="o">=</code><code> </code><code class="p">{</code><code>
</code><code>    </code><code class="s1">'</code><code class="s1">Content-Type</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="s1">'</code><code class="s1">application/x-www-form-urlencoded</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>    </code><code class="s1">'</code><code class="s1">Ocp-Apim-Subscription-Key</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="n">api_key</code><code class="p">,</code><code>
</code><code>    </code><code class="p">}</code><code>
</code><code class="n">response</code><code> </code><code class="o">=</code><code> </code><code class="n">requests</code><code class="o">.</code><code class="n">post</code><code class="p">(</code><code class="n">endpoint</code><code class="p">,</code><code> </code><code class="n">headers</code><code class="o">=</code><code class="n">headers</code><code class="p">,</code><code> </code><code class="n">params</code><code class="o">=</code><code class="n">params</code><code class="p">,</code><code> </code><code class="n">data</code><code class="o">=</code><code class="n">data</code><code class="p">)</code><code>
</code><code class="n">json_response</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">json</code><code class="p">(</code><code class="p">)</code><code>
</code><code class="k">print</code><code class="p">(</code><code class="n">json</code><code class="o">.</code><code class="n">dumps</code><code class="p">(</code><code class="n">json_response</code><code class="p">,</code><code> </code><code class="n">indent</code><code class="o">=</code><code class="mi">4</code><code class="p">)</code><code class="p">)</code><code>
</code><code>
</code><strong><code class="n">Output</code><code> </code><code class="p">(</code><code class="n">partially</code><code> </code><code class="n">shown</code><code> </code><code class="n">here</code><code class="p">)</code><code class="p">:</code></strong><code>
</code><code class="s2">"</code><code class="s2">suggestions</code><code class="s2">"</code><code class="p">:</code><code> </code><code class="p">[</code><code>
</code><code>            </code><code class="p">{</code><code>
</code><code>               </code><code class="s2">"</code><code class="s2">suggestion</code><code class="s2">"</code><code class="p">:</code><code> </code><code class="s2">"</code><code class="s2">Hello</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>               </code><code class="s2">"</code><code class="s2">score</code><code class="s2">"</code><code class="p">:</code><code> </code><code class="mf">0.9115257530801</code><code>
</code><code>            </code><code class="p">}</code><code class="p">,</code><code>
</code><code>            </code><code class="p">{</code><code>
</code><code>               </code><code class="s2">"</code><code class="s2">suggestion</code><code class="s2">"</code><code class="p">:</code><code> </code><code class="s2">"</code><code class="s2">Hollow</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>               </code><code class="s2">"</code><code class="s2">score</code><code class="s2">"</code><code class="p">:</code><code> </code><code class="mf">0.858039839213461</code><code>
</code><code>            </code><code class="p">}</code><code class="p">,</code><code>
</code><code>            </code><code class="p">{</code><code>
</code><code>               </code><code class="s2">"</code><code class="s2">suggestion</code><code class="s2">"</code><code class="p">:</code><code> </code><code class="s2">"</code><code class="s2">Hallo</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>               </code><code class="s2">"</code><code class="s2">score</code><code class="s2">"</code><code class="p">:</code><code> </code><code class="mf">0.597385084464481</code><code>
</code><code>            </code><code class="p">}</code></pre>

<p>You can see the full tutorial in [<a data-type="noteref" href="ch02.xhtml#footnote_2_45">21</a>].</p>

<p>Going beyond APIs, we can build our own spell checker using a huge dictionary of words from a specific language. A naive solution would be to look for all words that can be composed with minimal alteration (addition, deletion, substitution) to its constituent letters. For example, if ‘“Hello” is a valid word that is already present in the dictionary, then the addition of “o” (minimal) to “Hllo” would make the correction.<a contenteditable="false" data-primary="spelling correction" data-startref="ch02_term9" data-type="indexterm" id="idm45969611299960"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="System-Specific Error Correction"><div class="sect2" id="system_specific_error_correction">
<h2>System-Specific Error Correction</h2>

<p><a contenteditable="false" data-primary="error correction" data-type="indexterm" id="ch02_term10"/>HTML or raw text scraped from the web are just a couple of sources for textual data. Consider another scenario where our dataset is in the form of a collection of PDF documents. The pipeline in this case starts with extraction of plain text from PDF documents. However, different PDF documents are encoded differently, and sometimes, we may not be able to extract the full text, or the structure of the text may get messed up. If we need full text or our text has to be grammatical or in full sentences (e.g., when we want to extract relations between various people in the news based on newspaper text), this can impact our application. While there are several libraries, such as PyPDF<a contenteditable="false" data-primary="PyPDF" data-type="indexterm" id="idm45969611274824"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611273592-marker" href="ch02.xhtml#idm45969611273592">22</a>], PDFMiner<a contenteditable="false" data-primary="PDFMiner" data-type="indexterm" id="idm45969611284248"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611283048-marker" href="ch02.xhtml#idm45969611283048">23</a>], etc., to extract text from <a contenteditable="false" data-primary="PDF documents: text extraction from" data-type="indexterm" id="idm45969611789912"/>PDF documents, they are far from perfect, and it’s not uncommon to encounter PDF documents that can’t be processed by such libraries. We leave their exploration as an exercise for the reader. [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611788568-marker" href="ch02.xhtml#idm45969611788568">24</a>] discusses some of the issues involved in PDF-to-text extraction in detail.</p>

<p>Another common source of textual data is scanned documents<a contenteditable="false" data-primary="scanned documents: text extraction from" data-type="indexterm" id="idm45969611802488"/>. Text extraction from scanned documents is typically done through optical character recognition (<a contenteditable="false" data-primary="OCR (optical character recognition)" data-type="indexterm" id="idm45969611801208"/>OCR)<a contenteditable="false" data-primary="optical character recognition (OCR)" data-type="indexterm" id="idm45969611811416"/>, using libraries such as <a contenteditable="false" data-primary="Tesseract" data-type="indexterm" id="idm45969611810136"/>Tesseract [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611820472-marker" href="ch02.xhtml#idm45969611820472">25</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611819032-marker" href="ch02.xhtml#idm45969611819032">26</a>]. Consider the example <a contenteditable="false" data-primary="images: text extraction from" data-type="indexterm" id="ch02_term11"/>image—a snippet from a 1950 article in a journal [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611831992-marker" href="ch02.xhtml#idm45969611831992">27</a>]—shown in <a data-type="xref" href="#an_example_of_scanned_text">Figure 2-5</a>.</p>

<figure><div id="an_example_of_scanned_text" class="figure"><img alt="An example of scanned text" src="Images/pnlp_0205.png" width="732" height="164"/>
<h6><span class="label">Figure 2-5. </span>An example of scanned text</h6>
</div></figure>

<p>The code snippet below shows how the <a contenteditable="false" data-primary="Python" data-type="indexterm" id="idm45969611768264"/>Python library pytesseract can be used to extract text from this image:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">PIL</code> <code class="kn">import</code> <code class="n">Image</code>
<code class="kn">from</code> <code class="nn">pytesseract</code> <code class="kn">import</code> <code class="n">image_to_string</code>
<code class="n">filename</code> <code class="o">=</code> <code class="s2">"somefile.png"</code>
<code class="n">text</code> <code class="o">=</code> <code class="n">image_to_string</code><code class="p">(</code><code class="n">Image</code><code class="o">.</code><code class="n">open</code><code class="p">(</code><code class="n">filename</code><code class="p">))</code>
<code class="k">print</code><code class="p">(</code><code class="n">text</code><code class="p">)</code></pre>

<p>This code will print the output as follows, where “\n” indicates a newline character:</p>

<pre data-type="programlisting">
’in the nineteenth century the only Kind of linguistics considered\nseriously
was this comparative and historical study of words in languages\nknown or
believed to <b>Fe</b> cognate—say the Semitic languages, or the Indo-\nEuropean
languages. It is significant that the Germans who really made\nthe subject what
it was, used the term Indo-germanisch. Those who know\nthe popular works of 
Otto Jespersen will remember how <b>fitmly</b> he\ndeclares that linguistic 
science is historical. And those who have noticed’</pre>

<p>We notice that there are two errors in the output of the OCR system in this case. Depending on the quality of the original scan, OCR output can potentially have larger amounts of errors. How do we clean up this text before feeding it into the next stage of the pipeline? One approach is to run the text through a spell checker such as pyenchant [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611836424-marker" href="ch02.xhtml#idm45969611836424">28</a>], which will identify misspellings and suggest some alternatives. More recent approaches use neural network architectures to train word/character-based language models, which are in turn used for correcting OCR text output based on the context [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611834696-marker" href="ch02.xhtml#idm45969611834696">29</a>].</p>

<p>Recall that we saw an example of a voice-based assistant in <a data-type="xref" href="ch01.xhtml#nlp_a_primer">Chapter 1</a>. In such cases, the source of text extraction is the output of an automatic speech recognition (<a contenteditable="false" data-primary="ASR (automatic speech recognition)" data-type="indexterm" id="idm45969611844712"/>ASR)<a contenteditable="false" data-primary="automatic speech recognition (ASR)" data-type="indexterm" id="idm45969611843512"/> system. Like OCR, it’s common to see some errors in ASR, owing to various factors, such as dialectical variations, slang, non-native English, new or domain-specific vocabulary, etc. The above-mentioned approach of spell checkers or neural language models can be followed here as well to clean up the extracted text.</p>

<p>What we’ve seen so far are just some examples of potential issues that may come up during the text-extraction and cleaning process. Though NLP plays a very small role in this process, we hope these examples illustrate how text extraction and cleanup could pose challenges in a typical NLP pipeline. We’ll also touch on these aspects in upcoming chapters for different NLP applications, where relevant. Let’s move on to the next step in our pipeline: pre-processing<a contenteditable="false" data-primary="pre-processing" data-type="indexterm" id="ch02_term12"/>.<a contenteditable="false" data-primary="text extraction and cleanup" data-startref="ch02_term7" data-type="indexterm" id="idm45969611851176"/><a contenteditable="false" data-primary="error correction" data-startref="ch02_term10" data-type="indexterm" id="idm45969611849800"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Pre-Processing"><div class="sect1" id="pre_processing">
<h1>Pre-Processing</h1>

<p>Let’s start with a simple question: we already did some cleanup in the previous step; why do we still have to pre-process text? Consider a scenario where we’re processing text from Wikipedia pages about individuals to extract biographical information about them. Our data acquisition starts with crawling such pages. However, our crawled data is all in HTML, with a lot of boilerplate from Wikipedia (e.g., all the links in the left panel), possibly the presence of links to multiple languages (in their script), etc. All such information is irrelevant for extracting features from text (in most cases). Our text-extraction step removed all this and gave us the plain text of the article we need. However, all NLP software typically works at the sentence level and expects a separation of words at the minimum. So, we need some way to split a text into words and sentences before proceeding further in a processing pipeline. Sometimes, we need to remove special characters and digits, and sometimes, we don’t care whether a word is in upper or lowercase and want everything in lowercase. Many more decisions like this are made while processing text. Such decisions are addressed during the pre-processing step of the NLP pipeline. Here are some common pre-processing steps used in NLP software:</p>

<dl>
	<dt>Preliminaries</dt>
	<dd>Sentence segmentation and word tokenization.</dd>
	<dt>Frequent steps</dt>
	<dd>Stop word removal, stemming and lemmatization, removing digits/punctuation, lowercasing, etc.</dd>
	<dt>Other steps</dt>
	<dd>Normalization, language detection, code mixing, transliteration, etc.</dd>
	<dt>Advanced processing<a contenteditable="false" data-primary="advanced processing" data-type="indexterm" id="idm45969611862168"/></dt>
	<dd>POS tagging, parsing, coreference resolution, etc.</dd>
</dl>

<p>While not all steps will be followed in all the NLP pipelines we encounter, the first two are more or less seen everywhere. Let’s take a look at what each of these steps mean.</p>

<section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Preliminaries"><div class="sect2" id="preliminaries">
<h2 class="less_space">Preliminaries</h2>

<p><a contenteditable="false" data-primary="preliminaries" data-type="indexterm" id="ch02_term13"/>As mentioned earlier, NLP software typically analyzes text by breaking it up into words (tokens) and sentences. Hence, any NLP pipeline has to start with a reliable system to split the text into sentences (sentence segmentation) and further split a sentence into words (word tokenization). On the surface, these seem like simple tasks, and you may wonder why they need special treatment. We will see why in the coming two subsections.</p>

<section data-type="sect3" data-pdf-bookmark="Sentence segmentation"><div class="sect3" id="sentence_segmentation">
<h3>Sentence segmentation</h3>

<p>As a simple rule, we can do sentence segmentation<a contenteditable="false" data-primary="sentence segmentation" data-type="indexterm" id="ch02_term14"/> by breaking up text into sentences at the appearance of full stops and question marks. However, there may be abbreviations, forms of addresses (Dr., Mr., etc.), or ellipses (...) that may break the simple rule.</p>

<p>Thankfully, we don’t have to worry about how to solve these issues, as most NLP libraries come with some form of sentence and word splitting implemented. A commonly used library is Natural Language Tool Kit (<a contenteditable="false" data-primary="NLTK" data-see="Natural Language Tool Kit" data-type="indexterm" id="idm45969611134184"/>NLTK)<a contenteditable="false" data-primary="Natural Language Tool Kit (NLTK)" data-secondary="sentence segmentation with" data-type="indexterm" id="idm45969611132712"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611131192-marker" href="ch02.xhtml#idm45969611131192">30</a>]. The code example below shows how to use a sentence and word splitter from NLTK and uses the first paragraph of this chapter as input:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code><code> </code><code class="nn">nltk.tokenize</code><code> </code><code class="kn">import</code><code> </code><code class="n">sent_tokenize</code><code class="p">,</code><code> </code><code class="n">word_tokenize</code><code>
</code><code>
</code><code class="n">mytext</code><code> </code><code class="o">=</code><code> </code><code class="s2">"</code><code class="s2">In the previous chapter, we saw examples of some common NLP </code><code>
</code><code class="n">applications</code><code> </code><code class="n">that</code><code> </code><code class="n">we</code><code> </code><code class="n">might</code><code> </code><code class="n">encounter</code><code> </code><code class="ow">in</code><code> </code><code class="n">everyday</code><code> </code><code class="n">life</code><code class="o">.</code><code> </code><code class="n">If</code><code> </code><code class="n">we</code><code> </code><code class="n">were</code><code> </code><code class="n">asked</code><code> </code><code class="n">to</code><code> </code><code>
</code><code class="n">build</code><code> </code><code class="n">such</code><code> </code><code class="n">an</code><code> </code><code class="n">application</code><code class="p">,</code><code> </code><code class="n">think</code><code> </code><code class="n">about</code><code> </code><code class="n">how</code><code> </code><code class="n">we</code><code> </code><code class="n">would</code><code> </code><code class="n">approach</code><code> </code><code class="n">doing</code><code> </code><code class="n">so</code><code> </code><code class="n">at</code><code> </code><code class="n">our</code><code> </code><code>
</code><code class="n">organization</code><code class="o">.</code><code> </code><code class="n">We</code><code> </code><code class="n">would</code><code> </code><code class="n">normally</code><code> </code><code class="n">walk</code><code> </code><code class="n">through</code><code> </code><code class="n">the</code><code> </code><code class="n">requirements</code><code> </code><code class="ow">and</code><code> </code><code class="k">break</code><code> </code><code class="n">the</code><code> </code><code>
</code><code class="n">problem</code><code> </code><code class="n">down</code><code> </code><code class="n">into</code><code> </code><code class="n">several</code><code> </code><code class="n">sub</code><code class="o">-</code><code class="n">problems</code><code class="p">,</code><code> </code><code class="n">then</code><code> </code><code class="k">try</code><code> </code><code class="n">to</code><code> </code><code class="n">develop</code><code> </code><code class="n">a</code><code> </code><code class="n">step</code><code class="o">-</code><code class="n">by</code><code class="o">-</code><code class="n">step</code><code> </code><code>
</code><code class="n">procedure</code><code> </code><code class="n">to</code><code> </code><code class="n">solve</code><code> </code><code class="n">them</code><code class="o">.</code><code> </code><code class="n">Since</code><code> </code><code class="n">language</code><code> </code><code class="n">processing</code><code> </code><code class="ow">is</code><code> </code><code class="n">involved</code><code class="p">,</code><code> </code><code class="n">we</code><code> </code><code class="n">would</code><code> </code><code class="n">also</code><code>
</code><code class="nb">list</code><code> </code><code class="nb">all</code><code> </code><code class="n">the</code><code> </code><code class="n">forms</code><code> </code><code class="n">of</code><code> </code><code class="n">text</code><code> </code><code class="n">processing</code><code> </code><code class="n">needed</code><code> </code><code class="n">at</code><code> </code><code class="n">each</code><code> </code><code class="n">step</code><code class="o">.</code><code> </code><code class="n">This</code><code> </code><code class="n">step</code><code class="o">-</code><code class="n">by</code><code class="o">-</code><code class="n">step</code><code> </code><code>
</code><code class="n">processing</code><code> </code><code class="n">of</code><code> </code><code class="n">text</code><code> </code><code class="ow">is</code><code> </code><code class="n">known</code><code> </code><code class="k">as</code><code> </code><em><code class="n">pipeline</code></em><code class="o">.</code><code> </code><code class="n">It</code><code> </code><code class="ow">is</code><code> </code><code class="n">the</code><code> </code><code class="n">series</code><code> </code><code class="n">of</code><code> </code><code class="n">steps</code><code> </code><code class="n">involved</code><code> </code><code class="ow">in</code><code>
</code><code class="n">building</code><code> </code><code class="nb">any</code><code> </code><code class="n">NLP</code><code> </code><code class="n">model</code><code class="o">.</code><code> </code><code class="n">These</code><code> </code><code class="n">steps</code><code> </code><code class="n">are</code><code> </code><code class="n">common</code><code> </code><code class="ow">in</code><code> </code><code class="n">every</code><code> </code><code class="n">NLP</code><code> </code><code class="n">project</code><code class="p">,</code><code> </code><code class="n">so</code><code> </code><code class="n">it</code><code> </code><code>
</code><code class="n">makes</code><code> </code><code class="n">sense</code><code> </code><code class="n">to</code><code> </code><code class="n">study</code><code> </code><code class="n">them</code><code> </code><code class="ow">in</code><code> </code><code class="n">this</code><code> </code><code class="n">chapter</code><code class="o">.</code><code> </code><code class="n">Understanding</code><code> </code><code class="n">some</code><code> </code><code class="n">common</code><code> </code><code class="n">procedures</code><code>
</code><code class="ow">in</code><code> </code><code class="nb">any</code><code> </code><code class="n">NLP</code><code> </code><code class="n">pipeline</code><code> </code><code class="n">will</code><code> </code><code class="n">enable</code><code> </code><code class="n">us</code><code> </code><code class="n">to</code><code> </code><code class="n">get</code><code> </code><code class="n">started</code><code> </code><code class="n">on</code><code> </code><code class="nb">any</code><code> </code><code class="n">NLP</code><code> </code><code class="n">problem</code><code> </code><code class="n">encountered</code><code> </code><code>
</code><code class="ow">in</code><code> </code><code class="n">the</code><code> </code><code class="n">workplace</code><code class="o">.</code><code> </code><code class="n">Laying</code><code> </code><code class="n">out</code><code> </code><code class="ow">and</code><code> </code><code class="n">developing</code><code> </code><code class="n">a</code><code> </code><code class="n">text</code><code class="o">-</code><code class="n">processing</code><code> </code><code class="n">pipeline</code><code> </code><code class="ow">is</code><code> </code><code class="n">seen</code><code> </code><code>
</code><code class="k">as</code><code> </code><code class="n">a</code><code> </code><code class="n">starting</code><code> </code><code class="n">point</code><code> </code><code class="k">for</code><code> </code><code class="nb">any</code><code> </code><code class="n">NLP</code><code> </code><code class="n">application</code><code> </code><code class="n">development</code><code> </code><code class="n">process</code><code class="o">.</code><code> </code><code class="n">In</code><code> </code><code class="n">this</code><code>
</code><code class="n">chapter</code><code class="p">,</code><code> </code><code class="n">we</code><code> </code><code class="n">will</code><code> </code><code class="n">learn</code><code> </code><code class="n">about</code><code> </code><code class="n">the</code><code> </code><code class="n">various</code><code> </code><code class="n">steps</code><code> </code><code class="n">involved</code><code> </code><code class="ow">and</code><code> </code><code class="n">how</code><code> </code><code class="n">they</code><code> </code><code class="n">play</code><code>  </code><code>
</code><code class="n">important</code><code> </code><code class="n">roles</code><code> </code><code class="ow">in</code><code> </code><code class="n">solving</code><code> </code><code class="n">the</code><code> </code><code class="n">NLP</code><code> </code><code class="n">problem</code><code> </code><code class="ow">and</code><code> </code><code class="n">we</code><code class="err">’</code><code class="n">ll</code><code> </code><code class="n">see</code><code> </code><code class="n">a</code><code> </code><code class="n">few</code><code> </code><code class="n">guidelines</code><code>
</code><code class="n">about</code><code> </code><code class="n">when</code><code> </code><code class="ow">and</code><code> </code><code class="n">how</code><code> </code><code class="n">to</code><code> </code><code class="n">use</code><code> </code><code class="n">which</code><code> </code><code class="n">step</code><code class="o">.</code><code> </code><code class="n">In</code><code> </code><code class="n">later</code><code> </code><code class="n">chapters</code><code class="p">,</code><code> </code><code class="n">we</code><code class="err">’</code><code class="n">ll</code><code> </code><code class="n">discuss</code><code>  </code><code>
</code><code class="n">specific</code><code> </code><code class="n">pipelines</code><code> </code><code class="k">for</code><code> </code><code class="n">various</code><code> </code><code class="n">NLP</code><code> </code><code class="n">tasks</code><code> </code><code class="p">(</code><code class="n">e</code><code class="o">.</code><code class="n">g</code><code class="o">.</code><code class="p">,</code><code> </code><code class="n">Chapters</code><code> </code><code class="mi">4</code><code class="err">–</code><code class="mi">7</code><code class="p">)</code><code class="o">.</code><code class="s2">"</code><code>
</code><code>
</code><code class="n">my_sentences</code><code> </code><code class="o">=</code><code> </code><code class="n">sent_tokenize</code><code class="p">(</code><code class="n">mytext</code><code class="p">)</code></pre>
</div></section>

<section data-type="sect3" class="pagebreak-before" data-pdf-bookmark="Word tokenization"><div class="sect3" id="word_tokenization">
<h3 class="less_space">Word tokenization</h3>

<p><a contenteditable="false" data-primary="word tokenization" data-type="indexterm" id="ch02_term15"/>Similar to sentence tokenization<a contenteditable="false" data-primary="tokenization" data-secondary="word" data-type="indexterm" id="ch02_term16"/>, to tokenize a sentence into words, we can start with a simple rule to split text into words based on the presence of punctuation marks. The <a contenteditable="false" data-primary="Natural Language Tool Kit (NLTK)" data-secondary="word tokenization with" data-type="indexterm" id="ch02_term44"/>NLTK library allows us to do that. If we take the previous example:</p>

<pre data-type="programlisting">
for sentence in my_sentences:
   print(sentence)
   print(word_tokenize(sentence))</pre>

<p>For the first sentence, the output is printed as follows:</p>

<pre data-type="programlisting">
In the previous chapter, we saw a quick overview of what is NLP, what are some
of the common applications and challenges in NLP, and an introduction to 
different tasks in NLP.
['In', 'the', 'previous', 'chapter', ',', 'we', 'saw', 'a', 'quick', 
'overview', 'of', 'what', 'is', 'NLP', ',', 'what', 'are', 'some', 'of', 'the', 
'common', 'applications', 'and', 'challenges', 'in', 'NLP', ',', 'and', 'an', 
'introduction', 'to', 'different', 'tasks', 'in', 'NLP', '.']</pre>

<p>While readily available solutions work for most of our needs and most NLP libraries will have a tokenizer and sentence splitter bundled with them, it’s important to remember that they’re far from perfect. For example, consider this sentence: “Mr. Jack O’Neil works at Melitas Marg, located at 245 Yonge Avenue, Austin, 70272.” If we run this through the NLTK tokenizer, O, ‘, and Neil are identified as three separate tokens. Similarly, if we run the sentence: “There are $10,000 and €1000 which are there just for testing a tokenizer” through this tokenizer, while $ and 10,000 are identified as separate tokens, €1000 is identified as a single token. In another scenario, if we want to tokenize tweets, this tokenizer will separate a hashtag into two tokens: a “#” sign and the string that follows it. In such cases, we may need to use a custom tokenizer built for our purpose. To complete our example, we’ll perform word tokenization after we perform sentence tokenization.</p>

<p>A point to note in this context is that NLTK<a contenteditable="false" data-primary="tokenization" data-secondary="tweet" data-type="indexterm" id="idm45969610516472"/> also has a tweet tokenize<a contenteditable="false" data-primary="tweet tokenization" data-type="indexterm" id="idm45969611011048"/>r; we’ll see how it’s useful in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch08.xhtml#social_media">8</a>. To summarize, although word- and sentence-tokenization approaches appear to be elementary and easy to implement, they may not always meet our specific tokenization needs, as we saw in the above examples. Note that we refer to NLTK’s example, but these observations hold true for any other library as well.<a contenteditable="false" data-primary="Natural Language Tool Kit (NLTK)" data-secondary="word tokenization with" data-startref="ch02_term44" data-type="indexterm" id="idm45969610551672"/> We leave that exploration as an exercise for the reader.</p>

<p>As tokenization may differ from one domain to the other, tokenization is also heavily dependent on language. Each language can have various linguistic rules and exceptions. <a data-type="xref" href="#language_specific_left_parenthesisengli">Figure 2-6</a> shows an example where “N.Y.!” has a total of three punctuations. But in English, N.Y. stands for New York, hence “N.Y.” should be treated as a single word and not be tokenized further. Such language-specific exceptions can be specified in the tokenizer provided by spaCy<a contenteditable="false" data-primary="spaCy library" data-secondary="tokenization with" data-type="indexterm" id="idm45969610556408"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_2_46-marker" href="ch02.xhtml#footnote_2_46">31</a>]. It’s also possible in spaCy to develop custom rules to handle such exceptions for languages that have high inflections (prefixes or suffixes) and complex morphology.</p>



<p>Another important fact to keep in mind is that any sentence segmenter and tokenizer will be sensitive to the input they receive. Let’s say we’re writing software to extract some information, such as company, position, and salary, from job offer letters. They follow a certain format, with a To and a From address, a signed note at the end, and so on. How will we decide what a sentence is in such a case? Should the entire address be considered a single “sentence”? Or should each line be split separately? Answers to such questions depend on what you want to extract and how sensitive the rest of the pipeline is about such decisions. For identifying specific patterns (e.g., dates or money expressions), well-formed regular expressions are the first step. In many practical scenarios, we may end up using a custom <a contenteditable="false" data-primary="tokenization" data-secondary="sentence" data-see="sentence segmentation" data-type="indexterm" id="idm45969611087992"/><a contenteditable="false" data-primary="preliminaries" data-startref="ch02_term13" data-type="indexterm" id="idm45969611086376"/><a contenteditable="false" data-primary="word tokenization" data-startref="ch02_term15" data-type="indexterm" id="idm45969610550392"/><a contenteditable="false" data-primary="tokenization" data-secondary="word" data-startref="ch02_term16" data-type="indexterm" id="idm45969610549016"/>tokenizer or sentence segmenter that suits our text structure instead of or on top of an existing one available in a standard NLP library [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610547080-marker" href="ch02.xhtml#idm45969610547080">32</a>].</p>

<figure><div id="language_specific_left_parenthesisengli" class="figure"><img alt="Language-specific (English here) exceptions during tokenization [_46]" src="Images/pnlp_0206.png" width="948" height="709"/>
<h6><span class="label">Figure 2-6. </span>Language-specific (English here) exceptions during tokenization [<a data-type="noteref" href="ch02.xhtml#footnote_2_46">31</a>]</h6>
</div></figure>

</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Frequent Steps"><div class="sect2" id="frequent_steps">
<h2>Frequent Steps</h2>

<p>Let’s look<a contenteditable="false" data-primary="tokenization" data-secondary="language-specific exceptions" data-type="indexterm" id="idm45969611078968"/> at some other frequent<a contenteditable="false" data-primary="pre-processing" data-secondary="frequent steps" data-type="indexterm" id="ch02_term17"/>ly performed pre-processing operations in an NLP pipeline. Say we’re designing software that identifies the category of a news article as one of politics, sports, business, and other. Assume we have a good sentence segmenter and word tokenizer in place. At that point, we would have to start thinking about what kind of information is useful for developing a categorization tool. Some of the frequently used words in English, such as a, an, the, of, in, etc., are not particularly useful for this task, as they don’t carry any content on their own to separate between the four categories. Such words are called <em><a contenteditable="false" data-primary="stop words" data-type="indexterm" id="idm45969610491208"/>stop words</em> and are typically (though not always) removed from further analysis in such problem scenarios. There is no standard list of stop words for English, though. There are some popular lists (NLTK<a contenteditable="false" data-primary="Natural Language Tool Kit (NLTK)" data-secondary="stop words" data-type="indexterm" id="idm45969610451080"/> has one, for example), although what a stop word is can vary depending on what we’re working on. For example, the word “news” is perhaps a stop word for this problem scenario, but it may not be a stop word for the offer letter data in the example mentioned in the previous step.</p>

<p>Similarly, in some cases, upper or lowercase may not make a difference for the problem. So, all text is lowercased (or uppercas<a contenteditable="false" data-primary="uppercasing" data-type="indexterm" id="idm45969610448632"/>ed, although <a contenteditable="false" data-primary="lowercasing" data-type="indexterm" id="idm45969610442856"/>lowercasing is more common). Removing <a contenteditable="false" data-primary="punctuation: removing" data-type="indexterm" id="idm45969610441624"/>punctuation and/or numbers<a contenteditable="false" data-primary="numbers: removing" data-type="indexterm" id="idm45969610440392"/> is also a common step for many NLP problems, such as text classification (<a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>), information retrieval (<a data-type="xref" href="ch07.xhtml#topics_in_brief">Chapter 7</a>), and social media analytics (<a data-type="xref" href="ch08.xhtml#social_media">Chapter 8</a>). We’ll see examples of how and if these steps are useful in upcoming chapters.</p>

<p>The code example below shows how to remove stop words, digits<a contenteditable="false" data-primary="digits: removing" data-type="indexterm" id="idm45969610477240"/>, and punctuation and lowercase a given collection of texts:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">nltk.corpus</code> <code class="kn">import</code> <code class="n">stopwords</code>
<code class="n">From</code> <code class="n">string</code> <code class="kn">import</code> <code class="nn">punctuation</code>
<code class="k">def</code> <code class="nf">preprocess_corpus</code><code class="p">(</code><code class="n">texts</code><code class="p">):</code>
    <code class="n">mystopwords</code> <code class="o">=</code> <code class="nb">set</code><code class="p">(</code><code class="n">stopwords</code><code class="o">.</code><code class="n">words</code><code class="p">(</code><code class="s2">"english"</code><code class="p">))</code>
    <code class="k">def</code> <code class="nf">remove_stops_digits</code><code class="p">(</code><code class="n">tokens</code><code class="p">):</code>
       <code class="k">return</code> <code class="p">[</code><code class="n">token</code><code class="o">.</code><code class="n">lower</code><code class="p">()</code> <code class="k">for</code> <code class="n">token</code> <code class="ow">in</code> <code class="n">tokens</code> <code class="k">if</code> <code class="n">token</code> <code class="ow">not</code> <code class="ow">in</code> <code class="n">mystopwords</code>                         <code class="ow">and</code>
               <code class="ow">not</code> <code class="n">token</code><code class="o">.</code><code class="n">isdigit</code><code class="p">()</code> <code class="ow">and</code> <code class="n">token</code> <code class="ow">not</code> <code class="ow">in</code> <code class="n">punctuation</code><code class="p">]</code>
    <code class="k">return</code> <code class="p">[</code><code class="n">remove_stops_digits</code><code class="p">(</code><code class="n">word_tokenize</code><code class="p">(</code><code class="n">text</code><code class="p">))</code> <code class="k">for</code> <code class="n">text</code> <code class="ow">in</code> <code class="n">texts</code><code class="p">]</code></pre>

<p>It’s important to note that these four processes are neither mandatory nor sequential in nature. The above function is just an illustration of how to add those processing steps into our project. The pre-processing we saw here, while specific to textual data, has nothing particularly linguistic about it—we’re not looking at any aspect of language other than frequency (stop words are very frequent words), and we’re removing non-alphabetic data (punctuation, digits). Two commonly used pre-processing steps that take the word-level properties into account are stemming and <span class="keep-together">lemmatization.</span></p>

<section data-type="sect3" data-pdf-bookmark="Stemming and lemmatization"><div class="sect3" id="stemming_and_lemmatization">
<h3>Stemming and lemmatization</h3>

<p><a contenteditable="false" data-primary="stemming" data-type="indexterm" id="idm45969610805624"/>Stemming refers to the process of removing suffixes and reducing a word to some base form such that all different variants of that word can be represented by the same form (e.g., “car” and “cars” are both reduced to “car”). This is accomplished by applying a fixed set of rules (e.g., if the word ends in “-es,” remove “-es”). More such examples are shown in <a data-type="xref" href="#difference_between_stemming_and_lemmati">Figure 2-7</a>. Although such rules may not always end up in a linguistically correct base form, stemming is commonly used in search engines to match user queries to relevant documents and in text classification to reduce the feature space to train machine learning models.</p>

<p>The following code snippet shows how to use a popular stemming algorithm called Porter Stemmer<a contenteditable="false" data-primary="Porter Stemmer" data-type="indexterm" id="idm45969611113160"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611111928-marker" href="ch02.xhtml#idm45969611111928">33</a>] using <a contenteditable="false" data-primary="Natural Language Tool Kit (NLTK)" data-secondary="stemming with" data-type="indexterm" id="idm45969611110792"/>NLTK:</p>

<pre data-code-language="python" data-type="programlisting" class="less_space pagebreak-before">
<code class="kn">from</code> <code class="nn">nltk.stem.porter</code> <code class="kn">import</code> <code class="n">PorterStemmer</code>
<code class="n">stemmer</code> <code class="o">=</code> <code class="n">PorterStemmer</code><code class="p">()</code>
<code class="n">word1</code><code class="p">,</code> <code class="n">word2</code> <code class="o">=</code> <code class="err">“</code><code class="n">cars</code><code class="err">”</code><code class="p">,</code> <code class="err">“</code><code class="n">revolution</code><code class="err">”</code> 
<code class="k">print</code><code class="p">(</code><code class="n">stemmer</code><code class="o">.</code><code class="n">stem</code><code class="p">(</code><code class="n">word1</code><code class="p">),</code> <code class="n">stemmer</code><code class="o">.</code><code class="n">stem</code><code class="p">(</code><code class="n">word2</code><code class="p">))</code></pre>

<p>This gives “car” as the stemmed version for “cars,” but “revolut” as the stemmed form of “revolution,” even though the latter is not linguistically correct. While this may not affect the performance of a search engine, derivation of correct linguistic form becomes useful in some other scenarios. This is accomplished by another process, closer to stemming, called lemmatization<a contenteditable="false" data-primary="lemmatization" data-type="indexterm" id="idm45969610790664"/>.</p>

<p>Lemmatization is the process of mapping all the different forms of a word to its base word, or <em>lemma</em>. While this seems close to the definition of stemming, they are, in fact, different. For example, the adjective “better,” when stemmed, remains the same. However, upon lemmatization, this should become “good,” as shown in <a data-type="xref" href="#difference_between_stemming_and_lemmati">Figure 2-7</a>. Lemmatization requires more linguistic knowledge, and modeling and developing efficient lemmatizers remains an open problem in NLP research even now.</p>

<figure><div id="difference_between_stemming_and_lemmati" class="figure"><img alt="Difference between stemming and lemmatization [_47]" src="Images/pnlp_0207.png" width="608" height="223"/>
<h6><span class="label">Figure 2-7. </span>Difference between stemming and lemmatization [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611891688-marker" href="ch02.xhtml#idm45969611891688">34</a>]</h6>
</div></figure>

<p>The following code snippet shows the usage of a lemmatizer based on <a contenteditable="false" data-primary="WordNetLemmatizer" data-type="indexterm" id="idm45969611889704"/>WordNet from <a contenteditable="false" data-primary="Natural Language Tool Kit (NLTK)" data-secondary="lemmatization with" data-type="indexterm" id="idm45969610841928"/>NLTK:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">nltk.stem</code> <code class="kn">import</code> <code class="n">WordNetLemmatizer</code>
<code class="n">lemmatizer</code> <code class="o">=</code> <code class="n">WordnetLemmatizer</code><code class="p">()</code>
<code class="k">print</code><code class="p">(</code><code class="n">lemmatizer</code><code class="o">.</code><code class="n">lemmatize</code><code class="p">(</code><code class="s2">"better"</code><code class="p">,</code> <code class="n">pos</code><code class="o">=</code><code class="s2">"a"</code><code class="p">))</code> <code class="c1">#a is for adjective</code></pre>

<p>And this code snippet shows a lemmatizer using spaCy:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code> <code class="nn">spacy</code>
<code class="n">sp</code> <code class="o">=</code> <code class="n">spacy</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="s1">'en_core_web_sm'</code><code class="p">)</code>
<code class="n">token</code> <code class="o">=</code> <code class="n">sp</code><code class="p">(</code><code class="s-Affix">u</code><code class="s1">'better'</code><code class="p">)</code>
<code class="k">for</code> <code class="n">word</code> <code class="ow">in</code> <code class="n">token</code><code class="p">:</code>
   <code class="k">print</code><code class="p">(</code><code class="n">word</code><code class="o">.</code><code class="n">text</code><code class="p">,</code>  <code class="n">word</code><code class="o">.</code><code class="n">lemma_</code><code class="p">)</code></pre>

<p>NLTK prints the output as “good,” whereas <a contenteditable="false" data-primary="spaCy library" data-secondary="lemmatization with" data-type="indexterm" id="idm45969610957832"/>spaCy prints “well”—both are correct. Since lemmatization involves some amount of linguistic analysis of the word and its context, it is expected that it will take longer to run than stemming, and it’s also typically used only if absolutely necessary. We’ll see how stemming and lemmatization are useful in the next chapters. The choice of lemmatizer is optional; we can choose NLTK or spaCy given what framework we’re using for other pre-processing steps in order to use a single framework in the complete pipeline.</p>

<p>Remember that not all of these steps are always necessary, and not all of them are performed in the order in which they’re discussed here. For example, if we were to remove digits and punctuation, what is removed first may not matter much. However, we typically lowercase the text before stemming. We also don’t remove tokens or lowercase the text before doing lemmatization because we have to know the part of speech of the word to get its lemma, and that requires all tokens in the sentence to be intact. A good practice to follow is to prepare a sequential list of pre-processing tasks to be done after having a clear understanding of how to process our data.</p>

<p><a data-type="xref" href="#common_pre_processing_steps_on_a_blob_o">Figure 2-8</a> lists the different pre-processing steps we’ve seen in this subsection so far, as a quick summary.</p>

<p>Note that these are the more common pre-processing steps, but they’re by no means exhaustive. Depending on the nature of the data, some additional pre-processing steps may be important. Let’s take a look at a few of those steps.</p>

<figure><div id="common_pre_processing_steps_on_a_blob_o" class="figure"><img alt="Common pre-processing steps on a blob of text" src="Images/pnlp_0208.png" width="1142" height="884"/>
<h6><span class="label">Figure 2-8. </span>Common pre-processing steps on a blob of text<a contenteditable="false" data-primary="pre-processing" data-secondary="common steps" data-type="indexterm" id="idm45969611972040"/><a contenteditable="false" data-primary="pre-processing" data-secondary="frequent steps" data-startref="ch02_term17" data-type="indexterm" id="idm45969610904376"/></h6>
</div></figure>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Other Pre-Processing Steps"><div class="sect2" id="other_pre_processing_steps">
<h2>Other Pre-Processing Steps</h2>

<p>So far, we’ve seen a few common pre-processing<a contenteditable="false" data-primary="pre-processing" data-secondary="other steps" data-type="indexterm" id="ch02_term18"/> steps in an NLP pipeline. While we haven’t explicitly stated the nature of the texts, we have assumed that we’re dealing with regular English text. What’s different if that’s not the case? Let’s introduce a few more pre-processing steps to deal with such scenarios, using a few examples.</p>

<section data-type="sect3" data-pdf-bookmark="Text normalization"><div class="sect3" id="text_normalization">
<h3>Text normalization</h3>

<p>Consider a scenario where we’re working with a collection of social media<a contenteditable="false" data-primary="social media text data (SMTD)" data-secondary="normalization of" data-type="indexterm" id="idm45969611035528"/> posts to detect news events. Social media text is very different from the language we’d see in, say, newspapers. A word can be spelled in different ways, including in shortened forms, a phone number can be written in different formats (e.g., with and without hyphens), names are sometimes in lowercase, and so on. When we’re working on developing NLP tools to work with such data, it’s useful to reach a canonical representation of text that captures all these variations into one representation. This is known as <em><a contenteditable="false" data-primary="text normalization" data-type="indexterm" id="idm45969611033352"/>text normalization</em>. Some common steps for text normalization<a contenteditable="false" data-primary="normalization" data-secondary="text" data-type="indexterm" id="idm45969610801816"/> are to convert all text to lowercase or uppercase, convert digits to text (e.g., 9 to nine), expand abbreviations, and so on. A simple way to incorporate text normalization can be found in Spacy<a contenteditable="false" data-primary="spaCy library" data-secondary="source code" data-type="indexterm" id="idm45969610800104"/>’s source code [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610798600-marker" href="ch02.xhtml#idm45969610798600">35</a>], which is a dictionary showing different spellings of a preset collection of words mapped to a single spelling. We’ll see more examples of text normalization in <a data-type="xref" href="ch08.xhtml#social_media">Chapter 8</a>.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Language detection"><div class="sect3" id="language_detection">
<h3>Language detection</h3>

<p>A lot of web content is in non-English languages<a contenteditable="false" data-primary="non-English language detection" data-type="indexterm" id="idm45969610821928"/><a contenteditable="false" data-primary="language" data-secondary="non-English languages" data-type="indexterm" id="idm45969610820856"/>. For example, say we’re asked to collect all reviews about our product on the web. As we navigate different e-commerce websites and start crawling pages related to our product, we notice several non-English reviews showing up. Since a majority of the pipeline is built with language-specific tools, what will happen to our NLP pipeline, which is expecting English text? In such cases, language detection<a contenteditable="false" data-primary="language detection" data-type="indexterm" id="idm45969611940184"/> is performed as the first step in an NLP pipeline. We can use libraries like Polyglot<a contenteditable="false" data-primary="Polyglot Python Library" data-type="indexterm" id="idm45969611938952"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611937720-marker" href="ch02.xhtml#idm45969611937720">36</a>] for language detection. Once this step is done, the next steps could follow a language-specific pipeline.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Code mixing and transliteration"><div class="sect3" id="code_mixing_and_transliteration">
<h3>Code mixing and transliteration</h3>

<p>The discussion above was about a scenario where the content is in non-English languages. However, there’s another scenario where a single piece of content is in more than one language. Many people across the world speak more than one language in their day-to-day lives. Thus, it’s not uncommon to see them using multiple languages in their social media posts, and a single post may contain many languages. As an example of code mixing<a contenteditable="false" data-primary="code mixing" data-type="indexterm" id="idm45969611018680"/>, we can look at a Singlish<a contenteditable="false" data-primary="Singlish" data-type="indexterm" id="idm45969611017400"/> (Singapore slang + English) phrase from LDC [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611016168-marker" href="ch02.xhtml#idm45969611016168">37</a>] in <a data-type="xref" href="#code_mixing_in_a_single_singlish_phrase">Figure 2-9</a>.</p>

<figure><div id="code_mixing_in_a_single_singlish_phrase" class="figure"><img alt="Code mixing in a single Singlish phrase" src="Images/pnlp_0209.png" width="1404" height="238"/>
<h6><span class="label">Figure 2-9. </span>Code mixing in a single Singlish phrase</h6>
</div></figure>

<p>A single popular phrase has words from Tamil, English, Malay, and three Chinese language variants. Code mixing refers to this phenomenon of switching between languages. When people use multiple languages in their write-ups, they often type words from these languages in Roman script, with English spelling. So, the words of another language are written along with English text. This is known as <em><a contenteditable="false" data-primary="transliteration" data-type="indexterm" id="idm45969610961336"/>transliteration</em>. Both of these phenomena are common in multilingual communities and need to be handled during the pre-processing of text. We’ll discuss more about these in <a data-type="xref" href="ch08.xhtml#social_media">Chapter 8</a>, where we’ll see examples of these phenomena in social media text.</p>

<p>This concludes our discussion of common pre-processing steps. While this list is by no means exhaustive, we hope it gives you some idea of the different forms of pre-processing that may be required, depending on the nature of the dataset. Now, let’s take a look at a few more pre-processing steps in the NLP pipeline—ones that need advanced language processing beyond what we’ve seen so far.<a contenteditable="false" data-primary="pre-processing" data-secondary="other steps" data-startref="ch02_term18" data-type="indexterm" id="idm45969611912232"/></p>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Advanced Processing"><div class="sect2" id="advanced_processing">
<h2>Advanced Processing</h2>

<p><a contenteditable="false" data-primary="advanced processing" data-type="indexterm" id="ch02_term19"/>Imagine we’re asked to develop a system to identify person and organization names in our company’s collection of one million documents. The common pre-processing steps we discussed earlier may not be relevant in this context. Identifying names requires us to be able to do POS tagging, as identifying proper nouns can be useful in identifying person and organization names. How do we do POS tagging<a contenteditable="false" data-primary="POS (part-of-speech) tagging" data-type="indexterm" id="idm45969611983064"/><a contenteditable="false" data-type="indexterm" data-primary="part-of-speech (POS) tagging" id="idm45969611981992"/> during the pre-processing stage of the project? We’re not going into the details of how POS taggers are developed (see Chapter 8 in [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611980632-marker" href="ch02.xhtml#idm45969611980632">38</a>] for details) in this book. Pre-trained and readily usable POS taggers are implemented in NLP libraries such as <a contenteditable="false" data-primary="Natural Language Tool Kit (NLTK)" data-secondary="POS tagging" data-type="indexterm" id="idm45969611978792"/>NLTK, spaCy<a contenteditable="false" data-primary="spaCy library" data-secondary="POS tagging" data-type="indexterm" id="idm45969611932344"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611930808-marker" href="ch02.xhtml#idm45969611930808">39</a>], and Parsey McParseface Tagger<a contenteditable="false" data-primary="Parsey McParseface Tagger" data-type="indexterm" id="idm45969611929320"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611928088-marker" href="ch02.xhtml#idm45969611928088">40</a>], and we generally don’t have to develop our own POS-tagging solutions. The following code snippet illustrates how to use many of the pre-built pre-processing functions we’ve discussed so far using the NLP library spaCy<a contenteditable="false" data-primary="spaCy library" data-secondary="pre-processing with" data-type="indexterm" id="idm45969610412664"/>:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code> <code class="nn">spacy</code>
<code class="n">nlp</code> <code class="o">=</code> <code class="n">spacy</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="s1">'en_core_web_sm'</code><code class="p">)</code>
<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="s-Affix">u</code><code class="s1">'Charles Spencer Chaplin was born on 16 April 1889 toHannah Chaplin </code>
         <code class="p">(</code><code class="n">born</code> <code class="n">Hannah</code> <code class="n">Harriet</code>
<code class="n">Pedlingham</code> <code class="n">Hill</code><code class="p">)</code> <code class="ow">and</code> <code class="n">Charles</code> <code class="n">Chaplin</code> <code class="n">Sr</code><code class="s1">')</code>
<code class="k">for</code> <code class="n">token</code> <code class="ow">in</code> <code class="n">doc</code><code class="p">:</code>
    <code class="k">print</code><code class="p">(</code><code class="n">token</code><code class="o">.</code><code class="n">text</code><code class="p">,</code> <code class="n">token</code><code class="o">.</code><code class="n">lemma_</code><code class="p">,</code> <code class="n">token</code><code class="o">.</code><code class="n">pos_</code><code class="p">,</code>
          <code class="n">token</code><code class="o">.</code><code class="n">shape_</code><code class="p">,</code> <code class="n">token</code><code class="o">.</code><code class="n">is_alpha</code><code class="p">,</code> <code class="n">token</code><code class="o">.</code><code class="n">is_stop</code><code class="p">)</code></pre>

<p>In this simple snippet, we can see tokenization, lemmatization, POS tagging, and several other steps in action! Note that if needed we can add additional processing steps with the same code snippet; we’ll leave that as an exercise for the reader. A point to note is that there may be differences in the output among different NLP libraries for the same pre-processing step. This is due in part to implementation differences and algorithmic variations among different libraries. Which library (or libraries) you’ll eventually want to use in your project is a subjective decision based on the amount of language processing you want.</p>

<p>Let’s now consider a slightly different problem: along with identifying person and organization names in our company’s collection of one million documents, we’re also asked to identify if a given person and organization are related to each other in some way (e.g., Satya <a contenteditable="false" data-primary="Nadella, Satya" data-type="indexterm" id="idm45969610562120"/>Nadella is related to <a contenteditable="false" data-primary="Microsoft" data-type="indexterm" id="idm45969610561016"/>Microsoft through the relation CEO). This is known as the problem of <em><a contenteditable="false" data-primary="relationship extraction (RE)" data-type="indexterm" id="idm45969610597640"/>relation extraction</em>, which we’ll discuss in greater detail in <a data-type="xref" href="ch05.xhtml#information_extraction">Chapter 5</a>. But for now, think about what kind of pre-processing we need for this case. We need POS tagging, which we already know how to add to our pipeline. We need a way of identifying person and organization names, which is a separate information extraction task known as <em>named entity recognition (NER)<a contenteditable="false" data-primary="named entity recognition (NER)" data-type="indexterm" id="idm45969610594776"/></em>, which we’ll discuss in <a data-type="xref" href="ch05.xhtml#information_extraction">Chapter 5</a>. Apart from these two, we need a way to identify patterns indicating “relation” between two entities in a sentence. This requires us to have some form of syntactic representation of the sentence, such as parsing, which we saw in <a data-type="xref" href="ch01.xhtml#nlp_a_primer">Chapter 1</a>. Further, we also want a way to identify and link multiple mentions of an entity (e.g., Satya Nadella, Mr. Nadella, he, etc.). We accomplish this with the pre-processing step known as <em>coreference resolution<a contenteditable="false" data-primary="coreference resolution" data-type="indexterm" id="idm45969610590936"/></em>. We saw an example of this in <a data-type="xref" href="ch01.xhtml#an_nlp_walkthrough_conversational_agent">“An NLP Walkthrough: Conversational Agents”</a>. <a data-type="xref" href="#output_from_different_stages_of_nlp_pip">Figure 2-10</a> shows the output from Stanford CoreNLP<a contenteditable="false" data-primary="Stanford Natural Language Processing Group" data-secondary="CoreNLP output" data-type="indexterm" id="idm45969611005544"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969611004008-marker" href="ch02.xhtml#idm45969611004008">41</a>], which illustrates a parser output and coreference resolution output for an example sentence, along with other pre-processing steps we discussed previously.</p>



<p>What we’ve seen so far in this section are some of the most common pre-processing steps in a pipeline. They’re all available as pre-trained, usable models in different NLP libraries. Apart from these, additional, customized pre-processing may be necessary, depending on the application. For example, consider a case where we’re asked to mine the social media sentiment on our product. We start by collecting data from, say, Twitter, and quickly realize there are tweets that are not in English. In such cases, we may also need a language-detection step before doing anything else.</p>

<p>Additionally, what steps we need also depends on a specific application. If we’re creating a system to identify whether the reviewer is expressing a positive or negative sentiment about a movie from a review they wrote, we might not worry much about parsing or coreference resolution, but we would want to consider stop word removal, lowercasing, and removing digits. However, if we’re interested instead in extracting calendar events from emails, we’ll probably be better off not removing stop words or doing stemming, but rather including, say, parsing. In the case where we want to extract relationships between different entities in the text and events mentioned in it, we would need coreference resolution, as we discussed previously. We’ll see examples of cases requiring such steps in <a data-type="xref" href="ch05.xhtml#information_extraction">Chapter 5</a>.</p>

<figure><div id="output_from_different_stages_of_nlp_pip" class="figure"><img alt="Output from different stages of NLP pipeline processing" src="Images/pnlp_0210.png" width="1376" height="1714"/>
<h6><span class="label">Figure 2-10. </span>Output from different stages of NLP pipeline processing</h6>
</div></figure>

<p>Finally, we have to consider the step-by-step procedures of pre-processing in each case, as summarized in <a data-type="xref" href="#advanced_pre_processing_steps_on_a_blob">Figure 2-11</a>.</p>

<figure><div id="advanced_pre_processing_steps_on_a_blob" class="figure"><img alt="Advanced pre-processing steps on a blob of text" src="Images/pnlp_0211.png" width="1206" height="884"/>
<h6><span class="label">Figure 2-11. </span><a contenteditable="false" data-primary="pre-processing" data-secondary="advanced processing" data-type="indexterm" id="idm45969610715448"/>Advanced pre-processing steps on a blob of text</h6>
</div></figure>

<p>For example, <a contenteditable="false" data-primary="POS (part-of-speech) tagging" data-type="indexterm" id="idm45969610713400"/><a contenteditable="false" data-type="indexterm" data-primary="part-of-speech (POS) tagging" id="idm45969610712248"/>POS tagging cannot be preceded by stop word removal, lowercasing, etc., as such processing affects POS tagger output by changing the grammatical structure of the sentence. How a particular pre-processing step is helping a given NLP problem is another question that is specific to the application, and it can only be answered with a lot of experimentation. We’ll discuss more specific pre-processing required for different NLP applications in upcoming chapters. <a contenteditable="false" data-primary="pre-processing" data-startref="ch02_term12" data-type="indexterm" id="idm45969610710520"/><a contenteditable="false" data-primary="advanced processing" data-startref="ch02_term19" data-type="indexterm" id="idm45969610709144"/>For now, let’s move on to the next step: feature engineering<a contenteditable="false" data-primary="feature engineering" data-type="indexterm" id="ch02_term26"/>.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Feature Engineering"><div class="sect1" id="feature_engineering">
<h1>Feature Engineering</h1>

<p>So far, we’ve seen different pre-processing steps and where they can be useful. When we use ML methods to perform our modeling step later, we’ll still need a way to feed this pre-processed text into an ML algorithm. <em>Feature engineering</em> refers to the set of methods that will accomplish this task. It’s also referred to as <em>feature extraction<a contenteditable="false" data-primary="feature extraction" data-seealso="feature engineering" data-type="indexterm" id="idm45969610749928"/></em>. The goal of feature engineering is to capture the characteristics of the text into a numeric vector that can be understood by the ML algorithms. We refer to this step as “text representation<a contenteditable="false" data-primary="text representation" data-type="indexterm" id="idm45969610748184"/>” in this book, and it’s the topic of <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a>. We also detail feature extraction in the context of developing a complete NLP pipeline and iterating to improve performance in <a data-type="xref" href="ch11.xhtml#the_end_to_end_nlp_process">Chapter 11</a>. Here, we’ll briefly touch on two different approaches taken in practice for feature engineering in (1) a classical NLP and traditional ML pipeline and (2) a DL pipeline. <a data-type="xref" href="#feature_engineering_for_classical_nlp_v">Figure 2-12</a> (adapted from [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610686184-marker" href="ch02.xhtml#idm45969610686184">42</a>]) distinguishes the two approaches.</p>

<figure><div id="feature_engineering_for_classical_nlp_v" class="figure"><img alt="Feature engineering for classical NLP versus DL-based NLP" src="Images/pnlp_0212.png" width="1397" height="2046"/>
<h6><span class="label">Figure 2-12. </span>Feature engineering for classical NLP<a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="classical" data-type="indexterm" id="idm45969610683304"/> versus DL-based NLP<a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="DL-based" data-type="indexterm" id="idm45969610681736"/><a contenteditable="false" data-primary="deep learning (DL)" data-secondary="feature engineering" data-type="indexterm" id="idm45969610680312"/></h6>
</div></figure>

<section data-type="sect2" data-pdf-bookmark="Classical NLP/ML Pipeline"><div class="sect2" id="classical_nlpsolidusml_pipeline">
<h2>Classical NLP/ML Pipeline</h2>

<p><a contenteditable="false" data-primary="machine learning (ML)" data-secondary="feature engineering" data-type="indexterm" id="idm45969610677224"/><a contenteditable="false" data-primary="machine learning (ML)" data-secondary="classical" data-type="indexterm" id="idm45969611050664"/><a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="classical" data-type="indexterm" id="idm45969611049288"/>Feature engineering is an integral step in any ML pipeline. Feature engineering steps convert the raw data into a format that can be consumed by a machine. These transformation functions are usually handcrafted in the classical ML pipeline, aligning to the task at hand. For example, imagine a task of sentiment classification on product reviews in e-commerce. One way to convert the reviews into meaningful “numbers” that helps predict the reviews’ sentiments (positive or negative) would be to count the number of positive and negative words in each review. There are statistical measures for understanding if a feature is useful for a task or not; we’ll discuss this in <a data-type="xref" href="ch11.xhtml#the_end_to_end_nlp_process">Chapter 11</a>. The main takeaway for building classical ML models is that the features are heavily inspired by the task at hand as well as domain knowledge (for example, using sentiment words in the review example). One of the advantages of handcrafted features is that the model remains interpretable—it’s possible to quantify exactly how much each feature is influencing the model prediction.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="DL Pipeline"><div class="sect2" id="dl_pipeline">
<h2>DL Pipeline</h2>

<p><a contenteditable="false" data-primary="deep learning (DL)" data-secondary="feature engineering" data-type="indexterm" id="idm45969611043992"/>The main drawback of classical ML models is the feature engineering. Handcrafted feature engineering becomes a bottleneck for both model performance and the model development cycle. A noisy or unrelated feature can potentially harm the model’s performance by adding more randomness to the data. Recently, with the advent of DL models, this approach has changed. In the DL pipeline, the raw data (after pre-processing) is directly fed to a model. The model is capable of “learning” features from the data. Hence, these features are more in line with the task at hand, so they generally give improved performance. But, since all these features are learned via model parameters, the model loses interpretability. It’s very hard to explain a DL model’s prediction, which is a disadvantage in a business-driven use case. For example, when identifying an email as ham or spam, it might be worth knowing which word or phrases played the significant role in making the email ham or spam. While this is easy to do with handcrafted features, it’s not easy in the case of DL models.</p>

<p>As we’ve already mentioned, feature engineering is heavily task specific, so we discuss it throughout the book in the context of textual data and a range of tasks. With a high-level understanding of feature engineering, now let’s take a look at the next step in the pipeline, which we<a contenteditable="false" data-primary="feature engineering" data-startref="ch02_term26" data-type="indexterm" id="idm45969611040664"/> call <em>modeling</em>.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Modeling"><div class="sect1" id="modeling">
<h1>Modeling</h1>

<p><a contenteditable="false" data-primary="modeling" data-type="indexterm" id="ch02_term27"/>We now have some amount of data related to our NLP project and a clear idea of what sort of cleaning up and pre-processing needs to be done and what features are to be extracted. The next step is about how to build a useful solution out of this. At the start, when we have limited data, we can use simpler methods and rules. Over time, with more data and a better understanding of the problem, we can add more complexity and improve performance. We’ll cover this process in this section.</p>

<section data-type="sect2" data-pdf-bookmark="Start with Simple Heuristics"><div class="sect2" id="start_with_simple_heuristics">
<h2>Start with Simple Heuristics</h2>

<p><a contenteditable="false" data-primary="heuristics" data-secondary="simple" data-type="indexterm" id="ch02_term28"/>At the very start of building a model, ML may not play a major role by itself. Part of that could be due to a lack of data, but human-built heuristics can also provide a great start in some ways. Heuristics may already be part of your system, either implicitly or explicitly. For instance, in email spam-classification tasks, we may have a blacklist of domains that are used exclusively to send spam. This information can be used to filter emails from those domains. Similarly, a blacklist of words in an email that denote a high chance of spam could also be used for this classification.</p>

<p>Such heuristics can be found in a range of tasks, especially at the start of applying ML. In an e-commerce setting, we may use a heuristic based on the number of purchases for ordering search results and show products belonging to the same category as recommendations while we collect data that could be used to build a larger, collaborative, filtering-based system that can recommend products using a range of other characteristics based on what customers with similar buying profiles purchased.</p>

<p>Another popular approach to incorporating heuristics in your system is using regular expressions. Let’s say we’re developing a system to extract different forms of information from text documents, such as dates and phone numbers, names of people who work in a given organization, etc. While some information, such as email IDs, dates, and telephone numbers can be extracted using normal (albeit complex) regular expressions, <a contenteditable="false" data-primary="Stanford Natural Language Processing Group" data-secondary="TokensRegex" data-type="indexterm" id="idm45969610927288"/><a contenteditable="false" data-primary="TokensRegex (Stanford NLP)" data-type="indexterm" id="idm45969610925944"/>Stanford NLP’s TokensRegex [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610924696-marker" href="ch02.xhtml#idm45969610924696">43</a>] and spaCy<a contenteditable="false" data-primary="spaCy library" data-secondary="rule-based matcher" data-type="indexterm" id="idm45969610923224"/>’s rule-based matching [<a data-type="noteref" href="ch02.xhtml#footnote_2_51">20</a>] are two tools that are useful for defining advanced regular expressions to capture other information, such as people who work in a specific organization. <a data-type="xref" href="#spacyapostrophes_rule_based_matcher">Figure 2-13</a> shows an example of spaCy’s rule-based matcher in action.</p>



<p>This shows a pattern that looks for text containing the lemma “match,” appearing as a noun, optionally preceded by an adjective, and followed by any word form of lemma “be.” Such patterns are an advanced form of regular expressions, which require some of the NLP pre-processing steps we saw earlier in this chapter. In the absence of large amounts of training data, and when we have some domain knowledge, we can start building systems by encoding this knowledge in the form of rules/heuristics. Even when we’re building ML-based models, we can use such heuristics to handle special cases—for example, cases where the model has failed to learn well. Thus, simple heuristics can give us a good starting point and be useful in ML models. Now, assuming we built such a heuristics-based system, where do we go from there?</p>

<figure><div id="spacyapostrophes_rule_based_matcher" class="figure"><img alt="spaCy’s rule-based matcher" src="Images/pnlp_0213.png" width="1109" height="842"/>
<h6><span class="label">Figure 2-13. </span>spaCy’s rule-based matcher</h6>
</div></figure>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Building Your Model"><div class="sect2" id="building_your_model">
<h2>Building Your Model</h2>

<p>While<a contenteditable="false" data-primary="spaCy library" data-secondary="rule-based matcher" data-type="indexterm" id="idm45969610890008"/> a set of simple heuristics is a good start, as our system matures, adding newer and newer heuristics may result in a complex, rule-based system. Such a system is hard to manage, and it can be even harder to diagnose the cause of errors. We need a system that’s easier to maintain as it matures. Further, as we collect more data, our ML model starts beating pure heuristics. At that point, a common practice is to combine heuristics directly or indirectly with the ML model. There are two broad ways of doing that:<a contenteditable="false" data-primary="modeling" data-secondary="combining heuristics with" data-type="indexterm" id="idm45969610887944"/><a contenteditable="false" data-primary="heuristics" data-secondary="combining with ML" data-type="indexterm" id="idm45969610886552"/></p>

<dl>
	<dt>Create a feature from the heuristic for your ML model</dt>
<dd><p>When there are many heuristics where the behavior of a single heuristic is deterministic but their combined behavior is fuzzy in terms of how they predict, it’s best to use these heuristics as features to train your ML model. For instance, in the email spam-classification example, we can add features, such as the number of words from the blacklist in a given email or the email bounce rate, to the ML model.</p></dd>
	<dt><a contenteditable="false" data-primary="pre-processing" data-type="indexterm" id="idm45969610218552"/>Pre-process your input to the ML model</dt>
<dd><p>If the heuristic has a really high prediction for a particular kind of class, then it’s best to use it before feeding the data in your ML model. For instance, if for certain words in an email, there’s a 99% chance that it’s spam, then it’s best to classify that email as spam instead of sending it to an ML model.</p></dd>
	</dl>


<p>Additionally, we have NLP service providers, such as Google Cloud Natural Language<a contenteditable="false" data-primary="Google Cloud" data-secondary="Natural Language" data-type="indexterm" id="idm45969610215672"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610214168-marker" href="ch02.xhtml#idm45969610214168">44</a>], Amazon Comprehend<a contenteditable="false" data-primary="Amazon Comprehend" data-type="indexterm" id="idm45969610212680"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610211480-marker" href="ch02.xhtml#idm45969610211480">45</a>], <a contenteditable="false" data-primary="Microsoft Azure" data-secondary="Cognitive Services" data-type="indexterm" id="idm45969610209992"/>Microsoft Azure Cognitive Services [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610208440-marker" href="ch02.xhtml#idm45969610208440">46</a>], and IBM Watson Natural Language Understanding<a contenteditable="false" data-primary="IBM Watson" data-type="indexterm" id="idm45969610982008"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610980840-marker" href="ch02.xhtml#idm45969610980840">47</a>], which provide off-the-shelf APIs<a contenteditable="false" data-primary="modeling" data-secondary="with APIs" data-secondary-sortas="APIs" data-type="indexterm" id="idm45969610979240"/><a contenteditable="false" data-primary="APIs" data-secondary="modeling with" data-type="indexterm" id="idm45969610977656"/> to solve various NLP tasks. If your project has an NLP problem that’s addressed by these APIs, you can start by using them to get an estimate of the feasibility of the task and how good your existing dataset is. Once you’re comfortable that the task is feasible and conclude that the off-the-shelf models give reasonable results, you can move toward building custom ML models and improving them.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Building THE Model"><div class="sect2" id="building_the_model">
<h2>Building THE Model</h2>

<p>We’ve seen examples of getting started building an NLP system by using heuristics or existing APIs, or by building our own ML models. We start with a baseline approach and work toward improving it. We may have to do many iterations of the model-building process to “build THE model” that gives good performance and is also production-ready. We cover some of the approaches to<a contenteditable="false" data-primary="modeling" data-secondary="approaches to" data-type="indexterm" id="ch02_term29"/> address this issue here:</p>

<dl>
	<dt>Ensemble and stacking<a contenteditable="false" data-primary="stacking" data-type="indexterm" id="idm45969610970760"/></dt>
	<dd><p>In our experience, a common practice is not to have a single model, but to use a collection of ML models, often dealing with different aspects of the prediction problem. There are two ways of doing this: we can feed one model’s output as input for another model, thus sequentially going from one model to another and obtaining a final output. This is called <em>model stacking<a contenteditable="false" data-primary="model stacking" data-type="indexterm" id="idm45969610968376"/></em>.<sup xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook"><a data-type="noteref" id="ch02fn1-marker" href="ch02.xhtml#ch02fn1">i</a></sup> Alternatively, we can also pool predictions from multiple models and make a final prediction. This is called <em>model ensembling<a contenteditable="false" data-primary="model ensembling" data-type="indexterm" id="idm45969610640392"/></em>. <a data-type="xref" href="#model_ensemble_and_stacking">Figure 2-14</a> demonstrates both of these procedures.</p>

	<p>In this figure, training data is used to build Models 1, 2, and 3. Outputs of these models are then combined to be used in a meta-model (a model that uses other models) to predict the final outcome. For example, in the email spam-classification case, we can assume that we run three different models: a heuristic-based score, Naive Bayes, and LSTM. The output of these three models is then fed into the meta-model based on logistic regression, which then gives the chances of the email being spam or not. As the product grows in terms of its features, the model will also grow in complexity. So, we may eventually end up using a combination of all of these—i.e., heuristics, machine learning, and stacked and ensemble models—as part of a large product.</p>
	 
	 <figure><div id="model_ensemble_and_stacking" class="figure"><img alt="Model ensemble and stacking" src="Images/pnlp_0214.png" width="1409" height="817"/>
	<h6><span class="label">Figure 2-14. </span>Model ensemble<a contenteditable="false" data-primary="model ensembling" data-type="indexterm" id="idm45969610635272"/> and stacking<a contenteditable="false" data-primary="model stacking" data-type="indexterm" id="idm45969610634008"/><a contenteditable="false" data-primary="stacking" data-type="indexterm" id="idm45969610632872"/></h6>
	</div></figure>
	</dd>

	<dt>Better feature engineering<a contenteditable="false" data-primary="feature engineering" data-type="indexterm" id="idm45969610631096"/></dt> 
	<dd><p>For both API-based and custom-built models, feature engineering is an important step, and it evolves throughout the process. A better feature engineering step may lead to better performance. For instance, if there are a lot of features, then we use feature selection to find a better model. We detail strategies for iterating feature engineering to achieve an optimal setting in <a data-type="xref" href="ch11.xhtml#the_end_to_end_nlp_process">Chapter 11</a>.</p></dd>
	<dt>Transfer learning</dt>
	<dd><p>Apart from model stacking or ensemble, there is a newer trend that’s becoming popular in the NLP community—<em><a contenteditable="false" data-primary="transfer learning" data-type="indexterm" id="idm45969610626712"/>transfer learning</em>, which we introduced in <a data-type="xref" href="ch01.xhtml#nlp_a_primer">Chapter 1</a>. Often, the model needs external knowledge beyond the dataset for the task to understand the language and the problem well. Transfer learning tries to transfer preexisting knowledge from a big, well-trained model to a newer model at its initial phase. Afterward, the new model slowly adapts to the task at hand. This is analogous to a teacher transferring wisdom and knowledge to a student. Transfer learning provides a better initialization, which helps in the downstream tasks, especially when the dataset for the downstream task is smaller. In these cases, transfer learning yields better results than just initializing a downstream model from scratch with random initialization. As an example, for email spam classification, we can use BERT to fine-tune the email dataset. We cover BERT in greater detail in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a> through <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch06.xhtml#chatbots">6</a>.</p></dd>
	<dt>Reapplying <a contenteditable="false" data-primary="heuristics" data-secondary="reapplying" data-type="indexterm" id="idm45969610949208"/>heuristics</dt> 
	<dd><p>No ML model is perfect. Hence, ML models still make mistakes. It’s possible to revisit these cases again at the end of the modeling pipeline to find any common pattern in errors and use heuristics to correct them. We can also apply domain-specific knowledge that is not automatically captured in the data to refine the model predictions. An analogy for reapplying heuristics would be our model as a trapeze artist performing great feats and these rules as the safety net so the artist doesn’t <a contenteditable="false" data-primary="modeling" data-secondary="approaches to" data-startref="ch02_term29" data-type="indexterm" id="idm45969610946552"/>fall off.</p></dd>
</dl>


<p>Between the stage of having no data, when we fully rely on heuristics, to a lot of data, where we can try a range of modeling techniques, we encounter a situation where we have a small amount of data, which is often not sufficient to build good ML models. In such scenarios, one approach to follow is active learning, where we can use user feedback or other such sources to continuously collect new data to build better models. We’ll discuss this in detail in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>. As we’ve just seen, modeling <a contenteditable="false" data-primary="modeling" data-secondary="strategies for" data-type="indexterm" id="idm45969610942920"/>strategies depend heavily on the data at hand. <a data-type="xref" href="#data_attributes_and_associated_decision">Table 2-1</a> provides a range of decision paths given our data volume and quality, based on our experience.</p>

<table class="border" id="data_attributes_and_associated_decision">
	<caption><span class="label">Table 2-1. </span>Data attributes and associated decision paths</caption>
	<thead>
		<tr>
			<th>Data attribute</th>
			<th>Decision path</th>
			<th>Examples</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>Large data volume</td>
			<td>Can use techniques that require more data, like DL. Can use a richer set of features as well.<br/>
			If the data is sufficiently large but unlabeled, we can also apply unsupervised techniques.</td>
			<td>If we have a lot of reviews and metadata associated with them, we can build a sentiment-analysis tool from scratch.</td>
		</tr>
		<tr>
			<td>Small data volume</td>
			<td>Need to start with rule-based or traditional ML solutions that are less data hungry. Can also adapt cloud APIs and generate more data with weak supervision.<br/>
			We can also use transfer learning if there’s a similar task that has large data.</td>
			<td>This often happens at the start of a completely new project.</td>
		</tr>
		<tr>
			<td>Data quality is poor and the data is heterogeneous in nature</td>
			<td>More data cleaning and pre-processing might be required.</td>
			<td>This entails issues like code mixing (different languages being mixed in the same sentence), unconventional language, transliteration, or noise (like social media text).</td>
		</tr>
		<tr>
			<td>Data quality is good</td>
			<td>Can directly apply off-the-shelf algorithms or cloud APIs more easily.</td>
			<td>Legal text or newspapers.</td>
		</tr>
		<tr>
			<td>Data consists of full-length documents</td>
			<td>Choose the right strategy for breaking the document into lower levels, like paragraphs, sentences, or phrases, depending on the problem.</td>
			<td>Document classification, review analysis, etc.</td>
		</tr>
	</tbody>
</table>

<p>So far, we’ve seen an overview of different forms of modeling that can be useful in an NLP pipeline and what modeling path to choose based on the data we have. Supervised learning, especially classification, is the most common modeling process you’ll encounter in the NLP projects you’ll be building in an industry scenario. We’ll discuss classification models in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a> and models used for different application scenarios in NLP in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch05.xhtml#information_extraction">5</a> through <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch07.xhtml#topics_in_brief">7</a>. Now, let’s take a look at the next step in the pipeline: evaluation.<a contenteditable="false" data-primary="modeling" data-startref="ch02_term27" data-type="indexterm" id="idm45969610607256"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Evaluation"><div class="sect1" id="evaluation">
<h1>Evaluation</h1>

<p><a contenteditable="false" data-primary="evaluation" data-type="indexterm" id="ch02_term330"/>A key step in the NLP pipeline is to measure how <em>good</em> the model we’ve built is. “Goodness<a contenteditable="false" data-primary="modeling" data-secondary="goodness of fit" data-type="indexterm" id="idm45969610602056"/>” of a model can have multiple meanings, but the most common interpretation is the measure of the model’s performance on unseen data. Success in this phase depends on two factors: (1) using the right metric for evaluation, and (2) following the right evaluation process. Let’s first focus on 1. Depending on the NLP task or problem, the evaluation metrics can vary. They can also vary depending on the phase: the model building, deployment, and production phases. Whereas in the first two phases, we typically use ML metrics, in the final phase, we also include business metrics to measure business impact.</p>

<p>Also, evaluations are of two types: intrinsic and extrinsic. Intrinsic focuses on <em>intermediary</em> objectives, while extrinsic<a contenteditable="false" data-primary="evaluation" data-secondary="extrinsic" data-type="indexterm" id="idm45969610599096"/> focuses on evaluating performance on the <em>final</em> objective. For example, consider a spam-classification system. The ML metric will be precision and recall, while the business metric will be “the amount of time users spent on a spam email.” Intrinsic evaluation will focus on measuring the system performance using precision and recall. Extrinsic evaluation will focus on measuring the time a user wasted because a spam email went to their inbox or a genuine email went to their spam folder.</p>

<section data-type="sect2" data-pdf-bookmark="Intrinsic Evaluation"><div class="sect2" id="intrinsic_evaluation">
<h2>Intrinsic Evaluation</h2>

<p>In this section, we’ll look at some intrinsic<a contenteditable="false" data-primary="evaluation" data-secondary="intrinsic" data-type="indexterm" id="ch02_term331"/> evaluation metrics that are commonly used to measure NLP systems. For most metrics in this category, we assume a test set where we have the <em><a contenteditable="false" data-primary="ground truth" data-type="indexterm" id="idm45969610876536"/>ground truth</em> or <em>labels<a contenteditable="false" data-primary="labels" data-type="indexterm" id="idm45969610874856"/></em> (human annotated, correct answers). Labels could be binary (e.g., 0/1 for text classification), one-to-two words (e.g., names for named entity recognition), or large text itself (e.g., text translated by machine translation). The output of the NLP model on a data point is <em>compared</em> against the corresponding label for that data point, and metrics are calculated based on the match (or mismatch) between the output and label. For most NLP tasks, the comparison can be automated, hence intrinsic evaluation can be automated. For some cases, like machine translation or summarization, it’s not always possible to automate evaluation since comparison is not subjective.</p>

<p><a data-type="xref" href="#popular_metrics_and_nlp_applications_wh">Table 2-2</a> lists various metrics used for intrinsic evaluation across various NLP tasks. For a more detailed discussion of the metrics, refer to the corresponding reference.</p>
<a contenteditable="false" data-primary="evaluation" data-secondary="metrics and applications" data-startref="ch02_term32" data-type="indexterm" id="idm45969610870872"/>

<table class="border" id="popular_metrics_and_nlp_applications_wh">
	<caption><span class="label">Table 2-2. </span>Popular metrics<a contenteditable="false" data-primary="evaluation" data-secondary="metrics and applications" data-type="indexterm" id="ch02_term32"/> and NLP applications where they’re used</caption>
	<thead>
		<tr>
			<th>Metric</th>
			<th>Description</th>
			<th>Applications</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>Accuracy<a contenteditable="false" data-primary="accuracy" data-type="indexterm" id="idm45969610862440"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_2_30-marker" href="ch02.xhtml#footnote_2_30">48</a>]</td>
			<td>Used when the output variable is categorical or discrete. It denotes the fraction of times the model makes correct predictions as compared to the total predictions it makes.</td>
			<td>Mainly used in classification tasks, such as sentiment classification (multiclass), natural language inference (binary), paraphrase detection (binary), etc.</td>
		</tr>
		<tr>
			<td>Precision<a contenteditable="false" data-primary="precision" data-type="indexterm" id="idm45969610857736"/> [<a data-type="noteref" href="ch02.xhtml#footnote_2_30">48</a>]</td>
			<td>Shows how precise or exact the model’s predictions are, i.e., given all the positive (the class we care about) cases, how many can the model classify correctly?</td>
			<td>Used in various classification tasks, especially in cases where mistakes in a positive class are more costly than mistakes in a negative class, e.g., disease predictions in healthcare.</td>
		</tr>
		<tr>
			<td>Recall<a contenteditable="false" data-primary="recall" data-type="indexterm" id="idm45969610053432"/> [<a data-type="noteref" href="ch02.xhtml#footnote_2_30">48</a>]</td>
			<td>Recall is complementary to precision. It captures how well the model can recall positive class, i.e., given all the positive predictions it makes, how many of them are indeed positive?</td>
			<td>Used in classification tasks, especially where retrieving positive results is more important, e.g., e-commerce search and other information-retrieval tasks.</td>
		</tr>
		<tr>
			<td>F1 score<a contenteditable="false" data-primary="F1 score" data-type="indexterm" id="idm45969610049336"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610048072-marker" href="ch02.xhtml#idm45969610048072">49</a>]</td>
			<td>Combines precision and recall to give a single metric, which also captures the trade-off between precision and recall, i.e., completeness and exactness.<br/>
			F1 is defined as (2 × Precision × Recall) / (Precision + Recall).</td>
			<td>Used simultaneously with accuracy in most of the classification tasks. It is also used in sequence-labeling tasks, such as entity extraction, retrieval-based questions answering, etc.</td>
		</tr>
		<tr>
			<td>AUC<a contenteditable="false" data-primary="AUC" data-type="indexterm" id="idm45969610044312"/> [<a data-type="noteref" href="ch02.xhtml#footnote_2_30">48</a>]</td>
			<td>Captures the count of positive predictions that are correct versus the count of positive predictions that are incorrect as we vary the threshold for prediction.</td>
			<td>Used to measure the quality of a model independent of the prediction threshold. It is used to find the optimal prediction threshold for a classification task.</td>
		</tr>
		<tr>
			<td>MRR (mean reciprocal rank)<a contenteditable="false" data-primary="MRR (Mean Reciprocal Rank)" data-type="indexterm" id="idm45969610040088"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610038792-marker" href="ch02.xhtml#idm45969610038792">50</a>]</td>
			<td>Used to evaluate the responses retrieved given their probability of correctness. It is the mean of the reciprocal of the ranks of the retrieved results.</td>
			<td>Used heavily in all information-retrieval tasks, including article search, e-commerce search, etc.</td>
		</tr>
		<tr>
			<td><a contenteditable="false" data-primary="MAP (Mean Average Precision)" data-type="indexterm" id="idm45969610035480"/>MAP (mean average precision) [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610034184-marker" href="ch02.xhtml#idm45969610034184">51</a>]</td>
			<td>Used in ranked retrieval results, like MRR. It calculates the mean precision across each retrieved result.</td>
			<td>Used in information-retrieval tasks.</td>
		</tr>
		<tr>
			<td>RMSE (root mean squared error)<a contenteditable="false" data-primary="RMSE (Root Mean Squared Error)" data-type="indexterm" id="idm45969610030776"/> [<a data-type="noteref" href="ch02.xhtml#footnote_2_30">48</a>]</td>
			<td>Captures a model’s performance in a real-value prediction task. Calculates the square root of the mean of the squared errors for each data point.</td>
			<td>Used in conjunction with MAPE in the case of regression problems, from temperature prediction to stock market price prediction.</td>
		</tr>
		<tr>
			<td>MAPE (mean absolute percentage error)<a contenteditable="false" data-primary="MAPE (Mean Absolute Percentage Error)" data-type="indexterm" id="idm45969610026616"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610025320-marker" href="ch02.xhtml#idm45969610025320">52</a>]</td>
			<td>Used when the output variable is a continuous variable. It is the average of absolute percentage error for each data point.</td>
			<td>Used to test the performance of a regression model.<br/>
			It is often used in conjunction with RMSE.</td>
		</tr>
		<tr>
			<td>BLEU (bilingual evaluation understudy)<a contenteditable="false" data-primary="BLEU (Bilingual Evaluation Understudy)" data-type="indexterm" id="idm45969610021592"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610020296-marker" href="ch02.xhtml#idm45969610020296">53</a>]</td>
			<td>Captures the amount of n-gram overlap between the output sentence and the reference ground truth sentence. It has many variants.</td>
			<td>Mainly used in machine-translation tasks. Recently adapted to other text-generation tasks, such as paraphrase generation and text summarization.</td>
		</tr>
		<tr>
			<td>METEOR<a contenteditable="false" data-primary="METEOR" data-type="indexterm" id="idm45969610017016"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969610015752-marker" href="ch02.xhtml#idm45969610015752">54</a>]</td>
			<td>A precision-based metric to measure the quality of text generated. It fixes some of the drawbacks of BLEU, such as exact word matching while calculating precision. METEOR allows synonyms and stemmed words to be matched with the reference word.</td>
			<td>Mainly used in machine translation.</td>
		</tr>
		<tr>
			<td>ROUGE<a contenteditable="false" data-type="indexterm" data-primary="Recall-Oriented Understudy for Gisting Evaluation (ROUGE)" id="idm45969610012360"/><a contenteditable="false" data-primary="ROUGE (Recall-Oriented Understudy for Gisting Evaluation)" data-type="indexterm" id="idm45969609998888"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969609997688-marker" href="ch02.xhtml#idm45969609997688">55</a>]</td>
			<td>Another metric to compare quality of generated text with respect to a reference text. As opposed to BLEU, it measures recall.</td>
			<td>Since it measures recall, it’s mainly used for summarization tasks where it’s important to evaluate how many words a model can recall.</td>
		</tr>
		<tr>
			<td>Perplexity<a contenteditable="false" data-primary="perplexity" data-type="indexterm" id="idm45969609994504"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_2_19-marker" href="ch02.xhtml#footnote_2_19">56</a>]</td>
			<td>A probabilistic measure that captures how confused an NLP model is. It’s derived from the cross-entropy in a next word prediction task. The exact definition can be found at [<a data-type="noteref" href="ch02.xhtml#footnote_2_19">56</a>].</td>
			<td>Used to evaluate language models. It can also be used in language-generation tasks, such as dialog generation.</td>
		</tr>
	</tbody>
</table>

<p>Apart from the list of metrics shown in <a data-type="xref" href="#popular_metrics_and_nlp_applications_wh">Table 2-2</a>, there are few more metrics and visualizations that are often used for solving NLP problems. While we’ve covered these topics briefly here, we encourage you to follow the references and learn more about these metrics.</p>

<p>In the case of classification tasks<a contenteditable="false" data-primary="classification tasks" data-type="indexterm" id="idm45969609987224"/>, a commonly used visual evaluation method<a contenteditable="false" data-primary="evaluation" data-secondary="visual methods" data-type="indexterm" id="idm45969609985928"/><a contenteditable="false" data-primary="visual evaluation methods" data-type="indexterm" id="idm45969609984552"/> is a <em>confusion matrix<a contenteditable="false" data-primary="confusion matrix" data-type="indexterm" id="idm45969609982936"/></em>. It allows us to inspect the actual and predicted output for different classes in the dataset. The name stems from the fact that it helps to understand how “confused” the classification model is in terms of identifying different classes. A confusion matrix is in turn used to compute metrics such as precision, recall, F1 score, and accuracy. We’ll see how to use confusion matrices in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>.</p>

<p><a contenteditable="false" data-primary="ranking" data-type="indexterm" id="idm45969609980008"/>Ranking tasks like information search and retrieval mostly uses ranking-based metrics, such as <a contenteditable="false" data-primary="MRR (Mean Reciprocal Rank)" data-type="indexterm" id="idm45969609978664"/>MRR and <a contenteditable="false" data-primary="MAP (Mean Average Precision)" data-type="indexterm" id="idm45969609977416"/>MAP, but usual classification metrics can be used, too. In the case of retrieval, we care mainly about recall, so recall at various ranks is calculated. For example, for information retrieval, a common metric is “Recall at rank K<a contenteditable="false" data-primary="Recall at rank K" data-type="indexterm" id="idm45969609975896"/>”; it looks for the presence of ground truth in top K retrieved results. If present, it’s a <span class="keep-together">success.</span></p>

<p>When it comes to text-generation tasks<a contenteditable="false" data-primary="text-generation tasks" data-type="indexterm" id="ch02_term33"/>, there are a number of metrics that are used, depending on the task. Even though BLEU<a contenteditable="false" data-primary="BLEU (Bilingual Evaluation Understudy)" data-type="indexterm" id="idm45969609972072"/> and METEOR are good metrics for machine translation, they may not be good metrics when applied to other generation tasks. For example, in the case of dialog generation, the ground truth is one of the correct answers, but there could be many variations in responses that are not listed. In cases like this, precision-based metrics such as BLEU and METEOR will completely fail to capture the task performance faithfully. For these reasons, perplexity is one metric that’s used extensively to understand a model’s text-generation ability.</p>

<p>However, any evaluation scheme for text generation is not perfect. This is because there could be multiple sentences that have the same meaning, and it’s not possible to have all the variations listed as ground truth. Therefore, the text generated and the ground truth can have the same meaning but be different sentences. This makes automated evaluation a difficult process. For example, say we build a machine-translation model that converts sentences from French to English. Consider the following sentence in French: “J’ai mangé trois filberts.” In English, this means, “I ate three filberts.” So, we put this sentence as the label. Say our model generates the following English translation: “I ate three hazelnuts.” Since the output does not match the label, automated evaluation will say the output is incorrect. But this <em>evaluation</em> is incorrect because English speakers are known to refer to filberts as hazelnuts. Even if we add this sentence as a possible label, our model could still generate “I have eaten three hazelnuts” as output. Yet again, the automated evaluation will say the model got it wrong since the output does not match either of the two labels. This is where human evaluation comes into play. But human evaluation can be expensive both in terms of time and<a contenteditable="false" data-primary="text-generation tasks" data-startref="ch02_term33" data-type="indexterm" id="idm45969609968056"/><a contenteditable="false" data-primary="evaluation" data-secondary="intrinsic" data-startref="ch02_term331" data-type="indexterm" id="idm45969609966680"/> money.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Extrinsic Evaluation"><div class="sect2" id="extrinsic_evaluation">
<h2>Extrinsic Evaluation</h2>

<p>Like we said earlier, extrinsic<a contenteditable="false" data-primary="evaluation" data-secondary="extrinsic" data-type="indexterm" id="ch02_term34"/> evaluation focuses on evaluating the model performance on the final objective. In industrial projects, any AI model is built with the aim of solving a business problem. For example, a regression model is built with the aim of ranking the emails of the users and bringing the most important emails to the top of the inbox, thereby helping the users of an email service save time. Consider a scenario where the regression model does well on the ML metrics but doesn’t really save a lot of time for the email service users, or where a question-answering model does very well on intrinsic metrics but fails to address a large number of questions in the production environment. Would we call such models successful? No, because they failed to achieve their business objectives. While this is not an issue for researchers in academia, for practitioners in industry, it’s very important.</p>

<p>The way to carry out extrinsic evaluation is to set up the business metrics and the process to measure them correctly at the start of the project. We’ll see examples of the right business metrics in later chapters.</p>

<p>We might ask: if extrinsic evaluation is what matters, why do intrinsic evaluation at all? The reason we must do intrinsic evaluation before extrinsic evaluation is that extrinsic evaluation often includes project stakeholders outside the AI team—sometimes even end users. Intrinsic evaluation can be done mostly by the AI team itself. This makes extrinsic evaluation a much more expensive process as compared to intrinsic evaluation. Therefore, intrinsic evaluation is used as a proxy for extrinsic evaluation. Only when we get consistently good results in intrinsic evaluation should we go for extrinsic evaluation.</p>

<p>Another thing to remember is that bad results in intrinsic evaluation often imply bad results in extrinsic evaluation. However, the converse may not be true. That is, we can have a model that does very well in intrinsic evaluation but does badly in extrinsic evaluation, but it’s unlikely that a model that does well in extrinsic evaluation did poorly during intrinsic evaluation. The reasons for poor performance in extrinsic evaluation could be many, from setting up the wrong metrics to not having suitable data or having wrong expectations. We touched on some of these in <a data-type="xref" href="ch01.xhtml#nlp_a_primer">Chapter 1</a> and will discuss them in more detail in <a data-type="xref" href="ch11.xhtml#the_end_to_end_nlp_process">Chapter 11</a>.</p>

<p>So far, we’ve seen some metrics commonly used for intrinsic evaluation and also discussed the importance of extrinsic evaluation to measure the performance of NLP models. There are some more metrics that are task specific, which are not seen across different NLP application scenarios. We’ll discuss such evaluation measures in detail as we cover these specific applications in upcoming chapters. With this, now let’s look at the next components of the pipeline: model deployment, monitoring, and<a contenteditable="false" data-primary="evaluation" data-secondary="extrinsic" data-startref="ch02_term34" data-type="indexterm" id="idm45969609954888"/><a contenteditable="false" data-primary="evaluation" data-startref="ch02_term330" data-type="indexterm" id="idm45969609953240"/> <span class="keep-together">updating.</span></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Post-Modeling Phases"><div class="sect1" id="post_modeling_phases">
<h1>Post-Modeling Phases</h1>

<p>Once our model has been tried and tested, we move on to the post-modeling phase: deploying, monitoring, and updating the model. We’ll cover these briefly in this <span class="keep-together">section</span>.<a contenteditable="false" data-primary="post-modeling phases" data-type="indexterm" id="ch02_term35"/></p>

<section data-type="sect2" data-pdf-bookmark="Deployment"><div class="sect2" id="deployment">
<h2>Deployment</h2>

<p><a contenteditable="false" data-primary="modeling" data-secondary="deployment" data-type="indexterm" id="idm45969609945304"/><a contenteditable="false" data-primary="deployment" data-type="indexterm" id="idm45969609943928"/>In most practical application scenarios, the NLP module we’re implementing is a part of a larger system (e.g., a spam-classification system in a larger email application). Thus, working through the processing, modeling, and evaluation pipeline is only a part of the story. Eventually, once we’re happy with one final solution, it needs to be deployed in a production environment as a part of a larger system. Deployment entails plugging the NLP module into the broader system. It may also involve making sure input and output data pipelines are in order, as well as making sure our NLP module is scalable under heavy load.</p>

<p>An NLP module is typically deployed as a web service. Let’s say we designed a web service that takes a text as input and returns the email’s category (spam or non-spam) as output. Now, each time someone gets a new email, it goes to the microservice, which classifies the email text. This, in turn, can be used to make a decision about what to do with the email (either show it or send it to the spam folder). In certain circumstances, like batch processing, the NLP module is deployed in the larger task queue. As an example, take a look at task queues in Google Cloud<a contenteditable="false" data-primary="Google Cloud" data-secondary="task queues" data-type="indexterm" id="idm45969609940824"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969609939320-marker" href="ch02.xhtml#idm45969609939320">57</a>] or AWS<a contenteditable="false" data-primary="Amazon Web Services (AWS)" data-type="indexterm" id="idm45969609937880"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969609936664-marker" href="ch02.xhtml#idm45969609936664">58</a>]. We’ll cover deployment in more detail in <a data-type="xref" href="ch11.xhtml#the_end_to_end_nlp_process">Chapter 11</a>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Monitoring"><div class="sect2" id="monitoring-id00008">
<h2>Monitoring</h2>

<p><a contenteditable="false" data-primary="monitoring" data-type="indexterm" id="ch02_term36"/><a contenteditable="false" data-primary="modeling" data-secondary="monitoring" data-type="indexterm" id="ch02_term37"/>Like with any software engineering project, extensive software testing has to be done before final deployment, and the model performance is monitored constantly after deploying. Monitoring for NLP projects and models has to be handled differently than a regular engineering project, as we need to ensure that the outputs produced by our models daily make sense. If we’re automatically training the model frequently, we have to make sure that the models behave in a reasonable manner. Part of this is done through a performance dashboard showing the model parameters and key performance indicators. We’ll discuss this more in <a data-type="xref" href="ch11.xhtml#the_end_to_end_nlp_process">Chapter 11</a>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Model Updating"><div class="sect2" id="model_updating">
<h2>Model Updating</h2>

<p><a contenteditable="false" data-primary="updating" data-type="indexterm" id="idm45969609926120"/><a contenteditable="false" data-primary="modeling" data-secondary="updating" data-type="indexterm" id="idm45969609924824"/>Once the model is deployed and we start gathering new data, we’ll iterate the model based on this new data to stay current with predictions. We cover this model update for each task throughout the book, especially in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a> through <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch07.xhtml#topics_in_brief">7</a> and <a data-type="xref" href="ch11.xhtml#the_end_to_end_nlp_process">Chapter 11</a>. As a start, <a data-type="xref" href="#project_attribute_and_associated_decisi">Table 2-3</a> gives some guidance on how to approach the model updating process for different post-deployment scenarios.</p>

<table class="border" id="project_attribute_and_associated_decisi">
	<caption><span class="label">Table 2-3. </span>Project attribute and associated decision paths</caption>
	<thead>
		<tr>
			<th>Project attribute</th>
			<th>Decision paths</th>
			<th>Examples</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>More training data is generated post-deployment.</td>
			<td>Once deployed, extracted signals can be used to automatically improve the model. Can also try online learning to train the model automatically on a daily basis.</td>
			<td>Abuse-detection systems where users flag data.</td>
		</tr>
		<tr>
			<td>Training data is not generated post-deployment.</td>
			<td>Manual labeling could be done to improve evaluation and the models.<br/>
			Ideally, each new model has to be manually built and evaluated.</td>
			<td>A subset of a larger NLP pipeline with no direct feedback.</td>
		</tr>
		<tr>
			<td>Low model latency is required, or model has to be online with near-real-time response.</td>
			<td>Need to use models that can be inferred quickly. Another option is to create memoization strategies like caching or have substantially bigger computing power.</td>
			<td>Systems that need to respond right away, like any chatbot or an emergency tracking system.</td>
		</tr>
		<tr>
			<td>Low model latency is not required, or model can be run in an offline fashion.</td>
			<td>Can use more advanced and slower models. This can also help in optimizing costs where feasible.</td>
			<td>Systems that can be run on a batch process, like retail product catalog<a contenteditable="false" data-primary="post-modeling phases" data-startref="ch02_term35" data-type="indexterm" id="idm45969609907000"/> analysis.</td>
		</tr>
	</tbody>
</table>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Working with Other Languages"><div class="sect1" id="working_with_other_languages">
<h1>Working with Other Languages</h1>

<p><a contenteditable="false" data-primary="language" data-secondary="non-English languages" data-type="indexterm" id="ch02_term933"/><a contenteditable="false" data-primary="non-English language processing" data-type="indexterm" id="ch02_term934"/>So far, our discussion has assumed that we’re dealing mostly with English text. Depending on the task at hand, we may need to build models and solutions for other languages as well. How we approach this will change based on what language we’re dealing with. The pipeline for some languages may be very similar to English, whereas some languages and scenarios may require us to rethink how we approach the problem. We’ve compiled some action points for dealing with different languages in <a data-type="xref" href="#language_attribute_and_action_plan">Table 2-4</a>, based on our experiences working on projects that involve non-English language processing.</p>

<table class="border" id="language_attribute_and_action_plan">
	<caption><span class="label">Table 2-4. </span>Language attribute and action plan</caption>
	<thead>
		<tr>
			<th>Language attribute</th>
			<th>Example and languages</th>
			<th>Action</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>High-resource languages</td>
			<td>Languages that have both ample data as well as pre-built models.<br/>
			Examples include English<a contenteditable="false" data-primary="English" data-type="indexterm" id="idm45969609892856"/>, <a contenteditable="false" data-primary="French" data-type="indexterm" id="idm45969609891656"/>French, and <a contenteditable="false" data-primary="Spanish" data-type="indexterm" id="idm45969609890392"/>Spanish.</td>
			<td>Possible to use pre-trained DL models. Easier to use.</td>
		</tr>
		<tr>
			<td>Low-resource languages</td>
			<td>Languages that have limited data and recent digital adoption. May not have pre-built models.<br/>
			Examples include Swahili<a contenteditable="false" data-primary="Swahili" data-type="indexterm" id="idm45969609886856"/>, <a contenteditable="false" data-primary="Burmese" data-type="indexterm" id="idm45969609885656"/>Burmese, and Uzbek<a contenteditable="false" data-primary="Uzbek" data-type="indexterm" id="idm45969609884392"/>.</td>
			<td>Depending on the task, may need to label more data as well as explore individual components.</td>
		</tr>
		<tr>
			<td>Morphologically rich</td>
			<td>Linguistic and grammatical information like subject, object, predicate, tense, and mode are not separate words, but are joined together.<br/>
			Examples include <a contenteditable="false" data-primary="Latin" data-type="indexterm" id="idm45969609880584"/>Latin, <a contenteditable="false" data-primary="Turkish" data-type="indexterm" id="idm45969609879352"/>Turkish, <a contenteditable="false" data-primary="Finnish" data-type="indexterm" id="idm45969609878088"/>Finnish, and Malayalam<a contenteditable="false" data-primary="Malayalam" data-type="indexterm" id="idm45969609876824"/>.</td>
			<td>If the language is not resource rich, we’ll need to explore <a contenteditable="false" data-primary="morphological analysis" data-type="indexterm" id="idm45969609875240"/>morphological analyzers that exist for the language. In the worst case, manual rules to handle certain cases might be needed.</td>
		</tr>
		<tr>
			<td>Vocabulary<a contenteditable="false" data-primary="vocabulary variation" data-type="indexterm" id="idm45969609873000"/> variation heavy</td>
			<td>Nonstandard spellings<a contenteditable="false" data-primary="spelling, nonstandard" data-type="indexterm" id="idm45969609871288"/> and high word variation.<br/>
			For <a contenteditable="false" data-primary="Arabic" data-type="indexterm" id="idm45969609869688"/>Arabic and <a contenteditable="false" data-primary="Hindi" data-type="indexterm" id="idm45969609868456"/>Hindi, the spellings are nonstandard.</td>
			<td>If the language is not resource rich, then we may need to first normalize the words/spellings before training any model.<br/>
			This may not be needed for languages with large datasets, as they can still learn of vocabulary variation.</td>
		</tr>
		<tr>
			<td>CJK languages<a contenteditable="false" data-primary="CJK languages" data-type="indexterm" id="idm45969609865336"/></td>
			<td>These languages are derived from ancient Chinese characters. They’re not alphabet based and have several thousand characters for basic literacy and over 40,000 characters for larger coverage. Thus, they have to be handled differently.<br/>
			They include Chinese<a contenteditable="false" data-primary="Chinese" data-type="indexterm" id="idm45969609863192"/>, <a contenteditable="false" data-primary="Japanese" data-type="indexterm" id="idm45969609861992"/>Japanese, and <a contenteditable="false" data-primary="Korean" data-type="indexterm" id="idm45969609860728"/>Korean, hence the name CJK.</td>
			<td>Use specific tokenization schemes in these languages. Given that an ample amount of CJK data is available, it’s possible to build NLP models for various tasks from scratch.<br/>
			There are also pre-trained models for them.<br/>
			Transfer learning from models trained in other languages beyond CJK may not be useful in this case.</td>
		</tr>
	</tbody>
</table>


<p>Next, we’ll turn<a contenteditable="false" data-primary="non-English language processing" data-startref="ch02_term933" data-type="indexterm" id="idm45969609857448"/><a contenteditable="false" data-primary="language" data-secondary="non-English languages" data-startref="ch02_term934" data-type="indexterm" id="idm45969609856024"/> our attention to a case study that will put all these steps together.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Case Study"><div class="sect1" id="case_study">
<h1>Case Study</h1>

<p><a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="case studies" data-type="indexterm" id="ch02_term40"/>So far, we’ve seen different stages of an NLP pipeline. At each stage, we discussed what it’s about, why it’s useful, and how it fits into the general framework of an NLP pipeline. However, we tackled these individual stages separately, away from the overall context. How do all these stages work together in a real-world NLP system pipeline? Let’s see a case study, using <a contenteditable="false" data-primary="Uber" data-type="indexterm" id="ch02_term42"/>Uber’s tool to improve customer care: Customer Obsession Ticketing Assistant (COTA)<a contenteditable="false" data-primary="Customer Obsession Ticketing Assistant (COTA)" data-type="indexterm" id="ch02_term41"/><a contenteditable="false" data-primary="COTA (Customer Obsession Ticketing Assistant)" data-type="indexterm" id="ch02_term43"/>.</p>

<p>Uber operates in 400+ cities worldwide, and cbased on the number of people who use Uber every day, we can expect that their customer support teams receive several hundreds of thousands of tickets on different issues each day. There are a couple of solutions to choose from for a given ticket. The goal of COTA is to rank these solutions and pick the best possible one. Uber developed COTA using ML and NLP techniques to enable better customer support and quick and efficient resolution of such tickets. <a data-type="xref" href="#nlp_pipeline_for_ranking_tickets_in_a_t">Figure 2-15</a> shows the pipeline in Uber’s COTA and the various NLP components in it.</p>

<figure><div id="nlp_pipeline_for_ranking_tickets_in_a_t" class="figure"><img alt="NLP pipeline for ranking tickets in a ticketing system by Uber [_54]" src="Images/pnlp_0215.png" width="1428" height="648"/>
<h6><span class="label">Figure 2-15. </span>NLP pipeline for ranking tickets in a ticketing system by Uber [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_2_54-marker" href="ch02.xhtml#footnote_2_54">59</a>]</h6>
</div></figure>

<p>The information needed to identify the ticket issue and select a solution in this system comes from three sources, as shown in the figure. Ticket text is, as the name indicates, textual content, which is where NLP comes into the picture. After cleaning up the text by removing HTML tags (not shown in the figure), the pre-processing steps consist of tokenization, lowercasing, stop word removal, and lemmatization. We saw how to do all of these earlier in this chapter. After pre-processing, the ticket text is represented as a collection of words (known as a <em>bag of words</em> and discussed in detail in <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a>).</p>

<p>The next step in this pipeline is feature engineering. The bag of words we obtained earlier is fed to two NLP modules—TF-IDF (term frequency and inverse document frequency) and <a contenteditable="false" data-primary="LSI (Latent Semantic Indexing)" data-type="indexterm" id="idm45969609837224"/>LSI (latent semantic indexing)—which are used to understand the meaning of a text using this bag of words representation. This process comes under the NLP task called topic modeling, which we’ll discuss in <a data-type="xref" href="ch07.xhtml#topics_in_brief">Chapter 7</a>. Exactly how Uber uses these NLP tasks in this context is an interesting idea: Uber collects the historical tickets for each solution from their database, forms a bag-of-words vector representation for each solution, and creates a topic model based on these representations. An incoming ticket is then mapped to this topic space of solutions, creating a vector representation for the ticket. Cosine similarity is a common measure of similarity between any two vectors. It is used to create a vector where each element indicates the ticket text’s similarity to one solution. Thus, at the end of this feature engineering step, we end up with a representation indicating the ticket text’s similarity to all possible solutions.</p>

<p>In the next stage, modeling, this representation is combined with ticket information and trip data to build a ranking system that shows the three best solutions for the ticket. Under the hood, this ranking model consists of a binary classification system, which classifies each ticket-solution combination as a match or mismatch. The matches are then ranked based on a scoring function. [<a data-type="noteref" href="ch02.xhtml#footnote_2_54">59</a>] describes more details on the implementation of this system pipeline.</p>

<p>The next step in our pipeline is evaluation. How does evaluation work in this context? While the evaluation of model performance itself can be done in terms of an intrinsic evaluation measure such as MRR, the overall effectiveness of this approach is evaluated extrinsically. It’s estimated that COTA’s quick ticket resolution saves Uber tens of millions of dollars every year.</p>

<p>As we learned earlier, a model is not built just once. COTA, too, was continually experimented with and improved upon. After exploring a range of DL architectures, the best solution that was ultimately chosen resulted in a 10% greater accuracy compared to the previous version with the binary classification-based ranking system. The process does not end here, though. As we can see from the COTA team’s article [<a data-type="noteref" href="ch02.xhtml#footnote_2_54">59</a>], it’s a continuous process of model deployment, monitoring, and<a contenteditable="false" data-primary="Natural Language Processing (NLP)" data-secondary="case studies" data-startref="ch02_term40" data-type="indexterm" id="idm45969609829880"/><a contenteditable="false" data-primary="Customer Obsession Ticketing Assistant (COTA)" data-startref="ch02_term41" data-type="indexterm" id="idm45969609828248"/><a contenteditable="false" data-primary="Uber" data-startref="ch02_term42" data-type="indexterm" id="idm45969609826776"/><a contenteditable="false" data-primary="COTA (Customer Obsession Ticketing Assistant)" data-startref="ch02_term43" data-type="indexterm" id="idm45969609825400"/> updating.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Wrapping Up"><div class="sect1" id="wrapping_up-id00062">
<h1>Wrapping Up</h1>

<p>In this chapter, we saw the different steps involved in developing an NLP pipeline for a given project description and saw a detailed case study of a real-world application. We also saw how a traditional NLP pipeline and a DL-based NLP pipeline differ from each other and learned what to do when working with non-English languages. Aside from the case study, we looked at these steps in a more general manner in this chapter. Specific details for each step will depend on the task at hand and the purpose of our implementation. We’ll look at a few task-specific pipelines from <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a> onward, describing in detail what’s unique as well as common across different tasks while designing such <a contenteditable="false" data-primary="pipeline" data-startref="ch02_term1" data-type="indexterm" id="idm45969609820616"/>pipelines. In the next chapter, we’ll tackle the question of text representation that we mentioned briefly earlier in this chapter.</p>
</div></section>
<div data-type="footnotes"><h5>Footnotes</h5><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="ch02fn1"><sup><a href="ch02.xhtml#ch02fn1-marker">i</a></sup> This is different from the vertical stacking done in neural networks like LSTM.</p></div><div data-type="footnotes"><h5>References</h5><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612744872">[<a href="ch02.xhtml#idm45969612744872-marker">1</a>] Iderhoff, Nicolas. <a href="https://oreil.ly/NcwbT">nlp-datasets: Alphabetical list of free/public domain datasets with text data for use in Natural Language Processing (NLP)</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612743320">[<a href="ch02.xhtml#idm45969612743320-marker">2</a>] Google. <a href="https://oreil.ly/RYjaz">“Dataset Search”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612720744">[<a href="ch02.xhtml#idm45969612720744-marker">3</a>] Miller, George A. “WordNet: A Lexical Database for English.” <em>Communications of the ACM</em> 38.11 (1995): 39–41.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612719528">[<a href="ch02.xhtml#idm45969612719528-marker">4</a>] NTLTK documentation. <a href="https://oreil.ly/ALA5z">“WordNet Interface”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_2_11">[<a href="ch02.xhtml#footnote_2_11-marker">5</a>] Xie, Qizhe, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V. Le. <a href="https://oreil.ly/0KEoN">“Unsupervised Data Augmentation for Consistency Training”</a>. (2019).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_2_28">[<a href="ch02.xhtml#footnote_2_28-marker">6</a>] Wikipedia. <a href="https://oreil.ly/sYoEb">“Fat-finger error”</a>. Last modified January 26, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612689032">[<a href="ch02.xhtml#idm45969612689032-marker">7</a>] <a href="https://www.snorkel.org">Snorkel. “Programmatically Building and Managing Training Data”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612687752">[<a href="ch02.xhtml#idm45969612687752-marker">8</a>] Ratner, Alexander, Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen Wu, and Christopher Ré. “Snorkel: Rapid Training Data Creation with Weak Supervision.” <em>The VLDB Journal</em> 29 (2019): 1–22.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612685448">[<a href="ch02.xhtml#idm45969612685448-marker">9</a>] Bach, Stephen H., Daniel Rodriguez, Yintao Liu, Chong Luo, Haidong Shao, Cassandra Xia, Souvik Sen et al. <a href="https://oreil.ly/CnWxH">“Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale”</a>. (2018).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_2_21">[<a href="ch02.xhtml#footnote_2_21-marker">10</a>] Wei, Jason W., and Kai Zou. <a href="https://oreil.ly/T4WvN">“Eda: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks”</a>, (2019).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612679032">[<a href="ch02.xhtml#idm45969612679032-marker">11</a>] <a href="https://oreil.ly/37Bhj">GitHub repository</a> for [<a data-type="noteref" href="ch02.xhtml#footnote_2_21">10</a>]. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612675672">[<a href="ch02.xhtml#idm45969612675672-marker">12</a>] Ma, Edward. <a href="https://oreil.ly/LW78u">nplaug: Data augmentation for NLP</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612671848">[<a href="ch02.xhtml#idm45969612671848-marker">13</a>] Shioulin and Nisha. <a href="https://oreil.ly/U5ExU">“A Guide to Learning with Limited Labeled Data”</a>. April 2, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612658168">[<a href="ch02.xhtml#idm45969612658168-marker">14</a>] eForms. <a href="https://oreil.ly/sEgr9">“Blank Invoice Templates”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612656520">[<a href="ch02.xhtml#idm45969612656520-marker">15</a>] <a class="orm:hideurl" href="http://amazon.com">Amazon.com</a>. <a href="https://oreil.ly/8Zq3K">“Amazon Elements Vitamin B12 Methylcobalamin 5000 mcg - Normal Energy Production and Metabolism, Immune System Support - 2 Month Supply (65 Berry Flavored Lozenges)”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612647192">[<a href="ch02.xhtml#idm45969612647192-marker">16</a>] <a href="https://oreil.ly/W0eDZ">Beautiful Soup</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612644680">[<a href="ch02.xhtml#idm45969612644680-marker">17</a>] Scrapy.org. <a href="https://scrapy.org">Scrapy</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612028216">[<a href="ch02.xhtml#idm45969612028216-marker">18</a>] <a href="https://home.unicode.org">Unicode</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969612022408">[<a href="ch02.xhtml#idm45969612022408-marker">19</a>] Dickinson, Markus, Chris Brew, and Detmar Meurers. <em>Language and Computers</em>. New Jersey: John Wiley &amp; Sons, 2012. ISBN: 978-1-405-18305-5</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_2_51">[<a href="ch02.xhtml#footnote_2_51-marker">20</a>] Explosion.ai. <a href="https://oreil.ly/CgeBw">"Rule-based matching"</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_2_45">[<a href="ch02.xhtml#footnote_2_45-marker">21</a>] Microsoft documentation. <a href="https://oreil.ly/Rwq0w">“Quickstart: Check spelling with the Bing Spell Check REST API and Python”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611273592">[<a href="ch02.xhtml#idm45969611273592-marker">22</a>] Stamy, Matthew. <a href="https://oreil.ly/6OXi3">PyPDF2: A utility to read and write PDFs with Python</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611283048">[<a href="ch02.xhtml#idm45969611283048-marker">23</a>] pdfminer. <a href="https://oreil.ly/FVlxl">pdfminer.six: Community maintained fork of pdfminer</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611788568">[<a href="ch02.xhtml#idm45969611788568-marker">24</a>] FilingDB. <a href="https://oreil.ly/Fa1gB">“What’s so hard about PDF text extraction?”</a> Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611820472">[<a href="ch02.xhtml#idm45969611820472-marker">25</a>] Tesseract-OCR. <a href="https://oreil.ly/WLIWy">“Tesseract Open Source OCR Engine (main repository)”</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611819032">[<a href="ch02.xhtml#idm45969611819032-marker">26</a>] Python-tesseract documentation<a href="https://oreil.ly/UqaEz">Python-tesseract</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611831992">[<a href="ch02.xhtml#idm45969611831992-marker">27</a>] Firth, John Rupert. “Personality and Language in Society.” <em>The Sociological Review</em> 42.1 (1950): 37–52.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611836424">[<a href="ch02.xhtml#idm45969611836424-marker">28</a>] pyenchant. <a href="https://oreil.ly/Ntq5J">Spellchecking library for python</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611834696">[<a href="ch02.xhtml#idm45969611834696-marker">29</a>] KBNL Research. <a href="https://oreil.ly/BEWT1">ochre: Toolbox for OCR post-correction</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611131192">[<a href="ch02.xhtml#idm45969611131192-marker">30</a>] <a href="http://www.nltk.org">“Natural Language ToolKit”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_2_46">[<a href="ch02.xhtml#footnote_2_46-marker">31</a>] Explosion.ai. <a href="https://oreil.ly/W97S3">“spaCy 101: Everything you need to know”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610547080">[<a href="ch02.xhtml#idm45969610547080-marker">32</a>] Evang, Kilian, Valerio Basile, Grzegorz Chrupała, and Johan Bos. “Elephant: Sequence Labeling for Word and Sentence Segmentation.” <em>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</em> (2013): 1422–1426.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611111928">[<a href="ch02.xhtml#idm45969611111928-marker">33</a>] Porter, Martin F. “An Algorithm For Suffix Stripping.” <em>Program: electronic library and information systems</em> 14.3 (1980): 130–137.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611891688">[<a href="ch02.xhtml#idm45969611891688-marker">34</a>] Padmanabhan, Arvind. <a href="https://oreil.ly/erczD">“Lemmatization”</a>. October 11, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610798600">[<a href="ch02.xhtml#idm45969610798600-marker">35</a>] Explosion.ai. <a href="https://oreil.ly/kw5_4">“spaCy”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611937720">[<a href="ch02.xhtml#idm45969611937720-marker">36</a>] Polyglot documentation.<a href="https://oreil.ly/vt4XB">Polyglot Python library</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611016168">[<a href="ch02.xhtml#idm45969611016168-marker">37</a>] Mair, Victor. <a href="https://oreil.ly/tbnK3">“Singlish: alive and well”</a>. May 14, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611980632">[<a href="ch02.xhtml#idm45969611980632-marker">38</a>] Jurafsky, Dan and James H. Martin. <a href="https://oreil.ly/Ta16f"><em>Speech and Language Processing</em>, Third Edition (Draft)</a>, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611930808">[<a href="ch02.xhtml#idm45969611930808-marker">39</a>] Explosion.ai. <a href="https://spacy.io/">“spaCy: Industrial-Strength Natural Language Processing in Python”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611928088">[<a href="ch02.xhtml#idm45969611928088-marker">40</a>] DeepAI. <a href="https://oreil.ly/BaRyS">“Parsey Mcparseface API”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969611004008">[<a href="ch02.xhtml#idm45969611004008-marker">41</a>] Stanford CoreNLP.<a href="https://oreil.ly/137-o">Stanford CoreNLP – Natural language software</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610686184">[<a href="ch02.xhtml#idm45969610686184-marker">42</a>] Ghaffari, Parsa. <a href="https://oreil.ly/Fmy_2">“Leveraging Deep Learning for Multilingual Sentiment Analysis”</a>. July 14, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610924696">[<a href="ch02.xhtml#idm45969610924696-marker">43</a>] The Stanford Natural Language Processing Group. <a href="https://oreil.ly/AUGVP">“Stanford TokensRegex”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610214168">[<a href="ch02.xhtml#idm45969610214168-marker">44</a>] Google. <a href="https://oreil.ly/Tti8y">“Cloud Natural Language”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610211480">[<a href="ch02.xhtml#idm45969610211480-marker">45</a>] Amazon. <a href="https://oreil.ly/DO9jA">“AWS Comprehend”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610208440">[<a href="ch02.xhtml#idm45969610208440-marker">46</a>] Microsoft. <a href="https://oreil.ly/0dokf">“Azure Cognitive Services documentation”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610980840">[<a href="ch02.xhtml#idm45969610980840-marker">47</a>] IBM. <a href="https://oreil.ly/_KUkX">“Watson Natural Language Understanding”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_2_30">[<a href="ch02.xhtml#footnote_2_30-marker">48</a>] Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. <em>The Elements of Statistical Learning</em>, Second Edition. New York: Springer, 2001. ISBN: 978-0-387-84857-0</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610048072">[<a href="ch02.xhtml#idm45969610048072-marker">49</a>] Wikipedia. <a href="https://oreil.ly/-d6IZ">“F1 score”</a>. Last modified April 18, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610038792">[<a href="ch02.xhtml#idm45969610038792-marker">50</a>] Wikipedia. <a href="https://oreil.ly/9eK2K">“Mean reciprocal rank”</a>. Last modified December 6, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610034184">[<a href="ch02.xhtml#idm45969610034184-marker">51</a>] Wikipedia. <a href="https://oreil.ly/a2Jmq">“Evaluation measures (information retrieval)”</a>. Last modified February 12, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610025320">[<a href="ch02.xhtml#idm45969610025320-marker">52</a>] Wikipedia. <a href="https://oreil.ly/TXzj5">“Mean absolute percentage error”</a>. Last modified February 6, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610020296">[<a href="ch02.xhtml#idm45969610020296-marker">53</a>] Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu. “BLEU: A Method for Automatic Evaluation of Machine Translation.” <em>Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</em> (2002): 311–318.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969610015752">[<a href="ch02.xhtml#idm45969610015752-marker">54</a>] Banerjee, Satanjeev and Alon Lavie. “METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments.” <em>Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</em> (2005): 65–72.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969609997688">[<a href="ch02.xhtml#idm45969609997688-marker">55</a>] Lin, Chin-Yew. “ROUGE: A Package for Automatic Evaluation of Summaries.” <em>Text Summarization Branches Out</em> (2004): 74–81.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_2_19">[<a href="ch02.xhtml#footnote_2_19-marker">56</a>] Wikipedia. <a href="https://oreil.ly/NDKkiy">“Perplexity”</a>. Last modified February 13, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969609939320">[<a href="ch02.xhtml#idm45969609939320-marker">57</a>] Google Cloud. <a href="https://oreil.ly/O7CD0">“Quickstart for Cloud Tasks queues”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969609936664">[<a href="ch02.xhtml#idm45969609936664-marker">58</a>] Amazon. <a href="https://oreil.ly/zXHZz">“Amazon Simple Queue Service”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_2_54">[<a href="ch02.xhtml#footnote_2_54-marker">59</a>] Zheng, Huaixiu., Yi-Chia Wang, and Piero Molino. <a href="https://oreil.ly/dxhWB">“COTA: Improving Uber Customer Care with NLP &amp; Machine Learning”</a>. January 3, 2018.</p></div></div></section></div>



  </body>
</html>