<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<link href="Styles/Style00.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style01.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style02.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style03.css" rel="stylesheet" type="text/css" />
<style type="text/css" title="ibis-book">
    @charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0 !important}#sbo-rt-content div.preface p.byline+p.byline{margin:0 !important}#sbo-rt-content div.sect1&gt;p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1&gt;p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]&gt;div&gt;h1,#sbo-rt-content section[data-type="preface"]&gt;div&gt;h1,#sbo-rt-content section[data-type="appendix"]&gt;div&gt;h1,#sbo-rt-content section[data-type="glossary"]&gt;div&gt;h1,#sbo-rt-content section[data-type="bibliography"]&gt;div&gt;h1,#sbo-rt-content section[data-type="index"]&gt;div&gt;h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content div.figure h6,#sbo-rt-content figure h6,#sbo-rt-content figure figcaption{font-size:.9rem !important;text-align:center;font-weight:normal !important;font-style:italic;font-family:serif !important;text-transform:none !important;letter-spacing:normal !important;color:#000;padding-top:.25em !important;margin-top:0 !important;page-break-before:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]&gt;div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:2em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content p[data-type="footnote"]{font-size:90% !important;line-height:1.2em !important;margin-left:2.5em !important;text-indent:-2.3em !important}#sbo-rt-content p[data-type="footnote"] sup{display:inline-block !important;position:static !important;width:2em !important;text-align:right !important;font-size:100% !important;padding-right:.5em !important}#sbo-rt-content p[data-type="footnote"] a[href$="-marker"]{font-family:sans-serif !important;font-size:90% !important;color:#8e0012 !important}#sbo-rt-content p[data-type="footnote"] a[data-type="xref"]{margin:0 !important;padding:0 !important;text-indent:0 !important}#sbo-rt-content a[data-type="noteref"]{font-family:sans-serif !important;color:#8e0012;margin-left:0;padding-left:0}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dl{margin-bottom:1.5em !important}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important;line-height:1.25rem;font-style:italic}#sbo-rt-content dd{margin:10px 0 .25em 1.5em !important;line-height:1.65em !important}#sbo-rt-content dd p{padding:0 !important;margin:0 0 10px !important}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul&gt;li,#sbo-rt-content ol ul,#sbo-rt-content ol ul&gt;li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul&gt;li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul&gt;li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul&gt;li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol&gt;li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol&gt;li,#sbo-rt-content ul ol,#sbo-rt-content ul ol&gt;li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol&gt;li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol&gt;li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol&gt;li&gt;ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol&gt;li&gt;ol&gt;li&gt;ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div[data-type="tip"] figure h6,#sbo-rt-content div[data-type="note"] figure h6,#sbo-rt-content div[data-type="warning"] figure h6,#sbo-rt-content div[data-type="caution"] figure h6,#sbo-rt-content div[data-type="important"] figure h6{font-family:serif !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content table li{margin:10px 0 0 .25em !important}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:top;font-size:80%}#sbo-rt-content th{vertical-align:bottom}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller;word-break:break-all}#sbo-rt-content table.border tbody&gt;tr:last-child&gt;td{border-bottom:transparent}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content div[data-type="equation"] math{font-size:calc(.35em + 1vw)}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index h3{padding:.25em;margin-top:1em !important;background-color:#F0F0F0}#sbo-rt-content div.index li{line-height:130%;list-style-type:none}#sbo-rt-content div.index a.indexterm{color:#8e0012 !important}#sbo-rt-content div.index ul{margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.index ul ul{margin-left:2em !important;margin-top:0 !important}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content pre.break-code,#sbo-rt-content code.break-code,#sbo-rt-content .break-code pre,#sbo-rt-content .break-code code{word-break:break-all}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content .width-10,#sbo-rt-content figure.width-10 img{width:10% !important}#sbo-rt-content .width-20,#sbo-rt-content figure.width-20 img{width:20% !important}#sbo-rt-content .width-30,#sbo-rt-content figure.width-30 img{width:30% !important}#sbo-rt-content .width-40,#sbo-rt-content figure.width-40 img{width:40% !important}#sbo-rt-content .width-50,#sbo-rt-content figure.width-50 img{width:50% !important}#sbo-rt-content .width-60,#sbo-rt-content figure.width-60 img{width:60% !important}#sbo-rt-content .width-70,#sbo-rt-content figure.width-70 img{width:70% !important}#sbo-rt-content .width-80,#sbo-rt-content figure.width-80 img{width:80% !important}#sbo-rt-content .width-90,#sbo-rt-content figure.width-90 img{width:90% !important}#sbo-rt-content .width-full,#sbo-rt-content .width-100{width:100% !important}#sbo-rt-content .sc{text-transform:none !important}#sbo-rt-content .right{float:none !important}#sbo-rt-content a.totri-footnote{padding:0 !important}#sbo-rt-content figure.width-10,#sbo-rt-content figure.width-20,#sbo-rt-content figure.width-30,#sbo-rt-content figure.width-40,#sbo-rt-content figure.width-50,#sbo-rt-content figure.width-60,#sbo-rt-content figure.width-70,#sbo-rt-content figure.width-80,#sbo-rt-content figure.width-90{width:auto !important}#sbo-rt-content p img,#sbo-rt-content pre img{width:1.25em;line-height:1em;margin:0 .15em -.2em}#sbo-rt-content figure.no-frame div.border-box{border:none}#sbo-rt-content .right{text-align:right !important}
    </style>
<style type="text/css" id="font-styles">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }</style>
<style type="text/css" id="font-family">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }</style>
<style type="text/css" id="column-width">#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }</style>

<style type="text/css">body{margin:1em;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}body{background-color:transparent!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style></head>
<body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 11. The End-to-End NLP Process"><div class="chapter" id="the_end_to_end_nlp_process">
<h1><span class="label">Chapter 11. </span>The End-to-End NLP Process</h1>
<blockquote class="right">
<p class="right"><em>The process is more important than the goal. The person you become</em><br/> <em>is infinitely more valuable than whatever the result is.</em></p>
<p data-type="attribution" style="text-align:right"><em>Anthony Moore</em></p>
</blockquote>

<p>So far<a contenteditable="false" data-type="indexterm" data-primary="Natural Language Processing (NLP)" data-secondary="end-to-end process" id="ch11_term1"/> in the book, we’ve addressed a range of NLP<a contenteditable="false" data-type="indexterm" data-primary="Moore, Anthony" id="idm45969586976808"/> problems, starting from what an NLP pipeline looks like to how NLP is applied in different domains. Efficiently applying what we’ve learned to build end-to-end software products involving NLP takes more than just stitching together various steps in an NLP pipeline—there are several decision points during the process. While a lot of this knowledge comes only with experience, we’ve distilled some of our knowledge about the end-to-end NLP process in this chapter to help you hit the ground running faster and better.</p>

<p>In <a data-type="xref" href="ch02.xhtml#nlp_pipeline">Chapter 2</a>, we already saw what a typical pipeline for an NLP system looks like. How is this chapter then any different from that? In <a data-type="xref" href="ch02.xhtml#nlp_pipeline">Chapter 2</a>, we focused primarily on the technical aspects of the pipeline—for example, how do we represent text? What pre-processing steps should we do? How do we build a model, and then how do we evaluate it? In the subsequent chapters in Parts <a data-type="xref" data-xrefstyle="select:labelnumber" href="part01.xhtml#foundations">I</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="part02.xhtml#essentials">II</a> of the book, we delved deeper into different algorithms to perform various NLP tasks. We also saw how NLP is used in various industry domains, such as healthcare, e-commerce, and social media. However, in all these chapters, we spent little time on the issues related to deploying and maintaining such systems and on the processes to follow when managing such projects. These are the focus of this chapter. Most of the points discussed here are broadly applicable not just to NLP, but also to other concepts, such as data science (DS)<a contenteditable="false" data-type="indexterm" data-primary="data science (DS)" id="idm45969586969000"/><a contenteditable="false" data-type="indexterm" data-primary="DS (data science)" id="idm45969586967896"/>, machine learning<a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" id="idm45969586966664"/>, artificial intelligence (AI)<a contenteditable="false" data-type="indexterm" data-primary="artificial intelligence (AI)" id="idm45969586965400"/><a contenteditable="false" data-type="indexterm" data-primary="AI" data-see="artificial intelligence" id="idm45969586964280"/>, etc. Throughout this chapter, we use these terms interchangeably; where the focus is specifically on NLP tasks, we mention that explicitly.</p>

<p class="pagebreak-before">We’ll start the discussion by revisiting the NLP pipeline we introduced in <a data-type="xref" href="ch02.xhtml#nlp_pipeline">Chapter 2</a> and take a look at the last two steps: deployment, followed by monitoring and updating the model, which we didn’t cover in earlier chapters. We’ll also see what it takes to build and maintain a mature NLP system. This is followed by a discussion on the data science processes followed in various AI teams, especially with respect to building NLP software in particular. We’ll conclude the chapter with a lot of recommendations, best practices, and do’s and don’ts to successfully deliver NLP projects. Let’s start by looking at how to deploy NLP software.</p>

<section data-type="sect1" data-pdf-bookmark="Revisiting the NLP Pipeline: Deploying NLP Software"><div class="sect1" id="revisiting_the_nlp_pipeline_deploying_n">
<h1>Revisiting the NLP Pipeline: Deploying NLP Software</h1>

<p><a contenteditable="false" data-type="indexterm" data-primary="Natural Language Processing (NLP)" data-secondary="deployment" id="ch11_term2"/><a contenteditable="false" data-type="indexterm" data-primary="software deployment" id="ch11_term3"/><a contenteditable="false" data-type="indexterm" data-primary="deployment" id="ch11_term4"/>In <a data-type="xref" href="ch02.xhtml#nlp_pipeline">Chapter 2</a>, we saw that a typical production pipeline for NLP projects consists of the following stages: data acquisition, text cleaning, text pre-processing, text representation and feature engineering, modeling, evaluation, deployment, monitoring, and model updating. When we encounter a new problem scenario involving NLP in our organization, we have to first start thinking about creating an NLP pipeline covering these stages. Some of the questions we should ask ourselves in this process are:</p>
<ul>
<li>
	<p>What kind of data do we need for training the NLP system? Where do we get this data from? These questions are important at the start and also later as the model matures.</p></li>
<li>
	<p>How much data is available? If it’s not enough, what data augmentation techniques can we try?</p></li>
<li>
	<p>How will we label the data, if necessary?</p></li>
<li>
	<p>How will we quantify the performance of our model? What metrics will we use to do that?</p></li>
<li>
	<p>How will we deploy the system? Using API calls over the cloud, or a monolith system, or an embedded module on an edge device?</p></li>
<li>
	<p>How will the predictions be served: streaming or batch process?</p></li>
<li>
	<p>Would we need to update the model? If yes, what will the update frequency be: daily, weekly, monthly?</p></li>
<li>
	<p>Do we need a monitoring and alerting mechanism for model performance? If yes, what kind of mechanism do we need and how will we put it in place?</p></li>
</ul>

<p class="pagebreak-before">Once we’ve thought through these key decision points<a contenteditable="false" data-type="indexterm" data-primary="Natural Language Processing (NLP)" data-secondary="key decision points" id="idm45969586944808"/>, a broad design of our pipeline is ready! We can then start to focus on building version 1 of the model with strong baselines, implementing the pipeline, deploying the model, and from there, iteratively improving our solution. In <a data-type="xref" href="ch02.xhtml#nlp_pipeline">Chapter 2</a>, we saw how different stages of the NLP pipeline before deployment are implemented for various NLP tasks. Let’s now take a look at the final stages of the pipeline: deployment, monitoring, and model updating.</p>

<p>What does deployment mean? Any NLP model we build is typically a part of some larger software system. Once our model is working well in isolation, we plug it into a larger system and ensure that everything is working well. The set of all of the tasks related to integrating the model with the rest of the software and making it production-ready is called <em>deployment</em>. Typical steps in deployment of a model include<a contenteditable="false" data-type="indexterm" data-primary="deployment" data-secondary="typical steps" id="idm45969586940600"/>:</p>
<ol>
<li>
	<p><em>Model packaging<a contenteditable="false" data-type="indexterm" data-primary="packaging" id="idm45969586937624"/><a contenteditable="false" data-type="indexterm" data-primary="model packaging" id="idm45969586936488"/>:</em> If the model is large, it might need to be saved in persistent cloud storage<a contenteditable="false" data-type="indexterm" data-primary="cloud storage" id="idm45969586935128"/><a contenteditable="false" data-type="indexterm" data-primary="storage" id="idm45969586934024"/>, such as AWS S3<a contenteditable="false" data-type="indexterm" data-primary="Amazon Web Services (AWS)" data-secondary="AWS S3" id="idm45969586932792"/>, Azure Blob Storage<a contenteditable="false" data-type="indexterm" data-primary="Microsoft Azure" data-secondary="Blob Storage" id="idm45969586931288"/>, or Google Cloud Storage<a contenteditable="false" data-type="indexterm" data-primary=" Google Cloud Storage" id="idm45969586929752"/>, for easy access. It might also be serialized and wrapped up in a library call for easy access. There are also open formats<a contenteditable="false" data-type="indexterm" data-primary="open formats" id="idm45969586928376"/> like ONNX<a contenteditable="false" data-type="indexterm" data-primary="ONNX" id="idm45969586927144"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586925880-marker" href="ch11.xhtml#idm45969586925880">1</a>] that provide interoperability across different frameworks.</p></li>
<li>
	<p><em>Model serving<a contenteditable="false" data-type="indexterm" data-primary="model serving" id="idm45969586923400"/>:</em> The model can be made available as a web service for other services to consume. In cases where a more tightly coupled system and batch process is more applicable, the model could be part of a task flow system like Airflow<a contenteditable="false" data-type="indexterm" data-primary="Airflow (Apache)" id="idm45969586921768"/><a contenteditable="false" data-type="indexterm" data-primary="Apache Airflow" id="idm45969586920664"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586919432-marker" href="ch11.xhtml#idm45969586919432">2</a>], Oozie<a contenteditable="false" data-type="indexterm" data-primary="Oozie (Apache)" id="idm45969586918152"/><a contenteditable="false" data-type="indexterm" data-primary="Apache Oozie" id="idm45969586917048"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586864696-marker" href="ch11.xhtml#idm45969586864696">3</a>], or Chef<a contenteditable="false" data-type="indexterm" data-primary="Chef" id="idm45969586863400"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586862136-marker" href="ch11.xhtml#idm45969586862136">4</a>], instead of a web service<a contenteditable="false" data-type="indexterm" data-primary="web services" id="idm45969586860808"/>. Microsoft<a contenteditable="false" data-type="indexterm" data-primary="Microsoft" data-secondary="reference pipelines for MLOps" id="idm45969586859608"/> has also released reference pipelines for MLOps<a contenteditable="false" data-type="indexterm" data-primary="MLOps" id="idm45969586857944"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_11_44-marker" href="ch11.xhtml#footnote_11_44">5</a>] and MLOps in Python [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586855000-marker" href="ch11.xhtml#idm45969586855000">6</a>].</p></li>
<li>
	<p><em>Model scaling<a contenteditable="false" data-type="indexterm" data-primary="scaling" id="idm45969586852856"/><a contenteditable="false" data-type="indexterm" data-primary="model scaling" id="idm45969586851720"/>:</em> Models that are hosted as web services should be able to scale with respect to request traffic. Models that are running as part of a batch service should also be able to scale with respect to the input batch size. Public cloud platforms as well as on-premise cloud systems have technologies that enable that. <a data-type="xref" href="#aws_cloud_and_sagemaker_to_serve_text_c">Figure 11-1</a> shows one such pipeline for text classification on AWS. More details on the engineering of this pipeline can be found in the AWS post [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_11_70-marker" href="ch11.xhtml#footnote_11_70">7</a>].</p></li>
</ol>
<figure><div id="aws_cloud_and_sagemaker_to_serve_text_c" class="figure">
<img src="Images/pnlp_1101.png" alt="AWS Cloud and SageMaker to serve text classification [_70]" width="1409" height="1344"/>
<h6><span class="label">Figure 11-1. </span><a contenteditable="false" data-type="indexterm" data-primary="Amazon Web Services (AWS)" data-secondary="SageMaker" id="idm45969586845224"/><a contenteditable="false" data-type="indexterm" data-primary="SageMaker (AWS)" id="idm45969586843832"/>AWS Cloud and SageMaker to serve text classification<a contenteditable="false" data-type="indexterm" data-primary="text classification" data-secondary="AWS pipeline" id="idm45969586842536"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Web Services (AWS)" data-secondary="AWS Cloud" id="idm45969586841160"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586839640-marker" href="ch11.xhtml#idm45969586839640">8</a>]</h6>
</div></figure>

<p>Let’s look at an example to understand the deployment of an NLP model into a larger<a contenteditable="false" data-type="indexterm" data-primary="software deployment" data-startref="ch11_term3" id="idm45969586837144"/><a contenteditable="false" data-type="indexterm" data-primary="Natural Language Processing (NLP)" data-secondary="deployment" data-startref="ch11_term2" id="idm45969586835768"/><a contenteditable="false" data-type="indexterm" data-primary="deployment" data-startref="ch11_term4" id="idm45969586834056"/> system.</p>

<section data-type="sect2" data-pdf-bookmark="An Example Scenario"><div class="sect2" id="an_example_scenario">
<h2>An Example Scenario</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="deployment" data-secondary="example scenario" id="ch11_term6"/><a contenteditable="false" data-type="indexterm" data-primary="text classification" data-secondary="example scenario" id="ch11_term5"/>Let’s say we work for a social media platform and are asked to build a classifier to identify abusive user comments. The goal of this classifier is to prevent abusive content from appearing on the platform by flagging any content that’s potentially abusive and sending it for human moderation. We worked hard on collecting the data relevant to this task, designing a set of features, and testing a range of algorithms, and we built a predictive model that takes a new comment as input and classifies it as abusive or safe. What next?</p>

<p>Our model is just a small part of the larger social media platform. There are several components: content is being rendered dynamically, and there are various modules to interact with users, components responsible for storage and retrieval of data, and so on. It’s possible that different subsystems of the platform are written in different programming languages. Our classifier is just a small component of the product, and we need to integrate it into the larger setup. How do we go about doing this? A common way to address this scenario is to create a web service where the model sits behind the web service. The rest of the product interacts with the model via this web service. It queries the service with the new comment(s) and gets back the prediction(s). The call to this web service<a contenteditable="false" data-type="indexterm" data-primary="web services" id="idm45969586825304"/> is integrated into the product wherever necessary. Popular web application frameworks such as Flask<a contenteditable="false" data-type="indexterm" data-primary="Flask" id="idm45969586823960"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586822728-marker" href="ch11.xhtml#idm45969586822728">9</a>], Falcon<a contenteditable="false" data-type="indexterm" data-primary="Falcon Web Framework" id="idm45969586821288"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586820056-marker" href="ch11.xhtml#idm45969586820056">10</a>], and Django<a contenteditable="false" data-type="indexterm" data-primary="Django Project" id="idm45969586818728"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586817528-marker" href="ch11.xhtml#idm45969586817528">11</a>] are typically used to create such web services.</p>

<p>Developing various NLP solutions involves relying on a range of pre-existing libraries. Setting up a web service and hosting what we built in the cloud or some server requires us to ensure that there are no compatibility issues. To address this, there is a range of options available. The most common option is to package various libraries into a container like Docker<a contenteditable="false" data-type="indexterm" data-primary="Docker" id="idm45969586815320"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586814088-marker" href="ch11.xhtml#idm45969586814088">12</a>] or Kubernetes<a contenteditable="false" data-type="indexterm" data-primary="Kubernetes" id="idm45969586812808"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586811576-marker" href="ch11.xhtml#idm45969586811576">13</a>]. Operationalizing a web service for production requires addressing many other issues, such as tech stack, load balancing, latency, throughput, availability, and reliability. Building and making a model production ready includes a whole lot of engineering tasks, which can often be time consuming. Cloud services such as AWS SageMaker<a contenteditable="false" data-type="indexterm" data-primary="SageMaker (AWS)" id="idm45969586809944"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Web Services (AWS)" data-secondary="SageMaker" id="idm45969586808872"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586807352-marker" href="ch11.xhtml#idm45969586807352">14</a>] and Azure Cognitive Services<a contenteditable="false" data-type="indexterm" data-primary="Microsoft Azure" data-secondary="Cognitive Services" id="idm45969586805864"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586804392-marker" href="ch11.xhtml#idm45969586804392">15</a>] try to make these engineering tasks easy. Sometimes, the whole process, to the last detail, is automated to such an extent that it’s as simple as one-click-get-done to set up the service. The idea is to let the AI teams focus on the most important part: model building.</p>

<p>Another important issue to address is model size<a contenteditable="false" data-type="indexterm" data-primary="model size" id="idm45969586802024"/>. Modern NLP models can be quite large. For example, Google’s Word2vec model<a contenteditable="false" data-type="indexterm" data-primary="Word2vec model (Google)" data-secondary="size" id="idm45969586800888"/><a contenteditable="false" data-type="indexterm" data-primary="Google" data-secondary="Word2vec model" id="idm45969586799512"/> is 4.8 GB in size and takes over 100 seconds just to load into memory (refer back to <em>Ch3/Pre_Trained_Word_Embeddings.ipynb</em>). Likewise, a fastText classification model<a contenteditable="false" data-type="indexterm" data-primary="fastText classification models" id="idm45969586797384"/> is typically over 2 GB in size. DL models like BERT<a contenteditable="false" data-type="indexterm" data-primary="BERT (Bidirectional Encoder Representations from Transformers)" data-secondary="size" id="idm45969586796056"/> are known to be even bulkier. Hosting such large models in the cloud can be both challenging and expensive. There’s a lot of work happening in the area of model compression<a contenteditable="false" data-type="indexterm" data-primary="model compression" id="ch11_term7"/> to address such scenarios. Some of them are listed below:</p>
<ul>
<li>
	<p>“Compressing BERT for Faster Prediction,” a blog post by a team at Rasa NLP<a contenteditable="false" data-type="indexterm" data-primary="Rasa NLP" id="idm45969586791608"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586790184-marker" href="ch11.xhtml#idm45969586790184">16</a>]</p></li>
<li>
	<p>“A Survey of Model Compression and Acceleration for Deep Neural Networks,” a report by a team at Microsoft Research<a contenteditable="false" data-type="indexterm" data-primary="Microsoft Research" id="idm45969586787304"/> and Tsinghua University<a contenteditable="false" data-type="indexterm" data-primary="Tsinghua University" id="idm45969586786072"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586784840-marker" href="ch11.xhtml#idm45969586784840">17</a>]</p></li>
<li>
	<p>“FastText.zip: Compressing text classification models,” a report by a team at Facebook AI Research<a contenteditable="false" data-type="indexterm" data-primary="Facebook AI Research" id="idm45969586781992"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586780760-marker" href="ch11.xhtml#idm45969586780760">18</a>]</p></li>
<li>
	<p>“Awesome ML Model Compression,” a GitHub repository by Cedric Chee<a contenteditable="false" data-type="indexterm" data-primary="Chee, Cedric" id="idm45969586778360"/> that includes relevant papers, videos, libraries, and tools [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586777048-marker" href="ch11.xhtml#idm45969586777048">19</a>]</p></li>
</ul>

<p>This is just a brief overview of various steps that go into deploying our NLP model. There are books and other materials that cover this in complete detail. As a start, interested readers can look at the later chapters of the book <em>Machine Learning Engineering</em> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586772872-marker" href="ch11.xhtml#idm45969586772872">20</a>].</p>

<p>For most industry use cases, model building<a contenteditable="false" data-type="indexterm" data-primary="modeling" id="idm45969586770648"/> is seldom a one-time activity. As the deployed system gets used more, the models built need to adapt to new scenarios and new data points. Hence, the models should be updated regularly. Let’s discuss the issues to consider while building and maintaining mature NLP<a contenteditable="false" data-type="indexterm" data-primary="text classification" data-secondary="example scenario" data-startref="ch11_term5" id="idm45969586769128"/><a contenteditable="false" data-type="indexterm" data-primary="deployment" data-secondary="example scenario" data-startref="ch11_term6" id="idm45969586767480"/> software.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Building and Maintaining a Mature System"><div class="sect1" id="building_and_maintaining_a_mature_syste">
<h1>Building and Maintaining a Mature System</h1>

<p><a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="updating" id="idm45969586763896"/><a contenteditable="false" data-type="indexterm" data-primary="updating" id="idm45969586762520"/>In most real-world settings, the underlying patterns in data change over a period of time. This means that the models that were trained long before can become stale—i.e., the data used to train the model is very different from the data in the production environment that’s being fed to the model for predictions. This is called <em>covariate shift</em><a contenteditable="false" data-type="indexterm" data-primary="covariate shift" id="idm45969586760648"/>, and it results in a performance drop of the model. Model update is a common approach to deal with such scenarios. On a similar note, in most industrial settings, once the first version of a model is consumed, improving the model becomes inevitable. Updating and improving an existing NLP model could just mean retraining with newer or additional training data, or it sometimes involves adding new features. When updating such models, the goal is to ensure that the deployed system performs at least as well as the existing system. Most model updates and improvements lead to more complex models. As the models grow in complexity, we need to ensure that the system doesn’t crumble under increasing complexity. We need to manage the complexity of a mature NLP model while making sure it’s also maintainable. Some of the issues we need to consider in this process are:</p>
<ul>
<li>
	<p>Finding better features</p></li>
<li>
	<p>Iterating existing models</p></li>
<li>
	<p>Code and model reproducibility</p></li>
<li>
	<p>Troubleshooting and testing</p></li>
<li>
	<p>Minimizing technical debt</p></li>
<li>
	<p>Automating the ML process</p></li>
</ul>

<p>In this section, let’s take a look at these issues one by one, starting with a discussion about how to find better features.</p>

<section data-type="sect2" data-pdf-bookmark="Finding Better Features"><div class="sect2" id="finding_better_features">
<h2>Finding Better Features</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="feature selection" id="ch11_term9"/>Throughout this book, we’ve repeatedly stressed the importance of building a simple model first. This version 1 model is seldom an end in itself. We may keep on adding new features and periodically retraining the model beyond V1. Our goal is to find the features that are most expressive to capture the regularities in the data that are useful for making predictions. How can we develop such features? We saw different ways to generate textual feature representations in <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a>. We can start with one of those that doesn’t require prior knowledge about the problem domain (e.g., basic vectorization, distributed representations, and universal representations) or use our prior knowledge about the problem and domain to develop specific features for our problem (i.e., handcrafted features) or use a combination of both.</p>

<p>Designing specific features for a given problem (or feature engineering<a contenteditable="false" data-type="indexterm" data-primary="feature engineering" id="idm45969586747512"/>) can be both difficult and expensive. This is why problem-agnostic text representations are commonly used as a starting point. However, domain-specific features have their own value. For example, in a task of sentiment classification, more than vector representations of raw text, domain-specific indicators, such as count of negative words, count of positive words, and other word- and phrase-level features, are useful to extract the sentiment in a more robust manner.</p>

<p>Let’s say we implemented a bunch of features to build our NLP models. Does the best model need each one of these features? How do we choose the most informative features among the several we implemented? For example, if we use two features where one can be derived from the other, we’re not adding any extra information to the model. Feature selection is a great technique to handle such cases and make informed decisions. There are plenty of statistical methods that can be used to fine-tune our feature sets by removing redundant or irrelevant features. This broad area is called <em>feature selection</em>.</p>

<p>Two popular techniques for feature selection are wrapper methods and filter methods. Wrapper methods use an ML model to score feature subsets. Each new subset is used to train a model, which is tested on a hold-out set and then used to identify the best features based on the error rate of the model. Wrapper methods are computationally expensive, but they often provide the best set of features. Filter methods use some sort of proxy measure instead of the error rate to rank and score features (e.g., correlation among the features and correlation with the output predictions). Such measures are fast to compute while still capturing the usefulness of the feature set. Filter methods are usually less computationally expensive than wrappers, but they produce a feature set that’s not as well optimized to a specific type of predictive model. In DL-based approaches, while feature engineering and feature selection is automated, we have to experiment with various model architectures.</p>

<p class="pagebreak-before">Since feature selection methods are usually task specific (i.e., methods for classification tasks are different from methods for, say, machine translation), interested readers can look into resources such as sparse features, dense features, and feature interactions from Wide and Deep Learning from Google AI [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586741816-marker" href="ch11.xhtml#idm45969586741816">21</a>]. The book <em>Feature Engineering for Machine Learning</em> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_11_22-marker" href="ch11.xhtml#footnote_11_22">22</a>] would also be useful. However, we hope this overview convinced you of feature selection’s role in building mature, production-quality NLP systems. Assuming we’re going through this process of adding new features and evaluating them, how should we incorporate them into our training process and update our NLP models? Let’s take a look at this question<a contenteditable="false" data-type="indexterm" data-primary="feature selection" data-startref="ch11_term9" id="idm45969586737544"/> now.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Iterating Existing Models"><div class="sect2" id="iterating_existing_models">
<h2>Iterating Existing Models</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="iterating existing models" id="idm45969586734296"/>As we mentioned earlier, any NLP model is seldom a static entity. We’re often required to update our models even in production systems. There are several reasons for this. We may get more (and newer) data that differs from previous training data. If we don’t update our model to reflect this change, it will soon become stale and churn out poor predictions. We may get some user feedback on where the model predictions are going wrong. This will then require us to reflect on the model and its features and make amendments accordingly. In both cases, we need to set up a process to periodically retrain and update the existing model and deploy the new model in production.</p>

<p>When we develop a new model, intuitively, it’s always good to compare the results with our previous best models to understand the incremental value addition. How do we know this new model is better than the existing one? The analysis of model performance can be based on comparing raw predictions from both models, or it could be from a perspective of a derived performance based on the predictions. Let’s explain these two cases by revisiting the abusive comments detection example from earlier in this chapter.</p>

<p>Let’s say we have a gold standard test set of abusive versus non-abusive comments. We can always use this to compare an old model with the new one in terms of, say, classification accuracy. We can also follow an external validation approach and look for other aspects, such as how many model decisions were contested by users every day. It would be practical to set up a dashboard to monitor these metrics periodically and display them for each model so that we can choose the one that’s the best improvement over the current model among the various models we may build. We can also A/B test<a contenteditable="false" data-type="indexterm" data-primary="A/B testing" id="idm45969586730072"/> a new model with an old model (or any baseline system) and measure business KPIs<a contenteditable="false" data-type="indexterm" data-primary="KPIs (key performance indicators)" id="idm45969586728840"/><a contenteditable="false" data-type="indexterm" data-primary="key performance indicators (KPIs)" id="idm45969586727720"/> to see how well the new model performs. When onboarding a new model, it might also be a good practice to first roll it out to a small fraction of users, monitor its performance, and then progressively expand it to the entire user base.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Code and Model Reproducibility"><div class="sect2" id="code_and_model_reproducibility">
<h2>Code and Model Reproducibility</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="code reproducibility" id="idm45969586724504"/><a contenteditable="false" data-type="indexterm" data-primary="reproducibility" id="idm45969586723400"/><a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="reproducibility" id="idm45969586722296"/>Making sure your NLP models continue working in the same fashion in different environments can be critical for the long-term success of any project. A model or result that’s reproducible is generally considered more robust. There is a range of best practices you can use to achieve this while building systems.</p>

<p>Maintaining separation between code, data, and model(s) is always a good strategy. Separating code and data is generally a best practice in software engineering, and it becomes even more critical for AI systems. While there are established version control systems for code, such as Git, versioning of models and datasets<a contenteditable="false" data-type="indexterm" data-primary="datasets" data-secondary="version control " id="idm45969586719704"/><a contenteditable="false" data-type="indexterm" data-primary="version control" id="idm45969586718488"/> can be different. As of recently, there are tools like Data Version Control<a contenteditable="false" data-type="indexterm" data-primary="Data Version Control (DVC)" id="idm45969586717256"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586715880-marker" href="ch11.xhtml#idm45969586715880">23</a>] that address this issue. It’s always a good practice to name model and data versions appropriately so that we can revert back easily, if needed. While storing the models, you should try to have all your model parameters, along with other variables, in a separate file. Similarly, try to avoid hardcoded parameter values in your model. If you have to use arbitrary numbers in your training process (e.g., a seed value somewhere), explain it in the code as comments.</p>

<p>Another good practice is creating checkpoints in your code and model often. You should store your learned model in a repository both periodically and at milestones. When training a model, it’s also a good idea to use the same seed wherever random initialization is used. This ensures that the model creates similar results (and internal representation) every time the same parameters and data are used.</p>

<p>A keystone for improving reproducibility is to make sure to note all steps explicitly. This is especially necessary in the exploratory phase of data analysis. On the same note, it helps to record as many intermediate steps and data outputs as possible. This helps in transforming your experimental model to an in-production model without any loss of information. To read further, we would suggest a report on AI reproducibility state of the art [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586712232-marker" href="ch11.xhtml#idm45969586712232">24</a>] and an interview of a reproducibility researcher at Facebook, Joelle Pineau<a contenteditable="false" data-type="indexterm" data-primary="Pineau, Joelle" id="idm45969586711000"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586709720-marker" href="ch11.xhtml#idm45969586709720">25</a>]. This brings us to the next topic in this section. While making all these iterations and building multiple models, how do we ensure there are no errors and bugs in the training process and that our data isn’t noisy? How do we troubleshoot and test our code and models?</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Troubleshooting and Interpretability"><div class="sect2" id="troubleshooting_and_interpretability">
<h2>Troubleshooting and Interpretability</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="troubleshooting" id="ch11_term10"/>To maintain the quality of software, testing<a contenteditable="false" data-type="indexterm" data-primary="testing" id="idm45969586704600"/><a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="testing models" id="idm45969586703496"/> is a key step in any software development process. However, considering the probabilistic nature of ML models, how to test ML models is not obvious. Figures <a data-type="xref" data-xrefstyle="select:labelnumber" href="#tensorflow_model_analysis_left_parenthe">11-2</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="#lime_for_nlp_model_analysis">11-3</a> illustrate some of the good practices for testing out AI systems. We already saw how to use Lime (<a data-type="xref" href="#lime_for_nlp_model_analysis">Figure 11-3</a>) in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>.</p>
<figure><div id="tensorflow_model_analysis_left_parenthe" class="figure">
<img src="Images/pnlp_1102.png" alt="TensorFlow model analysis (TFMA) [_48]" width="1111" height="668"/>
<h6><span class="label">Figure 11-2. </span>TensorFlow Model Analysis (TFMA)<a contenteditable="false" data-type="indexterm" data-primary="TensorFlow model analysis (TFMA)" id="idm45969586695384"/><a contenteditable="false" data-type="indexterm" data-primary="TFMA (TensorFlow model analysis)" id="idm45969586694216"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_11_48-marker" href="ch11.xhtml#footnote_11_48">26</a>]</h6>
</div></figure>
<figure><div id="lime_for_nlp_model_analysis" class="figure">
<img src="Images/pnlp_1103.png" alt="Lime for NLP model analysis" width="1307" height="935"/>
<h6><span class="label">Figure 11-3. </span>Lime<a contenteditable="false" data-type="indexterm" data-primary="Lime" id="idm45969586689096"/> for NLP model analysis</h6>
</div></figure>

<p class="pagebreak-before">As we discussed earlier in the chapter, a model is just a small component of any AI system. When it comes to testing the entire system, barring the model, most techniques for testing of software engineering are applicable and work well.  When it comes to <a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="testing models" id="ch11_term12"/><a contenteditable="false" data-type="indexterm" data-primary="testing" id="ch11_term13"/>testing the model, the following steps are helpful:</p>
<ul>
<li>
	<p>Run the model on train, validation, and test datasets used during the model-building phase. There should not be any major deviation in the results for any of the metrics. K-fold cross validation is often used to verify model performance.</p></li>
<li>
	<p>Test the model for edge cases. For example, for sentiment classification<a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis" data-secondary="testing" id="idm45969586681256"/>, test with sentences with double or triple negation.</p></li>
<li>
	<p>Analyze the mistakes the model is making. The findings from the analysis should be similar to the findings from the analysis of the mistakes it was making during the development phase. For NLP, packages and techniques like TensorFlow Model Analysis<a contenteditable="false" data-type="indexterm" data-primary="TFMA (TensorFlow model analysis)" id="idm45969586678984"/><a contenteditable="false" data-type="indexterm" data-primary="TensorFlow model analysis (TFMA)" id="idm45969586677288"/> [<a data-type="noteref" href="ch11.xhtml#footnote_11_48">26</a>], Lime<a contenteditable="false" data-type="indexterm" data-primary="Lime" id="idm45969586675176"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586673944-marker" href="ch11.xhtml#idm45969586673944">27</a>], Shap<a contenteditable="false" data-type="indexterm" data-primary="Shap" id="idm45969586672472"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586671192-marker" href="ch11.xhtml#idm45969586671192">28</a>], and attention networks<a contenteditable="false" data-type="indexterm" data-primary="attention networks" id="idm45969586669640"/> [<a data-type="noteref" href="ch11.xhtml#footnote_11_44">5</a>] can give a deeper understanding of what the model is doing deep down. You can see this in action in Figures <a data-type="xref" data-xrefstyle="select:labelnumber" href="#tensorflow_model_analysis_left_parenthe">11-2</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="#lime_for_nlp_model_analysis">11-3</a>. The insights from these during development and production should not change much.</p></li>
<li>
	<p>Another good practice is to build a subsystem that keeps track of key statistics of the features. Since all features are numerical, we can maintain statistics like mean, median, standard deviation, distribution plots, etc. Any deviation in these statistics is a red flag, and we’re likely to see the system churning out wrong predictions. The reason could be as simple as a bug in the pipeline or as complex as a covariate shift in the underlying data. Packages like TensorFlow Model Analysis [<a data-type="noteref" href="ch11.xhtml#footnote_11_48">26</a>] can track these metrics. <a data-type="xref" href="#feature_statistics_in_tensorflow_extend">Figure 11-4</a> shows distributions for metrics of various features for a dataset that can be tracked to find covariate shift or bugs.</p><br/>
<figure class="no-frame"><div id="feature_statistics_in_tensorflow_extend" class="figure">
<img src="Images/pnlp_1104.png" alt="Feature statistics in TensorFlow Extended [_16]" width="1124" height="531"/>
<h6><span class="label">Figure 11-4. </span>Feature statistics in TensorFlow Extended<a contenteditable="false" data-type="indexterm" data-primary="TensorFlow Extended" id="idm45969586659448"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586658120-marker" href="ch11.xhtml#idm45969586658120">29</a>]</h6>
</div></figure></li>
<li>
	<p>Create dashboards for tracking model metrics and create an alerting mechanism on them in case there are any deviations in the metrics. We’ll discuss this point in detail in the next section.</p></li>
<li>
	<p>It’s always good to know what a model is doing inside. This goes a long way toward understanding why a model is behaving in a certain way. A key question in AI has been how to create intelligent systems where we can explain why the model is doing what it is doing. This is called <em>interpretability</em><a contenteditable="false" data-type="indexterm" data-primary="interpretability" id="idm45969586653992"/>. It’s the degree to which a human can understand the cause of a decision [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586652760-marker" href="ch11.xhtml#idm45969586652760">30</a>]. While many algorithms in machine learning (such as decision trees, random forest, XGboost, etc.) and computer vision have been very interpretable, this is not true for NLP, especially DL algorithms. With recent techniques such as attention networks, Lime, and Shapley, we have greater interpretability in NLP models. Interested readers can look at <em>Interpretable Machine Learning</em> by Christoph Molnar<a contenteditable="false" data-type="indexterm" data-primary="Molnar, Christoph" id="idm45969586650600"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586649368-marker" href="ch11.xhtml#idm45969586649368">31</a>] for further discussion<a contenteditable="false" data-type="indexterm" data-primary="troubleshooting" data-startref="ch11_term10" id="idm45969586647624"/><a contenteditable="false" data-type="indexterm" data-primary="testing" data-startref="ch11_term13" id="idm45969586646312"/><a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="testing models" data-startref="ch11_term12" id="idm45969586644936"/> on this topic.</p></li>
</ul>
<p> </p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Monitoring"><div class="sect2" id="monitoring-id00009">
<h2>Monitoring</h2>

<p>Once an ML<a contenteditable="false" data-type="indexterm" data-primary="monitoring" id="ch11_term11"/><a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="monitoring" id="ch11_term15"/> system has been deployed and is in production, we need to make sure the model continues working well. As an example deployment, if the model is being trained automatically every day with new data points, certain bugs can creep in, or the model can malfunction. To ensure that this doesn’t happen, we need to monitor the model for a range of things and trigger alerts at the right points:</p>
<ul>
<li>
	<p>Model performance has to be monitored regularly. For a web service–based model<a contenteditable="false" data-type="indexterm" data-primary="web service–based models" id="idm45969586636328"/><a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="web service–based" id="idm45969586635064"/>, it can be the mean and various percentiles—50th (median), 90th, 95th, and 99th (or deeper)—for response time. If the model is deployed as a batch service, statistics on the batch processing and task times have to be monitored.</p></li>
<li>
	<p>Similarly, it helps to store monitor model parameters, behavior, and KPIs. Model KPIs<a contenteditable="false" data-type="indexterm" data-primary="KPIs (key performance indicators)" id="idm45969586632600"/><a contenteditable="false" data-type="indexterm" data-primary="key performance indicators (KPIs)" id="idm45969586631384"/> for the abusive comments example would be the percentage of comments that were reported by users but not flagged by the model. For a text classification service<a contenteditable="false" data-type="indexterm" data-primary="text classification" data-secondary="KPIs for" id="idm45969586629960"/>, it could be the distribution of classes that are classified each day.</p></li>
<li>
	<p>For all the metrics we’re monitoring, we need to periodically run them through an anomaly detection system that can alert changes in normal behavior. This could be a sudden spike in the response rate of a web service or a sudden drop in retraining times. In the worst case, when the performance drops substantially, we may also want to hit circuit breakers (i.e., move to a more stable model or a default approach).</p></li>
<li>
	<p>If our overall engineering pipeline is using a logging framework, there’s a good chance it also has support for monitoring anomalies over time for any metric. For instance, ELK stack<a contenteditable="false" data-type="indexterm" data-primary="ELK stack (Elastic)" id="idm45969586626104"/> by Elastic<a contenteditable="false" data-type="indexterm" data-primary="Elasticsearch" data-secondary="ELK stack" id="idm45969586624872"/> offers built-in anomaly detection<a contenteditable="false" data-type="indexterm" data-primary="anomaly detection" id="idm45969586623336"/> [<a data-type="noteref" href="ch11.xhtml#footnote_11_70">7</a>]. <span class="keep-together">Sumo Logic</span><a contenteditable="false" data-type="indexterm" data-primary="Sumo Logic" id="idm45969586620680"/> also flags outliers that can be queried as needed [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586619384-marker" href="ch11.xhtml#idm45969586619384">32</a>]. Microsoft<a contenteditable="false" data-type="indexterm" data-primary="Microsoft" data-secondary="anomaly detection" id="idm45969586617976"/> also offers anomaly detection as a service [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586616408-marker" href="ch11.xhtml#idm45969586616408">33</a>].</p></li>
</ul>

<p>Monitoring our ML models and their deployments can save substantial time as the project scales. As the system matures and the model stabilizes, proper monitoring allows MLOps teams to largely manage it, so data scientists can solve other harder problems. Although, as systems mature, we also start accumulating more technical debt, which we’ll cover in the<a contenteditable="false" data-type="indexterm" data-primary="monitoring" data-startref="ch11_term11" id="idm45969586614136"/><a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="monitoring" data-startref="ch11_term15" id="idm45969586612824"/> next section.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Minimizing Technical Debt"><div class="sect2" id="minimizing_technical_debt">
<h2>Minimizing Technical Debt</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="technical debt minimization" id="ch11_term17"/>Throughout this book, and especially in this chapter, we’ve seen various aspects of training NLP models, deploying them as a part of a larger system, and iteratively improving from there on. As we start iterating from the first version of the system, the system and various components, including the model, can easily become complex. This brings the challenges of maintaining the system. We may have scenarios where we don’t know if the incremental improvements justify the complexity. Such scenarios can create a technical debt. Let’s take a brief look at addressing technical debt in building AI software.</p>

<p>It’s important to plan and build for the future when working with any software system. We have to ensure that our system continues being both performant and easy to maintain after all these continuous iterations and testing. Unused and poorly implemented improvements can create technical debt. If we’re not using a feature or any of its combinations with other features, it’s important to drop it out of the pipeline. A feature or part of the code that doesn’t work just clogs our infrastructure, hinders fast iteration, and brings down clarity.</p>

<p>A good rule of thumb is to look at the coverage a feature provides. If a feature is present in only a few data points, say, 1%, then maybe it’s not worth keeping. But even something like this can’t be applied blindly. For example, if the same feature covers just 1% of the data but gives 95% classification accuracy just based on that feature, then it’s really effective and most certainly worth continuing to use. From our experience, an important tip (that we’ve also reiterated several times in the book) is: <em>opt for a simpler model that has performance comparable to a much more complex model if you want to minimize technical debt</em>. Complex models may become necessary if there’s no equivalent simple model though.</p>

<p class="pagebreak-before">Besides these recommendations<a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="recommendations for" id="idm45969586603880"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="landmark work" id="ch11_term19"/>, we’d also like to share some landmark work on building mature ML systems:</p>
<ul>
<li>
	<p>“A Few Useful Things to Know About Machine Learning” by Pedro Domingoes<a contenteditable="false" data-type="indexterm" data-primary="Domingoes, Pedro" id="idm45969586599480"/> of the University of Washington [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586598008-marker" href="ch11.xhtml#idm45969586598008">34</a>]</p></li>
<li>
	<p>“Machine Learning: The High-Interest Credit Card of Technical Debt” by a team at Google <span class="keep-together">AI<a contenteditable="false" data-type="indexterm" data-primary="Google AI" id="idm45969586595256"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586593992-marker" href="ch11.xhtml#idm45969586593992">35</a>]</span></p></li>
<li>
	<p>“Hidden Technical Debt in Machine Learning Systems” by a team at Google <span class="keep-together">AI [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586591256-marker" href="ch11.xhtml#idm45969586591256">36</a>]</span></p></li>
<li>
	<p><em>Feature Engineering for Machine Learning</em>, a book written by Alice Zheng<a contenteditable="false" data-type="indexterm" data-primary="Zheng, Alice" id="idm45969586588664"/> and Amanda Casari<a contenteditable="false" data-type="indexterm" data-primary="Casari, Amanda" id="idm45969586587464"/> [<a data-type="noteref" href="ch11.xhtml#footnote_11_22">22</a>]</p></li>
<li>
	<p>“Ad Click Prediction: A View from the Trenches,” a work by a Google Search<a contenteditable="false" data-type="indexterm" data-primary="Google Search" id="idm45969586584664"/> team on the issues faced by a large online ML system [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586583368-marker" href="ch11.xhtml#idm45969586583368">37</a>]</p></li>
<li>
	<p>“Rules of Machine Learning,” an online guide created by Martin Zenkovich<a contenteditable="false" data-type="indexterm" data-primary="Zenkovich, Martin" id="idm45969586581192"/> of Google [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586579960-marker" href="ch11.xhtml#idm45969586579960">38</a>]</p></li>
<li>
	<p>“The Unreasonable Effectiveness of Data,” a report by renowned UC Berkeley researcher Peter Norvig<a contenteditable="false" data-type="indexterm" data-primary="Norvig, Peter" id="idm45969586577112"/> and a Google AI team [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586575880-marker" href="ch11.xhtml#idm45969586575880">39</a>]</p></li>
<li>
	<p>“Revisiting Unreasonable Effectiveness of Data in Deep Learning Era,” another modern look at the previous report by a team from Carnegie Mellon <span class="keep-together">University<a contenteditable="false" data-type="indexterm" data-primary="Carnegie Mellon University" id="idm45969586573160"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586571832-marker" href="ch11.xhtml#idm45969586571832">40</a>]</span></p></li>
</ul>

<p>So far, we’ve discussed various best practices used in building mature AI systems. From finding better features to version control of datasets, these practices are manual and effort intensive. Driven by the ultimate goal of building intelligent machines and reducing manual effort, an interesting recent work has been to automate some aspects of building AI systems. Let’s look at some key efforts in this<a contenteditable="false" data-type="indexterm" data-primary="technical debt minimization" data-startref="ch11_term17" id="idm45969586569544"/> direction.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Automating Machine Learning"><div class="sect2" id="automating_machine_learning">
<h2>Automating Machine Learning</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="automated machine learning (AutoML)" id="ch11_term21"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="automated" id="ch11_term20"/>One of the holy grails of machine learning is to automate more and more of the feature engineering process. This has led to the creation of a subarea called AutoML (automated machine learning), which aims to make machine learning more accessible. In most cases, it generates a data analysis pipeline that can include data pre-processing, feature selection, and feature engineering methods. This pipeline essentially selects ML methods and parameter settings that are optimized for a specific problem and data. As all of these steps can be time consuming for the ML expert and may be intractable for a beginner, AutoML can be a much-needed bridge for a gap in the world of machine learning. AutoML is itself essentially “doing machine learning using machine learning,” making this powerful and complex technology more widely accessible for those hoping to make use of massive amounts of data.</p>

<p>As an example, one research group at Google<a contenteditable="false" data-type="indexterm" data-primary="Google Cloud" data-secondary="AutoML" id="idm45969586561512"/> has used AutoML techniques [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_11_61-marker" href="ch11.xhtml#footnote_11_61">41</a>] for language modeling with the Penn Treebank dataset. Penn Treebank<a contenteditable="false" data-type="indexterm" data-primary="Penn Treebank dataset" id="idm45969586557912"/> is a benchmark dataset for linguistic structure [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586556536-marker" href="ch11.xhtml#idm45969586556536">42</a>]. The research group at Google found that their AutoML approach can design models that achieve accuracies on par with state-of-the-art models designed by world-class machine learning experts.  <a data-type="xref" href="#automl_generated_network_left_square_br">Figure 11-5</a> shows an example of a neural network generated by AutoML.</p>
<figure><div id="automl_generated_network_left_square_br" class="figure">
<img src="Images/pnlp_1105.png" alt="AutoML-generated network [_61]" width="822" height="383"/>
<h6><span class="label">Figure 11-5. </span>AutoML-generated network [<a data-type="noteref" href="ch11.xhtml#footnote_11_61">41</a>]</h6>
</div></figure>

<p>On the left side of the figure is a neural network that Google experts created to parse text. On the right side is another network that was created automatically by Google’s AutoML. AutoML that explores various neural network architectures automatically performed as well as the handcrafted model. It’s fascinating to see that their system did almost as well as humans even for designing ML models.</p>

<p>AutoML is the cutting edge of machine learning. One should only build it from the bottom up when more traditional methods for improving performance are exhausted. It often requires a high amount of computing and GPU resources and a higher level of technical skill when doing it from scratch.</p>

<section data-type="sect3" data-pdf-bookmark="auto-sklearn"><div class="sect3" id="auto_sklearn">
<h3>auto-sklearn</h3>

<p><a contenteditable="false" data-type="indexterm" data-primary="autosklearn" id="ch11_term22"/>As we mentioned previously, it’s generally a good idea to work on automating machine learning only after most other options have been exhausted. In cases where the need for AutoML [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586545528-marker" href="ch11.xhtml#idm45969586545528">43</a>] is more clear, one of the best libraries for applying it is auto-sklearn. It uses recent advancements in Bayesian optimization and meta-learning to search in a huge hyperparameter space to figure out a reasonably good ML model on its own. As it’s integrated with sklearn, which is one of the more popular ML libraries, using it is quite simple:</p>
<pre data-code-language="python" data-type="programlisting">  <code class="kn">import</code> <code class="nn">autosklearn.classification</code>
  <code class="kn">import</code> <code class="nn">sklearn.model_selection</code>
  <code class="kn">import</code> <code class="nn">sklearn.datasets</code>
  <code class="kn">import</code> <code class="nn">sklearn.metrics</code>
  <code class="n">X</code><code class="p">,</code> <code class="n">y</code> <code class="o">=</code> <code class="n">sklearn</code><code class="o">.</code><code class="n">datasets</code><code class="o">.</code><code class="n">load_digits</code><code class="p">(</code><code class="n">return_X_y</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
  <code class="n">X_train</code><code class="p">,</code> <code class="n">X_test</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">y_test</code> <code class="o">=</code> \
        <code class="n">sklearn</code><code class="o">.</code><code class="n">model_selection</code><code class="o">.</code><code class="n">train_test_split</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
  <code class="n">automl</code> <code class="o">=</code> <code class="n">autosklearn</code><code class="o">.</code><code class="n">classification</code><code class="o">.</code><code class="n">AutoSklearnClassifier</code><code class="p">()</code>
  <code class="n">automl</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>
  <code class="n">y_hat</code> <code class="o">=</code> <code class="n">automl</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code>
  <code class="k">print</code><code class="p">(</code><code class="s2">"Accuracy"</code><code class="p">,</code> <code class="n">sklearn</code><code class="o">.</code><code class="n">metrics</code><code class="o">.</code><code class="n">accuracy_score</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code> <code class="n">y_hat</code><code class="p">))</code></pre>

<p>This code builds an <code>autosklearn</code> classifier for the MNIST digits dataset [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586540872-marker" href="ch11.xhtml#idm45969586540872">44</a>]. It splits the dataset into training and test sets. While running for about an hour, this will automatically yield accuracy of over 98%.</p>

<p>When we peek through what’s happening internally, we see different stages of AutoML, as shown in the snippet below:</p>
<pre data-type="programlisting">[(0.080000, SimpleClassificationPipeline({'balancing:strategy': 'none',
'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 
'lda',
'imputation:strategy': 'mean', 'preprocessor:__choice__': 'polynomial',
'rescaling:__choice__': 'minmax',
'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',
'classifier:lda:n_components': 151,
'classifier:lda:shrinkage': 'auto', 'classifier:lda:tol': 
0.02939556179271624,
'preprocessor:polynomial:degree': 2, 'preprocessor:polynomial:include_bias': 
'True',
'preprocessor:polynomial:interaction_only': 'True',
'categorical_encoding:one_hot_encoding:minimum_fraction': 0.0729529152649298},
dataset_properties={
  'task': 2,
  'sparse': False,
  'multilabel': False,
  'multiclass': True,
  'target_type': 'classification',
  'signed': False})),
...
...
...
...
(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'none', 
'categorical_encoding:__choice__':
'one_hot_encoding', 'classifier:__choice__': 'passive_aggressive', 
'imputation:strategy': 'mean',
'preprocessor:__choice__': 'polynomial', 'rescaling:__choice__': 'minmax',
'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 
'classifier:passive_aggressive:C':
0.03485276894122253, 'classifier:passive_aggressive:average': 'True',
'classifier:passive_aggressive:fit_intercept': 'True', 
'classifier:passive_aggressive:loss': 'hinge',
'classifier:passive_aggressive:tol': 4.6384320611389e-05, 
'preprocessor:polynomial:degree': 3,
'preprocessor:polynomial:include_bias': 'True', 
'preprocessor:polynomial:interaction_only': 'True',
'categorical_encoding:one_hot_encoding:minimum_fraction': 0.11994577706637469},
dataset_properties={
  'task': 2,
  'sparse': False,
  'multilabel': False,
  'multiclass': True,
  'target_type': 'classification',
  'signed': False})),
]
auto-sklearn results:
  Dataset name: d74860caaa557f473ce23908ff7ba369
  Metric: accuracy
  Best validation score: 0.991011
  Number of target algorithm runs: 240
  Number of successful target algorithm runs: 226
  Number of crashed target algorithm runs: 1
  Number of target algorithms that exceeded the time limit: 2
  Number of target algorithms that exceeded the memory limit: 11</pre>

<p>Next, let’s take a look at Google Cloud services, as well as a few other approaches to NLP<a contenteditable="false" data-type="indexterm" data-primary="autosklearn" data-startref="ch11_term22" id="idm45969586451400"/> problems.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Google Cloud AutoML and other techniques"><div class="sect3" id="google_cloud_automl_and_other_technique">
<h3>Google Cloud AutoML and other techniques</h3>

<p>Google Cloud Services<a contenteditable="false" data-type="indexterm" data-primary="Google Cloud" data-secondary="AutoML" id="idm45969586447896"/> has also recently released AutoML as a service. This doesn’t require any technical knowledge beyond providing training data in the expected format. They’ve specifically built Cloud AutoML services for different parts of AI, including computer vision and structured tabular data, as well as for NLP.</p>

<p>For NLP, their Cloud AutoML is applied automatically when training custom models for:</p>
<ul>
<li>
	<p>Text classification</p></li>
<li>
	<p>Entity extraction</p></li>
<li>
	<p>Sentiment analysis</p></li>
<li>
	<p>Machine translation</p></li>
</ul>

<p>For all these tasks, Google Cloud has defined a specific format that the AutoML models expect the data to be in. More information on these can be found in their documentation [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586441400-marker" href="ch11.xhtml#idm45969586441400">45</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586439992-marker" href="ch11.xhtml#idm45969586439992">46</a>]. Microsoft<a contenteditable="false" data-type="indexterm" data-primary="Microsoft Azure" data-secondary="AutoML" id="idm45969586438616"/> also has tooling for AutoML in their Azure Machine Learning<a contenteditable="false" data-type="indexterm" data-primary="Microsoft Azure" data-secondary="Machine Learning" id="idm45969586437144"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586435640-marker" href="ch11.xhtml#idm45969586435640">47</a>].</p>

<p>Another interesting approach to tackling an NLP problem in a more automated way is to use the AutoCompete framework<a contenteditable="false" data-type="indexterm" data-primary="AutoCompete framework" id="idm45969586433720"/> created by Abhishek Thakur<a contenteditable="false" data-type="indexterm" data-primary="Thakur, Abhishek" id="idm45969586432488"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586431256-marker" href="ch11.xhtml#idm45969586431256">48</a>], a top-ranked Kaggle Competitions Grandmaster. Even though his initial approach was to focus on any data science problem specifically targeted to competitions, it has now evolved to a general framework to solve such problems. He has also released a detailed notebook titled “Approaching (Almost) Any NLP Problem on Kaggle” [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586429432-marker" href="ch11.xhtml#idm45969586429432">49</a>] that creates a general modeling framework for NLP problems with a well-defined dataset and goals. While this may not completely solve the specific NLP task you’re working at, it’s a good start to look at creating baseline models.</p>

<p>So far, we’ve addressed a range of issues that might come up when trying to build, deploy, and maintain NLP software. However, an equally important component of such an endeavor is to follow standard product development processes. While the field of software development processes and life cycle is well established, there are some important things to consider while working on projects that involve predictive models like the ones we’ve discussed throughout the book. Let’s now take a look at that<a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="automated" data-startref="ch11_term20" id="idm45969586426696"/><a contenteditable="false" data-type="indexterm" data-primary="automated machine learning (AutoML)" data-startref="ch11_term21" id="idm45969586425080"/> aspect.</p>
</div></section>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="The Data Science Process"><div class="sect1" id="the_data_science_process">
<h1>The Data Science Process</h1>

<p><a contenteditable="false" data-type="indexterm" data-primary="data science (DS)" id="ch11_term23"/><a contenteditable="false" data-type="indexterm" data-primary="DS (data science)" id="ch11_term223"/>Data science is a broad term describing the algorithms and processes used to extract meaningful information and actionable insights from all forms of data. Thus, all NLP work in the industry can be categorized under the data science umbrella. While data science as a term is relatively new, it’s been around in some form or another for the past few decades. Over the years, people have formulated and formalized the best processes and practices of working with data. Two popular processes in the industry are the KDD process and the Microsoft Team Data Science Process<a contenteditable="false" data-type="indexterm" data-primary="Microsoft Team Data Science Process (TDSP)" id="idm45969586418456"/><a contenteditable="false" data-type="indexterm" data-primary="Team Data Science Process (TDSP)" id="idm45969586417256"/>.</p>

<section data-type="sect2" data-pdf-bookmark="The KDD Process"><div class="sect2" id="the_kdd_process">
<h2>The KDD Process</h2>

<p>The ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)<a contenteditable="false" data-type="indexterm" data-primary="ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)" id="idm45969586414056"/><a contenteditable="false" data-type="indexterm" data-primary="Knowledge Discovery and Data Mining (KDD) process" id="ch11_term24"/><a contenteditable="false" data-type="indexterm" data-primary="KDD (Knowledge Discovery and Data Mining) process" id="ch11_term25"/> is one of the oldest and most reputed data mining conferences in the world. Some of the founders of the conference also created the KDD process in 1996. The KDD process [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_11_5-marker" href="ch11.xhtml#footnote_11_5">50</a>], depicted in <a data-type="xref" href="#the_kdd_process_left_square_bracket_5ri">Figure 11-6</a>, consists of a series of steps that should be applied to a data science or data mining problem to get better results.</p>
<figure><div id="the_kdd_process_left_square_bracket_5ri" class="figure">
<img src="Images/pnlp_1106.png" alt="The KDD process [_5]" width="1386" height="718"/>
<h6><span class="label">Figure 11-6. </span>The KDD process [<a data-type="noteref" href="ch11.xhtml#footnote_11_5">50</a>]</h6>
</div></figure>

<p>These steps are ordered as follows:</p>
<ol>
<li>
	<p><em>Understanding the domain:</em> This includes learning about the application and understanding the goals of a problem. It also involves getting deeper into the problem domain and extracting relevant domain knowledge.</p></li>
<li>
	<p><em>Target dataset<a contenteditable="false" data-type="indexterm" data-primary="target datasets" id="idm45969586401208"/><a contenteditable="false" data-type="indexterm" data-primary="datasets" data-secondary="target" id="idm45969586400072"/> creation:</em> This includes selecting a subset of data and variables the problem will focus on. We may have a plethora of data sources at our disposal, but we focus on the subset we need to work on.</p></li>
<li>
	<p><em>Data pre-processing<a contenteditable="false" data-type="indexterm" data-primary="pre-processing" id="idm45969586397368"/><a contenteditable="false" data-type="indexterm" data-primary="data pre-processing" data-seealso="pre-processing" id="idm45969586396232"/>:</em> This encompasses all activities needed so that the data can be treated coherently. This includes filling missing values, noise reduction, and removing outliers.</p></li>
<li>
	<p><em>Data reduction<a contenteditable="false" data-type="indexterm" data-primary="data reduction" id="idm45969586393560"/>:</em> If the data has a lot of dimensions, this step can be used to make it easier to work with. This includes steps like dimensionality reduction and projecting the data into another space. This step is optional depending on the data.</p></li>
<li>
	<p><em>Choosing the data mining<a contenteditable="false" data-type="indexterm" data-primary="data mining" id="idm45969586391016"/> task:</em> Various classes of algorithms can be applied to a problem. They may be regression, classification, or clustering. It’s important to select the right task based on our understanding from Step 1.</p></li>
<li>
	<p><em>Choosing the data mining algorithm:</em> Based on the selected data mining task, we need to select the right algorithm. For instance, for classification, we can choose algorithms such as SVM, random forests, CNNs, etc., as we saw in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>.</p></li>
<li>
	<p><em>Data mining:</em> This is a core step of applying the selection algorithm from Step 6 to the given dataset and creating predictive models. Tuning with respect to parameters and hyperparameters also happens here.</p></li>
<li>
	<p><em>Interpretation:</em> Once the algorithm is applied, the user has to interpret the results. This can be done partially by visualizing various components of results.</p></li>
<li>
	<p><em>Consolidation:</em> This is the final step where we deploy the built model into an existing system, document the approach, and generate reports.</p></li>
</ol>

<p>As seen in the figure, the KDD process is highly iterative. There can be any number of loops between various steps. At each step, we can and may need to go back to earlier steps and refine the information there before moving ahead. This process is a good reference when working on a specific data science problem. While not exactly the same, the pipelines we’ve discussed throughout the book deal with the same idea of bringing structure to building NLP systems. Now, let’s take a look at the<a contenteditable="false" data-type="indexterm" data-primary="Knowledge Discovery and Data Mining (KDD) process" data-startref="ch11_term24" id="idm45969586382856"/><a contenteditable="false" data-type="indexterm" data-primary="KDD (Knowledge Discovery and Data Mining) process" data-startref="ch11_term25" id="idm45969586381384"/> second <span class="keep-together">process.</span></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Microsoft Team Data Science Process"><div class="sect2" id="microsoft_team_data_science_process">
<h2>Microsoft Team Data Science Process</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="Microsoft Team Data Science Process (TDSP)" id="ch11_term26"/><a contenteditable="false" data-type="indexterm" data-primary="Team Data Science Process (TDSP)" id="ch02_term30"/>The KDD process was introduced in the late ’90s. As the fields of machine learning and data science grew, bigger teams working exclusively on such data science projects began to emerge. Further, in the fast-moving world of data-driven development, more flexible and iteration-based frameworks were needed, so other data science processes began to emerge. The Microsoft Team Data Science Process (TDSP) addresses this. It was released by the Microsoft Azure<a contenteditable="false" data-type="indexterm" data-primary="Microsoft Azure" id="idm45969586336488"/> team in 2017 and is one of the modern processes for applying machine learning and working in data science [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_11_6-marker" href="ch11.xhtml#footnote_11_6">51</a>].</p>

<p>TDSP is an agile, iterative data science process for executing and delivering advanced analytics solutions. It’s designed to improve the collaboration and efficiency of data science teams in enterprise organizations. The main features of TDSP are:</p>
<ul>
<li>
	<p>A data science life cycle definition</p></li>
<li>
	<p>A standardized  project structure, which includes project documentation and reporting templates</p></li>
<li>
	<p>An infrastructure for project execution</p></li>
<li>
	<p>Tools for data science, like version control, data exploration, and modeling</p></li>
</ul>

<p>The TDSP documentation [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586328872-marker" href="ch11.xhtml#idm45969586328872">52</a>] provides detailed insight into all of these aspects, so we’ll just take a brief look in this section. The TDSP data science life cycle, showing different phases of a data project, is shown in <a data-type="xref" href="#the_microsoft_tdsp_process_left_square">Figure 11-7</a>.</p>
<figure><div id="the_microsoft_tdsp_process_left_square" class="figure">
<img src="Images/pnlp_1107.png" alt="The Microsoft TDSP process [_6]" width="1440" height="1001"/>
<h6><span class="label">Figure 11-7. </span>The Microsoft TDSP life cycle [<a data-type="noteref" href="ch11.xhtml#footnote_11_6">51</a>]</h6>
</div></figure>

<p>While TDSP shares some similarities with the KDD process, an interesting aspect of TDSP is that it defines a life cycle of a data science project from a business and team management perspective. This includes the following stages:</p>
<ul>
<li>
	<p>Business understanding</p></li>
<li>
	<p>Data acquisition and understanding</p></li>
<li>
	<p>Modeling</p></li>
<li>
	<p>Deployment</p></li>
<li>
	<p>Customer acceptance</p></li>
</ul>

<p>At a high level, the data science life cycle showcases how various components of an effective and agile data science team should operate. The “Charter” and “Exit Report” documents in the TDSP documentation are particularly important to consider. They help define the project at the start of an engagement and provide a final report to the customer or client.</p>

<p>Overall, these processes can be useful for taking the problems and solutions we’ve discussed so far in this book from prototyping to deployment in a production system. These processes are of course not specific to NLP and are more generic recommendations for any data-driven projects involving ML approaches. While there are other similar project management processes for data science that are emerging as the field grows, we hope this gives you an overview of what to look out for in managing your own NLP projects in a software development<a contenteditable="false" data-type="indexterm" data-primary="data science (DS)" data-startref="ch11_term23" id="idm45969586316680"/><a contenteditable="false" data-type="indexterm" data-primary="DS (data science)" data-startref="ch11_term223" id="idm45969586315304"/><a contenteditable="false" data-type="indexterm" data-primary="Microsoft Team Data Science Process (TDSP)" data-startref="ch11_term26" id="idm45969586313928"/><a contenteditable="false" data-type="indexterm" data-primary="Team Data Science Process (TDSP)" data-startref="ch02_term30" id="idm45969586312456"/> setting.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Making AI Succeed at Your Organization"><div class="sect1" id="making_ai_succeed_at_your_organization">
<h1>Making AI Succeed at Your Organization</h1>

<p><a contenteditable="false" data-type="indexterm" data-primary="artificial intelligence (AI)" data-secondary="key points and rules of thumb" id="ch11_term33"/>So far, this book has focused on successfully building and deploying solutions for various AI problems. Success of any AI project is dependent not just on the technical superiority of the solution—there are many other factors involved, too. It’s a known fact that a large number of AI projects in industry fail because the model doesn’t get deployed or, if deployed, fails to achieve its objectives. According to a recent study by Gartner [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586307080-marker" href="ch11.xhtml#idm45969586307080">53</a>], more than 85% of AI projects fail. Here, we discuss some key points and rules of thumb to make AI projects succeed. Many of these points come from our own experience of working in various domains of AI across various organizations.</p>

<section data-type="sect2" data-pdf-bookmark="Team"><div class="sect2" id="team">
<h2>Team</h2>

<p><a contenteditable="false" data-type="indexterm" data-primary="team personnel" id="ch11_term34"/><a contenteditable="false" data-type="indexterm" data-primary="personnel" id="ch11_term35"/>It’s important to have the right team to solve the AI problems at hand. In understanding the problem statement, prioritizing, developing, deploying, and consuming, a lot depends on the skills of the team. While there’s no fixed recipe, in our experience, the right blend comes with having (1) scientists who build models, (2) engineers who operationalize and maintain models, and (3) leaders who manage AI teams and strategize. It’s good to have (4) scientists who have worked in industry after graduate school, (5) engineers who understand scale and data pipelines, and 6) leaders who have also been individual contributor scientists in the past. While (5) is pretty self-explanatory, (4) and (6) warrant some explanation.</p>

<p>Let’s look at (4) first. It’s important that scientists understand the fundamentals of machine learning and are able to think of novel solutions. Graduate school (especially a PhD) prepares you well for that. But, in industry, solving an AI problem is not just applying novel algorithms. It’s also about collecting and cleaning the data, making the data consumption-ready, and applying known techniques. This is very different from academia, where most work happens on known public datasets that are both readily available and clean. Most researchers in academia work on devising novel approaches to beat the state-of-the-art results. In many cases, scientists fresh from academia end up applying sophisticated approaches that prove counterproductive. One is building AI for products—AI is just a means, and not the end. That’s why it’s important that senior scientists on the team have built and deployed models in industrial settings.</p>

<p>Moving on to (6): AI leadership is very different from software engineering leadership<a contenteditable="false" data-type="indexterm" data-primary="leadership" id="idm45969586297720"/>. Even though what runs in production in any AI system is code, AI is fundamentally different from software engineering. Many leaders and organizations are not aware of this nuance. They believe that, because it’s code, all the principles of software engineering apply to it. From defining the problem statement to planning project timelines, developing an AI system is different from developing a traditional IT system. This is why it’s recommended that AI leaders in your organization have the experience of having been individual contributors (ICs) in the<a contenteditable="false" data-type="indexterm" data-primary="team personnel" data-startref="ch11_term34" id="idm45969586295912"/><a contenteditable="false" data-type="indexterm" data-primary="personnel" data-startref="ch11_term35" id="idm45969586294536"/> AI field.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Right Problem and Right Expectations"><div class="sect2" id="right_problem_and_right_expectations">
<h2>Right Problem and Right Expectations</h2>

<p>In many cases, either the problem at hand is ill defined or AI teams set the wrong expectations<a contenteditable="false" data-type="indexterm" data-primary="artificial intelligence (AI)" data-secondary="expectations vs reality" id="ch11_term36"/>. Let’s understand this better with some examples. Consider a scenario where we’re given a dump of what customers say about a particular product or brand, and we’re asked to bring out “interesting” insights. This is a very common scenario in industry; we discussed similar scenarios in <a data-type="xref" href="ch07.xhtml#topic_modeling">“Topic Modeling”</a>. Now, can we apply topic modeling to this particular scenario? It depends on what “interesting” means in this context. It could be what the majority of customers are saying, or it could be what a small subset of customers belonging to a particular region are saying, or it could be what customers are saying about a specific product feature. The possibilities are many. It’s important to work with the stakeholders first to clearly define the task. A great way to do this is to take a set of diverse example inputs that include edge cases and ask the stakeholders to write down the desired output. An important thing to keep in mind is that the ready availability of a lot of data does not make something an AI problem by default; many problems can be solved using engineering and rule-based and human-in-the-loop approaches.</p>

<p>Another common problem is stakeholders having wrong expectations of AI technology. This often happens because of articles in popular media that tend to compare AI to the human brain. While that’s correct as a motivation behind the area of AI, it’s far from the truth. For example, consider a scenario where we built a sentiment analysis system and, for a given input sentence, our system predicts a wrong output. It gives a very high accuracy, but not 100%. Most stakeholders coming from the world of software engineering treat this as a bug and are not willing to accept anything that’s not 100% correct. They are not aware of the fact that any AI system (as of today) will give wrong output for a subset of inputs. Another expectation of AI is that it will replace human effort completely, thus saving money. This is seldom the case. It’s better to treat AI as augmented intelligence to <em>support</em> human efforts rather than artificial intelligence to <em>replace</em> human efforts. Also, beyond a point, model performance stagnates and doesn’t continue rising with time. We see this in <a data-type="xref" href="#expectation_versus_reality_in_ai_perfor">Figure 11-8</a>, where reality behaves more like an S curve while the expectation continues rising.</p>


<p>Even a very mature and advanced AI system requires human supervision. In many cases, we can reduce human efforts, but that happens over a long period of time. In the same vein, stakeholders coming from software engineering may not understand the importance of building responsible AI. Responsible AI ensures trustworthy solutions that are fair, transparent, and accountable. Google [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586282904-marker" href="ch11.xhtml#idm45969586282904">54</a>] and Microsoft [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586281208-marker" href="ch11.xhtml#idm45969586281208">55</a>] have published best practices for building responsible AI systems.</p>

<figure><div id="expectation_versus_reality_in_ai_perfor" class="figure">
<img src="Images/pnlp_1108.png" alt="Expectation versus reality in AI performance" width="777" height="610"/>
<h6><span class="label">Figure 11-8. </span>Expectation versus reality in AI performance</h6>
</div></figure>

</div></section>

<section data-type="sect2" data-pdf-bookmark="Data and Timing"><div class="sect2" id="data_and_timing">
<h2>Data and Timing</h2>

<p>Data is at the heart of any AI system. We’ve discussed various aspects of data in detail in previous chapters. Let’s look at one more: in many cases, just because an organization has gigabytes or even petabytes of data, it doesn’t mean they’re ready for AI and can quickly reap its benefits. There’s a difference between having data and having the right data. Let’s understand this:</p>
<dl>
	<dt>Quality of data<a contenteditable="false" data-type="indexterm" data-primary="quality of data" id="idm45969586274344"/></dt> 
<dd><p>To perform well, any AI system needs a high quality of data for both training and prediction. What does high quality mean? Data that is structured, homogenous, cleaned, and free of noise and outliers. Going from a dump of noisy data to high-quality data is often a long process. The best way to think of it is the following analogy: raw data is crude oil and AI models are fighter jets. Fighter jets need aviation fuel to fly; they cannot fly on crude oil. So, to enable fighter jets, someone must set up the petroleum refinery to systematically extract the aviation fuel from the crude oil. And setting up this refinery is a long and expensive process.</p>

	<p>Another important point is to have the right representative data<a contenteditable="false" data-type="indexterm" data-primary="representative data" id="idm45969586271512"/>: data that allows us to solve the problem at hand. For example, there’s no way we can improve our search feature if we don’t already have the metadata<a contenteditable="false" data-type="indexterm" data-primary="metadata" id="idm45969586270024"/> about what we want to search. So, if we don’t have “Adidas Shoes Size 10 Tennis Shoes” but only have “Adidas Shoes Size 10,” there’s no way we can easily make our search help find tennis shoes.</p></dd>

	<dt>Quantity of data<a contenteditable="false" data-type="indexterm" data-primary="quantity of data" id="idm45969586268184"/></dt> 
	<dd><p>Most AI models are a compressed representation of the dataset used to train them. Not having enough data that’s a true representation of the data the model will see in production is a big reason for models not performing well. How much data is enough? This is a hard question to answer, but there are some rules of thumb. For instance, for sentence classification using baseline algorithms such as Naive Bayes<a contenteditable="false" data-type="indexterm" data-primary="Naive Bayes" id="idm45969586266040"/> or random forest<a contenteditable="false" data-type="indexterm" data-primary="random forest" id="idm45969586264808"/>, we’ve observed that having at least two to three thousand data points per class is a must to be able to build an acceptable <span class="keep-together">classifier.</span></p></dd>

	<dt>Data labeling<a contenteditable="false" data-type="indexterm" data-primary="labeling" id="idm45969586262456"/><a contenteditable="false" data-type="indexterm" data-primary="data labeling" id="idm45969586261320"/></dt> 
	<dd>As of today, most success stories of AI in industry have come from supervised AI. As we discussed in initial chapters, it’s the subarea where, for each data point, we have the ground truth. For many problems, the ground truth comes from human annotators. This is often a time-consuming and expensive process. In many industrial settings, stakeholders aren’t aware of the importance of this step.</dd>

	<dd>Data labeling is often a continuous process. While we do get data labeled in bulk as a one-time effort to build the first versions of our model, once the model is put in production and stabilizes, getting the production data annotated is a continuous process from there on. Further, we need to define processes for labeling and enforce quality checks to improve the accuracy and consistency of human annotators. This is done using metrics like kappa to measure inter-annotator <span class="keep-together">agreement</span> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586257784-marker" href="ch11.xhtml#idm45969586257784">56</a>].</dd>
</dl>

<p>Currently, AI talent comes at a high cost. Without the right data, it will be futile to hire AI talent; having the right data is a prerequisite for AI teams to deliver well and fast. By this, we don’t mean that we must have all of the prerequisites in place before bringing in AI talent. What we mean is that we must be fully aware of other prerequisites, such as the right data, and have realistic expectations in the absence of it.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="A Good Process"><div class="sect2" id="a_good_process">
<h2>A Good Process</h2>

<p>Another important factor that often leads to the failure of AI projects is not following the right process. In this chapter, we’ve already discussed both the KDD and Microsoft processes. Both of them are great starting points. Here are some other important points to consider when getting started:</p>
<dl>
	<dt>Set up the right metrics<a contenteditable="false" data-type="indexterm" data-primary="metrics" id="idm45969586252552"/></dt> 
		<dd>Most AI projects in industry aim to solve a business problem. In many cases, teams set up AI metrics like precision, recall, etc., as success metrics. But we must also set up the right business metrics along with AI metrics. For example, let’s say we’re building a text classifier to automatically assign customer complaints to the right customer care teams. The right metric for this is the number of times a complaint is reassigned to another team. A classifier that has a 95% F1 score but leads to many complaints being reassigned multiple times is of no use. Another example of this is a chatbot system that correctly detects intent but has high user drop-off rates. User interaction and drop-off rates provide a complete picture that’s missed by using only AI-specific metrics.</dd>
	<dt>Start simple, establish strong baselines<a contenteditable="false" data-type="indexterm" data-primary="baselines" id="idm45969586249720"/></dt> 
		<dd>AI scientists are often influenced by the latest techniques and recent state-of-the-art (SOTA) models<a contenteditable="false" data-type="indexterm" data-primary="state-of-the-art (SOTA) models" id="idm45969586248088"/><a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="state-of-the-art (SOTA) models" id="idm45969586247016"/><a contenteditable="false" data-type="indexterm" data-primary="SOTA (state-of-the-art) models" id="idm45969586245672"/> and apply those in their work straight away. Most SOTA techniques are both compute- and data-intensive, which leads to cost and time overruns. The best way is to start with simple approaches and build strong baselines. Many times, a SOTA technique might only give us marginal improvement over a rule-based system! Try multiple simple approaches first before pondering over complex approaches.</dd>
	<dt>Make it work, make it better</dt> 
		<dd>Building a model is often only 5–10% of most AI projects; the remaining 90% is made up of various steps, ranging from data collection to deployment, testing, maintenance, monitoring, integration, pilot testing, etc. It’s always good to build an acceptable model quickly and complete one full project cycle instead of spending a huge amount of time building an amazing model. This helps all stakeholders realize the value proposition of the project.</dd>
	<dt>Keep shorter turnaround cycles<a contenteditable="false" data-type="indexterm" data-primary="turnaround cycles" id="idm45969586242248"/></dt> 
		<dd>Even when solving a standard problem with well-known approaches, we must still apply them to our dataset to see if they work or not. For example, if we’re building a sentiment analysis system, it’s a well-known fact that Naive Bayes gives very strong baselines. Yet it’s very much possible that for our dataset, Naive Bayes might not give good numbers. Building AI systems involves a lot of experiments to figure what works and what doesn’t. Hence, it’s important to build models quickly and present the results to stakeholders frequently. This helps raise any red flags early and get early feedback.</dd>
</dl>

<p>There are a few other important things to consider, which we’ll cover next.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Other Aspects"><div class="sect2" id="other_aspects">
<h2>Other Aspects</h2>

<p>In addition to the various points we’ve discussed so far, there are some more key points to consider, including compute costs and return on investment. Let’s discuss those now:</p>
<dl>
	<dt>Cost of compute<a contenteditable="false" data-type="indexterm" data-primary="compute costs" id="idm45969586236504"/><a contenteditable="false" data-type="indexterm" data-primary="cost of compute" id="idm45969586235368"/></dt> 
		<dd>Many AI models (especially DL-based models) are compute-intensive. Over time, GPUs on the cloud or physical hardware prove to be considerably expensive. Many organizations are known to spend huge amounts on GPU and other cloud services—so much that they have to create parallel projects to reduce these costs.</dd>
<dt>Blindly following SOTA</dt> 
		<dd>Practitioners are often keen to apply SOTA models in their work. This often proves to be disastrous. For example, Meena<a contenteditable="false" data-type="indexterm" data-primary="Meena system" id="idm45969586232504"/><a contenteditable="false" data-type="indexterm" data-primary="chatbots" id="idm45969586231400"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586230168-marker" href="ch11.xhtml#idm45969586230168">57</a>], a SOTA chatbot system from Google that gave amazing results, took over 2,048 TPU for 30 days for training. That compute time is worth $1.4M. While Meena has shown some very impressive results, imagine using Meena techniques to build a chatbot for automating customer support that saves $1,000 a day. We would need to run the chatbot for over four years just to break even on the training cost.</dd>
<dt>ROI<a contenteditable="false" data-type="indexterm" data-primary="ROI (return on investment)" id="idm45969586227336"/></dt> 
		<dd>AI projects are expensive; various stages, such as data collection, labeling, hiring AI talent, and compute all involve costs. For this reason, it’s important to estimate the gains at the start of the project itself. We must establish the process and clear metrics to measure the returns early on in the project.</dd>
<dt>Full automation<a contenteditable="false" data-type="indexterm" data-primary="automation, full" id="idm45969586225064"/> is hard</dt> 
		<dd>We can never achieve complete automation, at least for any moderately complex AI project—it will continue to require some manual effort. <a data-type="xref" href="#complete_automation_can_be_hard">Figure 11-9</a> represents this in the same S curve we discussed earlier. Levels for complete automation and acceptable performance might change depending on the project, but the broad point will hold true.</dd>
</dl>
<figure><div id="complete_automation_can_be_hard" class="figure">
<img src="Images/pnlp_1109.png" alt="Complete automation can be hard" width="880" height="611"/>
<h6><span class="label">Figure 11-9. </span>Complete automation can be hard</h6>
</div></figure>

<p>We’ve covered some key points in this section, but making AI succeed in business is a vast topic. We suggest a few articles for further reading. While some of them bring out the distinctions between software engineering and AI, others discuss rules of thumb for building AI systems<a contenteditable="false" data-type="indexterm" data-primary="artificial intelligence (AI)" data-secondary="further reading" id="ch11_term38"/>:</p>
<ul>
<li>
	<p>“Why Is Machine Learning ‘Hard'?,” a blog post by S. Zayd Enam<a contenteditable="false" data-type="indexterm" data-primary="Enam, S. Zayd" id="idm45969586216200"/>, a Stanford researcher [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586214888-marker" href="ch11.xhtml#idm45969586214888">58</a>]</p></li>
<li>
	<p>“Software 2.0,” a blog post on AI as a different way of writing software by Andrej Karpathy<a contenteditable="false" data-type="indexterm" data-primary="Karpathy, Andrej" id="idm45969586212024"/>, a well-known researcher, educator, and scientist at Tesla [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586210792-marker" href="ch11.xhtml#idm45969586210792">59</a>]</p></li>
<li>
	<p>“NLP’s Clever Hans Moment Has Arrived,” an article by Benjamin Heinzerling<a contenteditable="false" data-type="indexterm" data-primary="Heinzerling, Benjamin" id="idm45969586208120"/> that argues the validity of SOTA results obtained on certain popular datasets [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586206888-marker" href="ch11.xhtml#idm45969586206888">60</a>]</p></li>
<li>
	<p>“Closing the AI Accountability Gap,” a report by a team at Google AI<a contenteditable="false" data-type="indexterm" data-primary="Google AI" id="idm45969586204072"/> and the nonprofit Partnership on AI<a contenteditable="false" data-type="indexterm" data-primary="Partnership on AI" id="idm45969586202840"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586201608-marker" href="ch11.xhtml#idm45969586201608">61</a>]</p></li>
<li>
	<p>“The Twelve Truths of Machine Learning for the Real World,” a blog post by Delip Rao<a contenteditable="false" data-type="indexterm" data-primary="Rao, Delip" id="idm45969586198984"/>, researcher and O’Reilly author [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586197704-marker" href="ch11.xhtml#idm45969586197704">62</a>]</p></li>
<li>
	<p>“What I’ve Learned Working with 12 Machine Learning Startups,” an article by Daniel Shenfeld<a contenteditable="false" data-type="indexterm" data-primary="Shenfeld, Daniel" id="idm45969586194952"/>, a startup veteran and ML consultant [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586193672-marker" href="ch11.xhtml#idm45969586193672">63</a>]</p></li>
</ul>

<p>These will give you a more holistic picture. <a data-type="xref" href="#life_cycle_of_an_ai_project">Figure 11-10</a> demonstrates what we’ve covered in this section and the chapter.</p>
<figure><div id="life_cycle_of_an_ai_project" class="figure">
<img src="Images/pnlp_1110.png" alt="Life cycle of an AI Project" width="1439" height="850"/>
<h6><span class="label">Figure 11-10. </span>Life cycle of an AI project<a contenteditable="false" data-type="indexterm" data-primary="Natural Language Processing (NLP)" data-secondary="project life cycle" id="idm45969586188328"/></h6>
</div></figure>

<p>Many of these suggestions are not hard rules set in stone; their application will depend on the context of your project, problem, data, and organization. We hope the discussion in this section will help in making your AI endeavors<a contenteditable="false" data-type="indexterm" data-primary="artificial intelligence (AI)" data-secondary="key points and rules of thumb" data-startref="ch11_term33" id="idm45969586186104"/><a contenteditable="false" data-type="indexterm" data-primary="artificial intelligence (AI)" data-secondary="further reading" data-startref="ch11_term38" id="idm45969586184424"/><a contenteditable="false" data-type="indexterm" data-primary="Natural Language Processing (NLP)" data-secondary="end-to-end process" data-startref="ch11_term1" id="idm45969586182760"/> succeed.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Peeking over the Horizon"><div class="sect1" id="peeking_over_the_horizon">
<h1>Peeking over the Horizon</h1>

<p>We’d like to end this chapter and the book with various perspectives of how machine learning<a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="future directions" id="ch11_term39"/> is evolving. ML will continue improving on the cutting edge, and its applications will be more relevant to business in the coming years. One way to look at this is the influential lecture by renowned scientist C.P. Snow<a contenteditable="false" data-type="indexterm" data-primary="Snow, C.P." id="idm45969586176968"/> in 1959, titled <em>The Two Cultures and the Scientific Revolution</em> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586175224-marker" href="ch11.xhtml#idm45969586175224">64</a>]. In this lecture, Snow states that the intellectual world can be seen from two distinct perspectives, which seem to be getting more divided over time. One perspective is of science and technology and the other is concerned with arts and humanities. He argues why it’s important for these two perspectives to have a common core for better advancements of the entire area. This is true for AI as well.</p>

<p>Analogously, in the world of AI<a contenteditable="false" data-type="indexterm" data-primary="artificial intelligence (AI)" data-secondary="perspectives on" id="idm45969586173160"/>, we see a similar set of two distinct perspectives emerging. On one hand, we have the advances made by researchers and scientists working on the forefront. On the other hand, we have businesses trying to leverage AI. This includes everyone from Fortune 500 companies to early stage startups. The world increasingly believes that the successful adoption of AI in industry will stem from an intersection of both.</p>

<p>From the perspective of researchers and scientists, we see two macro trends: building <em>truly intelligent machines</em><a contenteditable="false" data-type="indexterm" data-primary="truly intelligent machines" id="idm45969586170104"/><a contenteditable="false" data-type="indexterm" data-primary="intelligent machines" id="idm45969586169000"/> and applying <em>AI for social good</em><a contenteditable="false" data-type="indexterm" data-primary="artificial intelligence (AI)" data-secondary="for social good" data-secondary-sortas="social good" id="idm45969586167448"/><a contenteditable="false" data-type="indexterm" data-primary="social good" id="idm45969586165784"/><a contenteditable="false" data-type="indexterm" data-primary="good, social" id="idm45969586164680"/>. For instance, François Chollet<a contenteditable="false" data-type="indexterm" data-primary="Chollet, François" id="idm45969586163448"/> of Google has stressed the importance of building better metrics to measure intelligence in “On the Measure of Intelligence” [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586162072-marker" href="ch11.xhtml#idm45969586162072">65</a>]. Most evaluation of AI <a contenteditable="false" data-type="indexterm" data-primary="modeling" data-secondary="evaluation of" id="idm45969586160568"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation" id="idm45969586159224"/>models at present is inherently narrow in nature and measures specific skills as opposed to broad abilities and general intelligence. Chollet proposes certain measures inspired by testing of human intelligence, including efficiencies in new skill acquisition. They introduce a dataset called Abstraction and Reasoning Corpus (ARC)<a contenteditable="false" data-type="indexterm" data-primary="Abstraction and Reasoning Corpus (ARC)  dataset" id="idm45969586157640"/><a contenteditable="false" data-type="indexterm" data-primary="ARC" data-see="Abstraction and Reasoning Corpus" id="idm45969586156440"/> that’s inspired by a classic IQ test: the Raven’s Progressive Matrices [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_11_52-marker" href="ch11.xhtml#footnote_11_52">66</a>]. One such example is presented in <a data-type="xref" href="#example_of_an_arc_task_for_general_inte">Figure 11-11</a>, where the task is for the computer to infer the missing area by looking at the overall input matrix pattern. Work on improving measures of AI is necessary for developing better and more robust AI in the future.</p>


<p>AI and technology in general can be a force for social good. And there are now various initiatives that are working on AI for social good. Wadhwani AI<a contenteditable="false" data-type="indexterm" data-primary="Wadhwani AI" id="idm45969586151624"/> is working on improving maternal and early childhood health with AI [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586150392-marker" href="ch11.xhtml#idm45969586150392">67</a>]. Google AI for Social Good<a contenteditable="false" data-type="indexterm" data-primary="Google AI for Social Good" id="idm45969586148792"/> has a range of initiatives, including applying AI to predict and better manage floods [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586147448-marker" href="ch11.xhtml#idm45969586147448">68</a>]. Similarly, Microsoft<a contenteditable="false" data-type="indexterm" data-primary="Microsoft" data-secondary="AI for social good" id="idm45969586145544"/> is using AI to solve global climate issues, improve accessibility, and preserve cultural heritage [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586143928-marker" href="ch11.xhtml#idm45969586143928">69</a>]. Allen AI<a contenteditable="false" data-type="indexterm" data-primary="Allen AI" id="idm45969586142472"/> has been improving common-sense reasoning in NLP through the WinoGrande dataset<a contenteditable="false" data-type="indexterm" data-primary="WinoGrande dataset" id="idm45969586141240"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586140008-marker" href="ch11.xhtml#idm45969586140008">70</a>]. Such work by foundations and research labs is helping to incorporate the forefront of ML and NLP to improve human well-being.</p>

<figure><div id="example_of_an_arc_task_for_general_inte" class="figure">
<img src="Images/pnlp_1111.png" alt="Example of an ARC task for general intelligence from [_52]" width="1062" height="2096"/>
<h6><span class="label">Figure 11-11. </span><a contenteditable="false" data-type="indexterm" data-primary="AWS" data-see="Amazon Web Services" id="idm45969586136664"/><a contenteditable="false" data-type="indexterm" data-primary="Abstraction and Reasoning Corpus (ARC)  dataset" id="idm45969586135192"/>Example of an ARC task for general intelligence from [<a data-type="noteref" href="ch11.xhtml#footnote_11_52">66</a>]</h6>
</div></figure>

<p>A completely different perspective comes from the world of business. This is more practical and is concerned with business impact and business models. For instance, several consulting firms have conducted surveys across organizations on use cases and effectiveness of AI across industry verticals. McKinsey &amp; Company<a contenteditable="false" data-type="indexterm" data-primary="McKinsey &amp;amp; Company" id="idm45969586131928"/>’s Global AI survey<a contenteditable="false" data-type="indexterm" data-primary="Global AI survey (McKinsey)" id="idm45969586130696"/> is one such example [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586129464-marker" href="ch11.xhtml#idm45969586129464">71</a>]. They discuss how AI has helped different verticals save money by reducing inefficiencies and make more money by expanding the market. They also assess the impact of AI on the workforce and on which parts of organizations it’s most impactful. Another such study is a report by MIT Sloan<a contenteditable="false" data-type="indexterm" data-primary="MIT Sloan" id="idm45969586127192"/> and BCG<a contenteditable="false" data-type="indexterm" data-primary="BCG" id="idm45969586125992"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586124728-marker" href="ch11.xhtml#idm45969586124728">72</a>]. This is immensely useful for business leaders to learn how to onboard and grow AI inside their organizations.</p>

<p>Venture capital (VC) firms<a contenteditable="false" data-type="indexterm" data-primary="venture capital (VC) firms" id="idm45969586123016"/> have been investing heavily in startups building AI-powered businesses. Based on their understanding of how new AI businesses are formed and how they can succeed, they’re compiling reports and debriefs. Andressen Horowitz, a major VC firm, has published a report, “The New Business of AI,” based on their learnings in many AI investments [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969586121352-marker" href="ch11.xhtml#idm45969586121352">73</a>]. The report addresses business issues<a contenteditable="false" data-type="indexterm" data-primary="business issues" id="idm45969586119416"/> that AI startups are facing despite the hype, like lower gross margins and product-scaling challenges. They’ve provided practical advice on building AI businesses that can scale better and be more competitive.</p>

<p>This range of perspectives will be applicable depending on where your organization is in their AI journey. First, when starting a new AI business, lessons from VCs will help you decide what to build. Second, to formulate an AI strategy in a large organization, surveys and reports from industry will align you better. Last but not least, as your organization matures, incorporating SOTA techniques can lead to a step change in your<a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="future directions" data-startref="ch11_term39" id="idm45969586117096"/> products.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Final Words"><div class="sect1" id="final_words">
<h1>Final Words</h1>

<p>And here we come to the end of <em>Practical Natural Language Processing</em>! We hope you’ve learned a few things about NLP tasks and pipelines and their applications in various domains and that these will help you in your day-to-day work. The advances in NLP are just starting to bear big fruits. Some of the most fundamental questions in NLP, like context and common sense, have probably yet to even be asked properly.</p>

<p>True mastery of any skill requires a lifetime of learning, and we hope that our references, research papers, and industry reports will help you continue the journey.</p>
</div></section>
<div data-type="footnotes"><h5>Footnotes</h5></div><div data-type="footnotes"><h5>References</h5><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586925880">[<a href="ch11.xhtml#idm45969586925880-marker">1</a>] <a href="https://onnx.ai">ONNX</a>: An open format built to represent machine learning models. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586919432">[<a href="ch11.xhtml#idm45969586919432-marker">2</a>] <a href="https://oreil.ly/pJRzj">Apache Airflow</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586864696">[<a href="ch11.xhtml#idm45969586864696-marker">3</a>] <a href="https://oreil.ly/TW8xV">Apache Oozie</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586862136">[<a href="ch11.xhtml#idm45969586862136-marker">4</a>] <a href="https://www.chef.io">Chef</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_11_44">[<a href="ch11.xhtml#footnote_11_44-marker">5</a>] Microsoft. <a href="https://oreil.ly/z8SZa">“MLOps examples”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586855000">[<a href="ch11.xhtml#idm45969586855000-marker">6</a>] Microsoft. <a href="https://oreil.ly/mS8vB">MLOps using Azure ML Services and Azure DevOps</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_11_70">[<a href="ch11.xhtml#footnote_11_70-marker">7</a>] Elastic. <a href="https://oreil.ly/35PbS">“Anomaly Detection”</a>.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586839640">[<a href="ch11.xhtml#idm45969586839640-marker">8</a>] Krzus, Matt and and Jason Berkowitz. <a href="https://oreil.ly/oN0jO">“Text Classification with Gluon on Amazon SageMaker and AWS Batch”</a>. <em>AWS Machine Learning Blog</em>, March 20, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586822728">[<a href="ch11.xhtml#idm45969586822728-marker">9</a>] The Pallets Projects. <a href="https://oreil.ly/K6AW-">“Flask”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586820056">[<a href="ch11.xhtml#idm45969586820056-marker">10</a>] <a href="https://oreil.ly/ipNIv">The Falcon Web Framework</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586817528">[<a href="ch11.xhtml#idm45969586817528-marker">11</a>] <a href="https://oreil.ly/jsEyA">Django</a>: The web framework for perfectionists with deadlines. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586814088">[<a href="ch11.xhtml#idm45969586814088-marker">12</a>] <a href="https://www.docker.com">Docker</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586811576">[<a href="ch11.xhtml#idm45969586811576-marker">13</a>] <a href="https://kubernetes.io">Kubernetes</a>: Production-Grade Container Orchestration. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586807352">[<a href="ch11.xhtml#idm45969586807352-marker">14</a>] Amazon. <a href="https://oreil.ly/MCkm-">AWS SageMaker</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586804392">[<a href="ch11.xhtml#idm45969586804392-marker">15</a>] Microsoft. <a href="https://oreil.ly/30cWw">Azure Cognitive Services</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586790184">[<a href="ch11.xhtml#idm45969586790184-marker">16</a>] Sucik, Sam. <a href="https://oreil.ly/_Osgi">“Compressing BERT for Faster Prediction”</a>. <em>Rasa (blog)</em>, August 8, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586784840">[<a href="ch11.xhtml#idm45969586784840-marker">17</a>] <a href="https://oreil.ly/nOSC7">Cheng, Yu, Duo Wang, Pan Zhou, and Tao Zhang</a>. <a href="https://oreil.ly/bbjBw">“A Survey of Model Compression and Acceleration for Deep Neural Networks.”</a>  2017.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586780760">[<a href="ch11.xhtml#idm45969586780760-marker">18</a>] Joulin, Armand, Edouard Grave, Piotr Bojanowski, Matthijs Douze, Hérve Jégou, and Tomas Mikolov. <a href="https://oreil.ly/LEf1y">“FastText.zip: Compressing Text Classification Models”</a>,  2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586777048">[<a href="ch11.xhtml#idm45969586777048-marker">19</a>] Chee, Cedric. <a href="https://oreil.ly/aRYn_">Awesome machine learning model compression research papers, tools, and learning material</a>, (GitHub repo). Last accessed June 15, 2020.<a contenteditable="false" data-type="indexterm" data-primary="model compression" data-startref="ch11_term7" id="idm45969586775512"/></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586772872">[<a href="ch11.xhtml#idm45969586772872-marker">20</a>] Burkov, Andriy. <a href="https://oreil.ly/1xTP6"><em>Machine Learning Engineering</em> (Draft)</a>. 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586741816">[<a href="ch11.xhtml#idm45969586741816-marker">21</a>] Cheng, Heng-Tze. “<a href="https://oreil.ly/FBfSY">Wide &amp; Deep Learning: Better Together with TensorFlow</a>.” <em>Google AI Blog</em>, June 29, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_11_22">[<a href="ch11.xhtml#footnote_11_22-marker">22</a>] Zheng, Alice and Amanda Casari. <em>Feature Engineering for Machine Learning</em>. Boston: O’Reilly, 2018. ISBN: 978-9-35213-711-4</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586715880">[<a href="ch11.xhtml#idm45969586715880-marker">23</a>] <a href="https://dvc.org">DVC</a>: Open source version control system for machine learning projects. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586712232">[<a href="ch11.xhtml#idm45969586712232-marker">24</a>] Gundersen, Odd Erik and Sigbjørn Kjensmo. “State of the Art: Reproducibility in Artificial Intelligence.” <em>The Thirty-Second AAAI Conference on Artificial Intelligence</em> (2018).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586709720">[<a href="ch11.xhtml#idm45969586709720-marker">25</a>] Gibney, E. “This AI Researcher Is Trying to Ward Off a Reproducibility Crisis.” <em>Nature</em> 577.7788 (2020): 14.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_11_48">[<a href="ch11.xhtml#footnote_11_48-marker">26</a>] TensorFlow. <a href="https://oreil.ly/dQWKv">“Getting Started with TensorFlow Model Analysis”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586673944">[<a href="ch11.xhtml#idm45969586673944-marker">27</a>] Marco Tulio Correia Ribeiro. <a href="https://oreil.ly/FynST">Lime: Explaining the predictions of any machine learning classifier</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586671192">[<a href="ch11.xhtml#idm45969586671192-marker">28</a>] Lundberg, Scott. <a href="https://oreil.ly/8saPS">Shap: A game theoretic approach to explain the output of any machine learning model</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586658120">[<a href="ch11.xhtml#idm45969586658120-marker">29</a>] TensorFlow. <a href="https://oreil.ly/DHec0">“Get started with TensorFlow Data Validation”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586652760">[<a href="ch11.xhtml#idm45969586652760-marker">30</a>] Miller, Tim. <a href="https://oreil.ly/drgXS">“Explanation in Artificial Intelligence: Insights from the Social Sciences”</a>, (2017).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586649368">[<a href="ch11.xhtml#idm45969586649368-marker">31</a>] Molnar, Christoph. <a href="https://oreil.ly/EXsY8"><em>Interpretable Machine Learning: A Guide for Making Black Box Models Explainable</em></a>. 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586619384">[<a href="ch11.xhtml#idm45969586619384-marker">32</a>] Sumo Logic. <a href="https://oreil.ly/Izt9N">“Outlier”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586616408">[<a href="ch11.xhtml#idm45969586616408-marker">33</a>] Microsoft. <a href="https://oreil.ly/L9ksb">“Anomaly Detector API Documentation”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586598008">[<a href="ch11.xhtml#idm45969586598008-marker">34</a>] Domingos, Pedro. “A Few Useful Things to Know about Machine Learning.” <em>Communications of the ACM</em> 55.10(2012): 78–87.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586593992">[<a href="ch11.xhtml#idm45969586593992-marker">35</a>] Sculley, D., Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. “Machine Learning: The High Interest Credit Card of Technical Debt.” <em>SE4ML: Software Engineering for Machine Learning</em> (NIPS 2014 Workshop).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586591256">[<a href="ch11.xhtml#idm45969586591256-marker">36</a>] D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, VinayChaudhary, Michael Young, Jean-Francois Crespo, and Dan Dennison. “Hidden Technical Debt in Machine Learning Systems.” <em>Proceedings of the 28th International Conference on Neural Information Processing Systems</em> 2 (2015): 2503–2511.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586583368">[<a href="ch11.xhtml#idm45969586583368-marker">37</a>] McMahan, H. Brendan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie et al. “Ad Click Prediction: A View from the Trenches.” <em>Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (2013): 1222–1230.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586579960">[<a href="ch11.xhtml#idm45969586579960-marker">38</a>] Zinkevich, Martin. <a href="https://oreil.ly/-azsB">“Rules of Machine Learning: Best Practices for ML Engineering”</a>. <em>Google Machine Learning</em>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586575880">[<a href="ch11.xhtml#idm45969586575880-marker">39</a>] Halevy, Alon, Peter Norvig, and Fernando Pereira. “The Unreasonable Effectiveness of Data.” <em>IEEE Intelligent Systems</em> 24.2 (2009): 8–12.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586571832">[<a href="ch11.xhtml#idm45969586571832-marker">40</a>] Sun, Chen, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta. “Revisiting Unreasonable Effectiveness of Data in Deep Learning Era.” <em>Proceedings of the IEEE International Conference on Computer Vision</em> (2017): 843–852.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_11_61">[<a href="ch11.xhtml#footnote_11_61-marker">41</a>] Petrov, Slav. <a href="https://oreil.ly/tuwnp">“Announcing SyntaxNet: The World’s Most Accurate Parser Goes Open Source”</a>. <em>Google AI Blog</em>, May 12, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586556536">[<a href="ch11.xhtml#idm45969586556536-marker">42</a>] Marcus, Mitchell, Beatrice Santorini, and Mary Ann Marcinkiewicz. <a href="https://oreil.ly/yk7V4">“Building a Large Annotated Corpus of English: The Penn Treebank”</a>. <em>Computational Linguistics</em> 19, Number 2, Special Issue on Using Large Corpora: II (June 1993).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586545528">[<a href="ch11.xhtml#idm45969586545528-marker">43</a>] Feurer, Matthias, Aaron Klein, Katharina Eggensperger, Jost Springenberg, Manuel Blum, and Frank Hutter. “Efficient and Robust Automated Machine Learning.” <em>Advances in Neural Information Processing Systems</em> 28 (2015): 2962–2970.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586540872">[<a href="ch11.xhtml#idm45969586540872-marker">44</a>] Le Cun, Yann, Corinna Cortes and Christopher J.C. Burges. <a href="https://oreil.ly/d0fDb">“The MNIST database of handwritten digits”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586441400">[<a href="ch11.xhtml#idm45969586441400-marker">45</a>] Google Cloud. <a href="https://oreil.ly/3Ljr4">“Features and capabilities of AutoML Natural Language”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586439992">[<a href="ch11.xhtml#idm45969586439992-marker">46</a>] Google Cloud. <a href="https://oreil.ly/fq5DQ">“AutoML Translation”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586435640">[<a href="ch11.xhtml#idm45969586435640-marker">47</a>] Microsoft Azure. <a href="https://oreil.ly/yahkz">“What is automated machine learning (AutoML)?”</a>, February 28, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586431256">[<a href="ch11.xhtml#idm45969586431256-marker">48</a>] Thakur, Abhishek and Artus Krohn-Grimberghe. <a href="https://oreil.ly/8iFSU">“AutoCompete: A Framework for Machine Learning Competition”</a>, (2015).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586429432">[<a href="ch11.xhtml#idm45969586429432-marker">49</a>] Thakur, Abhishek. <a href="https://oreil.ly/ksGdV">“Approaching (Almost) Any NLP Problem on Kaggle”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_11_5">[<a href="ch11.xhtml#footnote_11_5-marker">50</a>] Fayyad, Usama, Gregory Piatetsky-Shapiro, and Padhraic Smyth. “The KDD Process for Extracting Useful Knowledge from Volumes of Data.” <em>Communications of the ACM</em> 39.11 (1996): 27–34.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_11_6">[<a href="ch11.xhtml#footnote_11_6-marker">51</a>] Microsoft Azure. <a href="https://oreil.ly/N6hzM">“What is the Team Data Science Process?”</a>, January 10, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586328872">[<a href="ch11.xhtml#idm45969586328872-marker">52</a>] Microsoft. <a href="https://oreil.ly/R8c7d">“Team Data Science Process Documentation”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586307080">[<a href="ch11.xhtml#idm45969586307080-marker">53</a>] Kidd, Chrissy. <a href="https://oreil.ly/28IOn">“Why Does Gartner Predict up to 85% of AI Projects Will ‘Not Deliver’ for CIOs?”</a>, <em>BMC Machine Learning &amp; Big Data Blog</em>, December 18, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586282904">[<a href="ch11.xhtml#idm45969586282904-marker">54</a>] Google AI. <a href="https://oreil.ly/aAicm">“Responsible AI Practices”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586281208">[<a href="ch11.xhtml#idm45969586281208-marker">55</a>] Microsoft. <a href="https://oreil.ly/rL2Oh">“Microsoft AI principles”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586257784">[<a href="ch11.xhtml#idm45969586257784-marker">56</a>] Artstein, Ron and Massimo Poesio. “Inter-Coder Agreement for Computational Linguistics.” <em>Computational Linguistics</em> 34.4 (2008): 555–596.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586230168">[<a href="ch11.xhtml#idm45969586230168-marker">57</a>] Adiwardana, Daniel and Thang Luong. <a href="https://oreil.ly/k7Cac">“Towards a Conversational Agent that Can Chat About…Anything”</a>. <em>Google AI Blog</em>, January 28, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586214888">[<a href="ch11.xhtml#idm45969586214888-marker">58</a>] Enam, S. Zayd. <a href="https://oreil.ly/ZcJ6c">“Why is Machine Learning ‘Hard’?”</a>, <em>Zayd’s Blog</em>, November 10, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586210792">[<a href="ch11.xhtml#idm45969586210792-marker">59</a>] Karpathy, Andrej. <a href="https://oreil.ly/XgkWP">“Software 2.0”</a>. <em>Medium Programming</em>, November 11, 2017.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586206888">[<a href="ch11.xhtml#idm45969586206888-marker">60</a>] Heinzerling, Benjamin. <a href="https://oreil.ly/oPIA2">“NLP’s Clever Hans Moment has Arrived”</a>. <em>The Gradient</em>, August 26, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586201608">[<a href="ch11.xhtml#idm45969586201608-marker">61</a>] Raji, Inioluwa Deborah, Andrew Smart, Rebecca N. White, Margaret Mitchell, Timnit Gebru, Ben Hutchinson, Jamila Smith-Loud, Daniel Theron, and Parker Barnes. <a href="https://oreil.ly/x7SJR">“Closing the AI Accountability Gap: Defining an End-to-End Framework for Internal Algorithmic Auditing”</a>, (2020).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586197704">[<a href="ch11.xhtml#idm45969586197704-marker">62</a>] Rao, Delip. <a href="https://oreil.ly/3oDtV">“The Twelve Truths of Machine Learning for the Real World”</a>. <em>Delip Rao (blog)</em>, December 25, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586193672">[<a href="ch11.xhtml#idm45969586193672-marker">63</a>] Shenfeld, David. <a href="https://oreil.ly/dRjPD">“What I’ve Learned Working with 12 Machine Learning Startups”</a>. <em>Towards Data Science (blog)</em>, May 6, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586175224">[<a href="ch11.xhtml#idm45969586175224-marker">64</a>] Snow, Charles Percy. <em>The Two Cultures and the Scientific Revolution</em>. Connecticut: Martino Fine Books, 2013.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586162072">[<a href="ch11.xhtml#idm45969586162072-marker">65</a>] Chollet, François. <a href="https://oreil.ly/XvV8v">“On The Measure of Intelligence”</a>, (2019).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_11_52">[<a href="ch11.xhtml#footnote_11_52-marker">66</a>] John, Raven J. “Raven Progressive Matrices,” in <em>Handbook of Nonverbal Assessment</em>, Boston: Springer, 2003.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586150392">[<a href="ch11.xhtml#idm45969586150392-marker">67</a>] Wadhwani AI. <a href="https://oreil.ly/zL2BL">“Maternal, Newborn, and Child Health”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586147448">[<a href="ch11.xhtml#idm45969586147448-marker">68</a>] Matias, Yossi. <a href="https://oreil.ly/qTp5L">“Keeping People Safe with AI-Enabled Flood Forecasting”</a>. <em>Google The Keyword (blog)</em>, September 24, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586143928">[<a href="ch11.xhtml#idm45969586143928-marker">69</a>] Microsoft. <a href="https://oreil.ly/XtOAD">“AI for Good”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586140008">[<a href="ch11.xhtml#idm45969586140008-marker">70</a>] Sakaguchi, Keisuke, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. <a href="https://oreil.ly/0_VLH">“WinoGrande: An Adversarial Winograd Schema Challenge at Scale”</a>, (2019).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586129464">[<a href="ch11.xhtml#idm45969586129464-marker">71</a>] Cam, Arif, Michael Chui, and Bryce Hall. <a href="https://oreil.ly/U61yX">“Global AI Survey: AI Proves Its Worth, but Few Scale Impact”</a>. <em>McKinsey &amp; Company Featured Insights</em>, November 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586124728">[<a href="ch11.xhtml#idm45969586124728-marker">72</a>] Ransbotham, Sam, Philipp Gerbert, Martin Reeves, David Kiron, and Michael Spira. “Artificial Intelligence in Business Gets Real<em>.” MIT Sloan Management Review</em> (September 2018). </p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969586121352">[<a href="ch11.xhtml#idm45969586121352-marker">73</a>] Casado, Martin and Matt Bornstein. <a href="https://oreil.ly/MMHTt">“The New Business of AI (and How It’s Different From Traditional Software)”</a>. <em>Andreesen Horowitz</em>, February 16, 2020.</p></div></div></section></div>



  </body>
</html>