<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<link href="Styles/Style00.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style01.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style02.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style03.css" rel="stylesheet" type="text/css" />
<style type="text/css" title="ibis-book">
    @charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0 !important}#sbo-rt-content div.preface p.byline+p.byline{margin:0 !important}#sbo-rt-content div.sect1&gt;p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1&gt;p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]&gt;div&gt;h1,#sbo-rt-content section[data-type="preface"]&gt;div&gt;h1,#sbo-rt-content section[data-type="appendix"]&gt;div&gt;h1,#sbo-rt-content section[data-type="glossary"]&gt;div&gt;h1,#sbo-rt-content section[data-type="bibliography"]&gt;div&gt;h1,#sbo-rt-content section[data-type="index"]&gt;div&gt;h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px auto !important;page-break-inside:avoid}#sbo-rt-content div.figure h6,#sbo-rt-content figure h6,#sbo-rt-content figure figcaption{font-size:.9rem !important;text-align:center;font-weight:normal !important;font-style:italic;font-family:serif !important;text-transform:none !important;letter-spacing:normal !important;color:#000;padding-top:.25em !important;margin-top:0 !important;page-break-before:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]&gt;div&gt;h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]&gt;div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:2em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content p[data-type="footnote"]{font-size:90% !important;line-height:1.2em !important;margin-left:2.5em !important;text-indent:-2.3em !important}#sbo-rt-content p[data-type="footnote"] sup{display:inline-block !important;position:static !important;width:2em !important;text-align:right !important;font-size:100% !important;padding-right:.5em !important}#sbo-rt-content p[data-type="footnote"] a[href$="-marker"]{font-family:sans-serif !important;font-size:90% !important;color:#8e0012 !important}#sbo-rt-content p[data-type="footnote"] a[data-type="xref"]{margin:0 !important;padding:0 !important;text-indent:0 !important}#sbo-rt-content a[data-type="noteref"]{font-family:sans-serif !important;color:#8e0012;margin-left:0;padding-left:0}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dl{margin-bottom:1.5em !important}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important;line-height:1.25rem;font-style:italic}#sbo-rt-content dd{margin:10px 0 .25em 1.5em !important;line-height:1.65em !important}#sbo-rt-content dd p{padding:0 !important;margin:0 0 10px !important}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul&gt;li,#sbo-rt-content ol ul,#sbo-rt-content ol ul&gt;li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul&gt;li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul&gt;li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul&gt;li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol&gt;li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol&gt;li,#sbo-rt-content ul ol,#sbo-rt-content ul ol&gt;li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol&gt;li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol&gt;li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol&gt;li&gt;ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol&gt;li&gt;ol&gt;li&gt;ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div[data-type="tip"] figure h6,#sbo-rt-content div[data-type="note"] figure h6,#sbo-rt-content div[data-type="warning"] figure h6,#sbo-rt-content div[data-type="caution"] figure h6,#sbo-rt-content div[data-type="important"] figure h6{font-family:serif !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content table li{margin:10px 0 0 .25em !important}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:top;font-size:80%}#sbo-rt-content th{vertical-align:bottom}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller;word-break:break-all}#sbo-rt-content table.border tbody&gt;tr:last-child&gt;td{border-bottom:transparent}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content div[data-type="equation"] math{font-size:calc(.35em + 1vw)}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index h3{padding:.25em;margin-top:1em !important;background-color:#F0F0F0}#sbo-rt-content div.index li{line-height:130%;list-style-type:none}#sbo-rt-content div.index a.indexterm{color:#8e0012 !important}#sbo-rt-content div.index ul{margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.index ul ul{margin-left:2em !important;margin-top:0 !important}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content pre.break-code,#sbo-rt-content code.break-code,#sbo-rt-content .break-code pre,#sbo-rt-content .break-code code{word-break:break-all}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content .width-10,#sbo-rt-content figure.width-10 img{width:10% !important}#sbo-rt-content .width-20,#sbo-rt-content figure.width-20 img{width:20% !important}#sbo-rt-content .width-30,#sbo-rt-content figure.width-30 img{width:30% !important}#sbo-rt-content .width-40,#sbo-rt-content figure.width-40 img{width:40% !important}#sbo-rt-content .width-50,#sbo-rt-content figure.width-50 img{width:50% !important}#sbo-rt-content .width-60,#sbo-rt-content figure.width-60 img{width:60% !important}#sbo-rt-content .width-70,#sbo-rt-content figure.width-70 img{width:70% !important}#sbo-rt-content .width-80,#sbo-rt-content figure.width-80 img{width:80% !important}#sbo-rt-content .width-90,#sbo-rt-content figure.width-90 img{width:90% !important}#sbo-rt-content .width-full,#sbo-rt-content .width-100{width:100% !important}#sbo-rt-content .sc{text-transform:none !important}#sbo-rt-content .right{float:none !important}#sbo-rt-content a.totri-footnote{padding:0 !important}#sbo-rt-content figure.width-10,#sbo-rt-content figure.width-20,#sbo-rt-content figure.width-30,#sbo-rt-content figure.width-40,#sbo-rt-content figure.width-50,#sbo-rt-content figure.width-60,#sbo-rt-content figure.width-70,#sbo-rt-content figure.width-80,#sbo-rt-content figure.width-90{width:auto !important}#sbo-rt-content p img,#sbo-rt-content pre img{width:1.25em;line-height:1em;margin:0 .15em -.2em}#sbo-rt-content figure.no-frame div.border-box{border:none}#sbo-rt-content .right{text-align:right !important}
    </style>
<style type="text/css" id="font-styles">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }</style>
<style type="text/css" id="font-family">#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }</style>
<style type="text/css" id="column-width">#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }</style>

<style type="text/css">body{margin:1em;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}body{background-color:transparent!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style></head>
<body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 5. Information Extraction"><div class="chapter" id="information_extraction">
<h1><span class="label">Chapter 5. </span>Information Extraction</h1>

<blockquote class="right">
<p class="right"><em>What’s in a name? A rose</em><br/> <em>by any other name would smell as sweet.</em></p>
<p data-type="attribution" style="text-align:right"><em>William Shakespeare</em></p>
</blockquote>

<p><a contenteditable="false" data-primary="Shakespeare, William" data-type="indexterm" id="idm45969598016600"/><a contenteditable="false" data-primary="information extraction (IE)" data-type="indexterm" id="ch05_term1"/><a contenteditable="false" data-primary="IE" data-see="information extraction" data-type="indexterm" id="idm45969598014056"/>We deal with a lot of textual content every day, be it short messages on the phone or daily emails or longer texts we read for fun or at work or to catch up on current affairs. Such text documents are a rich source of information for us. Depending on the context, “information<a contenteditable="false" data-primary="information" data-type="indexterm" id="idm45969598012264"/>” can mean multiple things, such as key events, people, or relationships between people, places, or organizations, etc. Information extraction (IE) refers to the NLP task of extracting relevant information from text documents. An example of IE put to use in real-world applications are the short blurbs we see to the right when we search for a popular figure’s name on Google.</p>

<p>When compared to structured information sources like databases or tables or semi-structured sources such as webpages (which have some markup), text is a form of unstructured data. For example, in a database, we know where to look for something based on its schema. However, to a large extent, text documents typically comprise free-flowing text without a set schema. This makes IE a challenging problem. Texts may contain various kinds of information. In most cases, extracting information that has a fixed pattern (e.g., addresses, phone numbers, dates, etc.) is relatively straightforward using pattern-based extraction techniques like regular expressions, even though the text itself is considered unstructured data. However, extracting other information (e.g., names of people, relations between different entities in the text, details for a calendar event, etc.) may require more advanced language processing.</p>

<p>In this chapter, we’ll discuss various IE tasks and the methods for implementing them for our applications. We’ll start with a brief historical background, followed by an overview of different IE tasks and applications of IE in the real world. We’ll then introduce the typical NLP processing pipeline for solving any IE task and move on to discuss how to solve specific IE tasks—key phrase extraction, named entity recognition, named entity disambiguation and linking, and relationship extraction—along with some practical advice on implementing them in your projects. We’ll then present a case study of how IE is used in a real-world scenario and briefly cover other advanced IE tasks. With this introduction, let’s explore IE, starting with a brief <span class="keep-together">history.</span></p>

<p><a contenteditable="false" data-primary="information extraction (IE)" data-secondary="historical background" data-type="indexterm" id="idm45969598007240"/>Approaches for extracting different kinds of information from documents like scientific papers and medical reports have been proposed in the past in the research community. However, Message Understanding Conferences<a contenteditable="false" data-primary="Message Understanding Conferences (US Navy)" data-type="indexterm" id="idm45969598005320"/><a contenteditable="false" data-primary="US Navy Message Understanding Conferences" data-type="indexterm" id="idm45969598004120"/> organized by the US Navy (1987–1998) [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969598002856-marker" href="ch05.xhtml#idm45969598002856">1</a>] can be considered the starting point for modern-day research on information extraction from text. This was followed by the Automatic Content Extraction Program<a contenteditable="false" data-primary="Automatic Content Extraction Program" data-type="indexterm" id="idm45969598001224"/> (1999–2008) [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597999992-marker" href="ch05.xhtml#idm45969597999992">2</a>] and the Text Analysis Conference<a contenteditable="false" data-primary="Text Analysis Conference (NIST)" data-type="indexterm" id="idm45969597998488"/><a contenteditable="false" data-primary="NIST Text Analysis Conference" data-type="indexterm" id="idm45969597997352"/> (2009–2018) series organized by NIST [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597996040-marker" href="ch05.xhtml#idm45969597996040">3</a>], which introduced competitions for extracting different kinds of information from text, from recognizing names of different entities to constructing large, queryable knowledge bases. Existing libraries and methods for extracting various forms of information from text and their use in real-world applications trace their origins back to the research that started in these conference series. Before we start looking at what the methods and libraries for IE are, let’s first take a look at some examples of where IE is used in real-world applications.</p>

<section data-type="sect1" data-pdf-bookmark="IE Applications"><div class="sect1" id="ie_applications">
<h1>IE Applications</h1>

<p><a contenteditable="false" data-primary="information extraction (IE)" data-secondary="real-world applications" data-type="indexterm" id="ch05_term2"/>IE is used in a wide range of real-world applications, from news articles, to social media, and even receipts. Here, we’ll cover the details of a few of them:</p>

<dl>
	<dt><a contenteditable="false" data-primary="news: tagging" data-type="indexterm" id="idm45969597989640"/>Tagging news and other content</dt>
		<dd><p>There’s a lot of text generated about various events happening around the world every day. In addition to classifying text using methods discussed in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>, it’s useful for some applications, such as search engines and recommendation systems, if such texts are tagged with important entities mentioned within them. For example, look at <a data-type="xref" href="#screenshot_from_the_google_news_homepag">Figure 5-1</a>, which shows a screenshot from the Google News [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597985352-marker" href="ch05.xhtml#idm45969597985352">4</a>] homepage.</p>

		<p>People (e.g., Jean Vanier), organizations (e.g., Progressive Conservative Party of Ontario), locations (e.g., Canada), and events (e.g., Brexit) currently in the news are extracted and shown to the reader so that they can go directly to news about a specific entity. This is one example of information extraction at work in a popular application.</p>
		
		<figure><div id="screenshot_from_the_google_news_homepag" class="figure"><img alt="Screenshot from the Google News homepage" src="Images/pnlp_0501.png" width="375" height="276"/>
		<h6><span class="label">Figure 5-1. </span>Screenshot from the Google News<a contenteditable="false" data-primary="Google News" data-type="indexterm" id="idm45969597981512"/> homepage</h6>
		</div></figure>
		
	</dd>
	<dt>Chatbots<a contenteditable="false" data-primary="chatbots" data-type="indexterm" id="idm45969597979576"/></dt>
		<dd><p>A chatbot needs to understand the user’s question in order to generate/retrieve a correct response. For example, consider the question, “What are the best cafes around the Eiffel Tower?” The chatbot needs to understand that “Eiffel Tower” and “cafe” are locations, then identify cafes within a certain distance of the Eiffel Tower. IE is useful in extracting such specific information from a pool of available data. We’ll discuss more on chatbots in <a data-type="xref" href="ch06.xhtml#chatbots">Chapter 6</a>.</p>
	</dd>
	<dt>Applications in social media<a contenteditable="false" data-primary="social media" data-secondary="information extraction from" data-type="indexterm" id="idm45969597975800"/></dt>
		<dd><p>A lot of information is disseminated through social media channels like Twitter. Extracting informative excerpts from social media text may help in decision making. An example use case is extracting time-sensitive, frequently updated information, such as traffic updates and disaster relief efforts, based on tweets. NLP for Twitter is one of the most useful applications that utilizes the abundant information present in social media. We’ll touch on some of these applications in <a data-type="xref" href="ch08.xhtml#social_media">Chapter 8</a>.</p>
	</dd>
	<dt>Extracting data<a contenteditable="false" data-primary="data extraction" data-see="information extraction" data-type="indexterm" id="idm45969597971752"/> from forms<a contenteditable="false" data-primary="forms: data extraction from" data-type="indexterm" id="idm45969597970216"/> and receipts<a contenteditable="false" data-primary="receipts: data extraction from" data-type="indexterm" id="idm45969597968936"/></dt>
		<dd><p>Many banking apps nowadays have the feature to scan a check and deposit the money directly into the user’s account. Whether you’re an individual, small business, or larger business enterprise, it’s not uncommon to use apps that scan bills and receipts. Along with <a contenteditable="false" data-primary="OCR (optical character recognition)" data-type="indexterm" id="idm45969597966920"/><a contenteditable="false" data-primary="optical character recognition (OCR)" data-type="indexterm" id="idm45969597965800"/>optical character recognition (OCR), information extraction techniques play an important role in these apps [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597964424-marker" href="ch05.xhtml#idm45969597964424">5</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597962504-marker" href="ch05.xhtml#idm45969597962504">6</a>]. We won’t discuss this aspect in this chapter, as OCR is the primary step in such applications and isn’t part of the processing pipelines in this book.</p>
	</dd>
</dl>

<p>Now that we have an idea of what IE is and where it’s useful, let’s move on to understanding what the different tasks covered under IE are.<a contenteditable="false" data-primary="information extraction (IE)" data-secondary="real-world applications" data-startref="ch05_term2" data-type="indexterm" id="idm45969597960376"/></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="IE Tasks"><div class="sect1" id="ie_tasks">
<h1>IE Tasks</h1>

<p><a contenteditable="false" data-primary="information extraction (IE)" data-secondary="tasks" data-type="indexterm" id="ch05_term3"/>IE is a term that’s used to refer to a range of different tasks of varying complexity. The overarching goal of IE is to extract “knowledge” from text, and each of these tasks provides different information to do that. To understand what these tasks are, consider the snippet from a <em>New York Times</em> article shown in <a data-type="xref" href="#a_new_york_times_article_from_april_30c">Figure 5-2</a>.</p>

<figure><div id="a_new_york_times_article_from_april_30c" class="figure"><img alt="A New York Times article from April 30, 2019 [_48]" src="Images/pnlp_0502.png" width="562" height="416"/>
<h6><span class="label">Figure 5-2. </span>A New York Times article from April 30, 2019 [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597951656-marker" href="ch05.xhtml#idm45969597951656">7</a>]</h6>
</div></figure>

<p>As human readers, we find several useful pieces of information in this blurb. For example, we know that the article is about Apple, the company (and not the fruit), and that it mentions a person, Luca Maestri, who is the finance chief of the company. The article is about the buyback of stock and other issues related to it. For a machine to understand all this involves different levels of IE.</p>

<p>Identifying that the article is about “buyback” or “stock price” relates to the IE task of <em>keyword</em><a contenteditable="false" data-primary="keyword extraction" data-type="indexterm" id="idm45969597947704"/> or <em>keyphrase extraction (KPE)</em><a contenteditable="false" data-primary="keyphrase extraction (KPE)" data-type="indexterm" id="idm45969597946152"/>. Identifying Apple as an organization and Luca Maestri as a person comes under the IE task of <em>named entity recognition (NER)</em><a contenteditable="false" data-primary="named entity recognition (NER)" data-type="indexterm" id="idm45969597944536"/>. Recognizing that Apple is not a fruit, but a company, and that it refers to Apple, Inc. and not some other company with the word “apple” in its name is the IE task of <em>named entity disambiguation and linking</em><a contenteditable="false" data-primary="named entity disambiguation and linking" data-type="indexterm" id="idm45969597942792"/>. Extracting the information that Luca Maestri is the finance chief of Apple refers to the IE task of <em>relation extraction</em><a contenteditable="false" data-primary="relation extraction" data-see="relationship extraction" data-type="indexterm" id="idm45969597941128"/><a contenteditable="false" data-primary="relationship extraction (RE)" data-type="indexterm" id="idm45969597939752"/>.</p>

<p>There are a few advanced IE tasks beyond those mentioned above. Identifying that this article is about a single event (let’s call it “Apple buys back stocks”) and being able to link it to other articles talking about the same event over time refers to the IE task of <em>event extraction</em><a contenteditable="false" data-primary="event extraction" data-type="indexterm" id="idm45969597937640"/>. A related task is <em>temporal information extraction<a contenteditable="false" data-primary="temporal information extraction" data-type="indexterm" id="idm45969597936088"/><a contenteditable="false" data-primary="information extraction (IE)" data-secondary="temporal" data-type="indexterm" id="idm45969597934920"/></em>, which aims to extract information about times and dates, which is also useful for developing calendar applications and interactive personal assistants. Finally, many applications, such as automatically generating weather reports or flight announcements, follow a standard template with some slots that need to be filled based on extracted data. This IE task is known as <em>template filling</em><a contenteditable="false" data-primary="template filling" data-type="indexterm" id="idm45969597932760"/>.</p>

<p>Each of these tasks requires different levels of language processing. A range of rule-based methods as well as supervised, unsupervised, and semi-supervised machine learning (including state-of-the-art deep learning approaches) can be used for developing solutions to solve these tasks. However, considering that IE is very much dependent on the application domain (e.g., finance, news, airlines, etc.), IE in industry is generally implemented as a hybrid system incorporating rule-based and learning-based approaches [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597930520-marker" href="ch05.xhtml#idm45969597930520">8</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597929336-marker" href="ch05.xhtml#idm45969597929336">9</a>]. IE is still a very active area of research, and not all these tasks are considered “solved” or matured enough to have standard approaches that can be used in real-world application scenarios. Tasks such as KPE and NER are more widely studied than others and have some tried-and-tested solutions. The rest of the tasks are relatively more challenging, and it’s more common to rely on pay-as-you-use services from large providers like Microsoft, Google, and IBM.</p>

<p>An important point to note regarding IE is that the datasets needed to train IE models are typically more specialized than what we saw, for example, in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>, where all we needed to get started was a collection of texts mapped to some categories. Hence, real-world use cases of IE may not always require us to train models from scratch, and we can make use of external APIs for some tasks. Before moving on to specific tasks, let’s first take a look at the general NLP pipeline for any IE task.<a contenteditable="false" data-primary="information extraction (IE)" data-secondary="tasks" data-startref="ch05_term3" data-type="indexterm" id="idm45969597925704"/></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="The General Pipeline for IE"><div class="sect1" id="the_general_pipeline_for_ie">
<h1>The General Pipeline for IE</h1>

<p><a contenteditable="false" data-primary="information extraction (IE)" data-secondary="general pipeline" data-type="indexterm" id="ch05_term4"/>The general pipeline for IE requires more fine-grained NLP processing than what we saw for text classification (<a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>). For example, to identify named entities (persons, organizations, etc.), we would need to know the part-of-speech tags of words. For relating multiple references to the same entity (e.g., Albert Einstein, Einstein, the scientist, he, etc.), we would need coreference resolution. Note that none of these are mandatory steps for building a text classification system. Thus, IE is a task that is more NLP intensive than text classification. <a data-type="xref" href="#ie_pipeline_illustrating_nlp_processing">Figure 5-3</a> shows a typical NLP pipeline for IE tasks. Not all steps in the pipeline are necessary for all IE tasks, and the figure demonstrates which IE tasks require what levels of analysis.</p>



<p>We discussed the details of the different processing steps illustrated in this figure in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch01.xhtml#nlp_a_primer">1</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch02.xhtml#nlp_pipeline">2</a>. As the figure shows, key phrase extraction is the task requiring minimal NLP processing (some algorithms also do POS tagging before extracting keyphrases), whereas, other than named entity recognition, all the other IE tasks require deeper NLP pre-processing followed by models developed for those specific tasks. IE tasks are typically evaluated in terms of precision, recall, and F1 scores using standard evaluation sets. Considering the different levels of NLP pre-processing required, IE tasks are also affected by the accuracy of these processing steps themselves. Collecting relevant training data and training our own models for IE, if necessary, should take all these aspects into account. With this background, let’s now start looking at each of the IE tasks, one<a contenteditable="false" data-primary="information extraction (IE)" data-secondary="general pipeline" data-startref="ch05_term4" data-type="indexterm" id="idm45969597913848"/> by one.</p>

<figure><div id="ie_pipeline_illustrating_nlp_processing" class="figure"><img alt="IE Pipeline illustrating NLP processing needed for some IE tasks" src="Images/pnlp_0503.png" width="1205" height="1139"/>
<h6><span class="label">Figure 5-3. </span>IE pipeline illustrating NLP processing needed for some IE tasks</h6>
</div></figure>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Keyphrase Extraction"><div class="sect1" id="keyphrase_extraction">
<h1>Keyphrase Extraction</h1>

<p><a contenteditable="false" data-primary="keyphrase extraction (KPE)" data-type="indexterm" id="ch05_term5"/>Consider<a contenteditable="false" data-primary="information extraction (IE)" data-secondary="typical pipeline" data-type="indexterm" id="idm45969597906664"/> a scenario where we want to buy a product, which has a hundred reviews, on Amazon<a contenteditable="false" data-primary="Amazon" data-secondary="“Reviews that mention” filter" data-secondary-sortas="Reviews that mention" data-type="indexterm" id="idm45969597905112"/>. There’s no way we’re going to read all of them to get an idea of what users think about the product. To facilitate this, Amazon has a filtering feature: “Read reviews that mention.” This presents a bunch of keywords or phrases that several people used in these reviews to filter the reviews, as shown in <a data-type="xref" href="#quotation_markreviews_that_mentionquota">Figure 5-4</a>. This is a good example of where KPE can be useful in an application we all use.</p>



<p>Keyword and phrase extraction, as the name indicates, is the IE task concerned <span class="keep-together">with extracting</span> important words and phrases that capture the gist of the text from a given text document. It’s useful for several downstream NLP tasks, such as <span class="keep-together">search/information</span> retrieval, automatic document tagging, recommendation systems, text summarization, etc.</p>

<figure><div id="quotation_markreviews_that_mentionquota" class="figure"><img alt="“Reviews that mention” on Amazon.ca" src="Images/pnlp_0504.png" width="623" height="187"/>
<h6><span class="label">Figure 5-4. </span>“Read reviews that mention” on Amazon.ca</h6>
</div></figure>

<p>KPE is a well-studied problem in the NLP community, and the two most commonly used methods to solve it are supervised learning and unsupervised learning. Supervised learning approaches require corpora with texts and their respective keyphrases and use engineered features or DL techniques [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597897080-marker" href="ch05.xhtml#idm45969597897080">10</a>]. Creating such labeled datasets for KPE is a time- and cost-intensive endeavor. Hence, unsupervised approaches that do not require a labeled dataset and are largely domain agnostic are more popular for KPE. These approaches are also more commonly used in real-world KPE applications. Recent research has also shown that state-of-the-art DL methods for KPE don’t perform any better than unsupervised approaches [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597895320-marker" href="ch05.xhtml#idm45969597895320">11</a>].</p>

<p>All the popular unsupervised KPE algorithms are based on the idea of representing the words and phrases in a text as nodes in a weighted graph where the weight indicates the importance of that keyphrase. Keyphrases are then identified based on how connected they are with the rest of the graph. The top-N important nodes from the graph are then returned as keyphrases. Important nodes are those words and phrases that are frequent enough and also well connected to different parts of the text. The different graph-based KPE approaches differ in the way they select potential words/phrases from the text (from a large set of possible words and phrases in the entire text) and the way these words/phrases are scored in the graph.</p>

<p>There’s a huge body of work on this topic, with some working implementations available. In most cases, existing approaches are a great starting point to meet your requirements. How can we use these to implement a keyphrase extractor in our project? Let ‘s look at an example.</p>

<section data-type="sect2" data-pdf-bookmark="Implementing KPE"><div class="sect2" id="implementing_kpe">
<h2>Implementing KPE</h2>

<p>The Python library textacy<a contenteditable="false" data-primary="textacy" data-type="indexterm" id="idm45969597889928"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597888696-marker" href="ch05.xhtml#idm45969597888696">12</a>], built on top of the well-known library spaCy [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597887064-marker" href="ch05.xhtml#idm45969597887064">13</a>], contains implementations for some of the common graph-based keyword and phrase extraction algorithms. The notebook associated with this section (<em>Ch5/KPE.ipynb</em>) illustrates the use of textacy to extract keyphrases using two algorithms, TextRank [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597885048-marker" href="ch05.xhtml#idm45969597885048">14</a>] and SGRank. We’ll use a text file that talks about the history of NLP as our test document. The code snippet below illustrates KPE with textacy:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">textacy</code> <code class="kn">import</code> <code class="o">*</code>
<code class="kn">import</code> <code class="nn">textacy.ke</code>

<code class="n">mytext</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="err">“</code><code class="n">nlphistory</code><code class="o">.</code><code class="n">txt</code><code class="err">”</code><code class="p">)</code><code class="o">.</code><code class="n">read</code><code class="p">()</code>
<code class="n">en</code> <code class="o">=</code> <code class="n">textacy</code><code class="o">.</code><code class="n">load_spacy_lang</code><code class="p">(</code><code class="s2">"en_core_web_sm"</code><code class="p">,</code> <code class="n">disable</code><code class="o">=</code><code class="p">(</code><code class="s2">"parser"</code><code class="p">,))</code>
<code class="n">doc</code> <code class="o">=</code> <code class="n">textacy</code><code class="o">.</code><code class="n">make_spacy_doc</code><code class="p">(</code><code class="n">mytext</code><code class="p">,</code> <code class="n">lang</code><code class="o">=</code><code class="n">en</code><code class="p">)</code>

<code class="k">print</code><code class="p">(</code><code class="s2">"Textrank output: "</code><code class="p">,</code> <code class="p">[</code><code class="n">kps</code> <code class="k">for</code> <code class="n">kps</code><code class="p">,</code> <code class="n">weights</code> <code class="ow">in</code> 
<code class="n">textacy</code><code class="o">.</code><code class="n">ke</code><code class="o">.</code><code class="n">textrank</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">normalize</code><code class="o">=</code><code class="s2">"lemma"</code><code class="p">,</code>  <code class="n">topn</code><code class="o">=</code><code class="mi">5</code><code class="p">)])</code>

<code class="k">print</code><code class="p">(</code><code class="s2">"SGRank output: "</code><code class="p">,</code> <code class="p">[</code><code class="n">kps</code> <code class="k">for</code> <code class="n">kps</code><code class="p">,</code> <code class="n">weights</code> <code class="ow">in</code> 
<code class="n">textacy</code><code class="o">.</code><code class="n">ke</code><code class="o">.</code><code class="n">sgrank</code><code class="p">(</code><code class="n">mydoc</code><code class="p">,</code> <code class="n">n_keyterms</code><code class="o">=</code><code class="mi">5</code><code class="p">)])</code>

<code class="n">Output</code><code class="p">:</code> 
<code class="n">Textrank</code> <code class="n">output</code><code class="p">:</code>  <code class="p">[</code><code class="s1">'successful natural language processing system'</code><code class="p">,</code> 
<code class="s1">'statistical machine translation system'</code><code class="p">,</code> <code class="s1">'natural language system'</code><code class="p">,</code> 
<code class="s1">'statistical natural language processing'</code><code class="p">,</code> <code class="s1">'natural language task'</code><code class="p">]</code>

<code class="n">SGRank</code> <code class="n">output</code><code class="p">:</code>  <code class="p">[</code><code class="s1">'natural language processing system'</code><code class="p">,</code> 
<code class="s1">'statistical machine translation'</code><code class="p">,</code> <code class="s1">'research'</code><code class="p">,</code> <code class="s1">'late 1980'</code><code class="p">,</code> <code class="s1">'early'</code><code class="p">]</code></pre>

<p>There are numerous options for how long our n-grams should be in these phrases; what POS tags should be considered or ignored; what pre-processing should be done a priori; how to eliminate overlapping n-grams, such as statistical machine translation and machine translation in the above example; and so on. Some of these are explored in the notebook, and we leave the rest as exercises for the reader.</p>

<p>We showed one example of implementing KPE with textacy. There are other options, though. For example, the Python library gensim<a contenteditable="false" data-primary="gensim library" data-secondary="KPE with" data-type="indexterm" id="idm45969597877672"/> has a keyword extractor based on TextRank<a contenteditable="false" data-primary="TextRank" data-type="indexterm" id="idm45969597758248"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597757016-marker" href="ch05.xhtml#idm45969597757016">15</a>]. [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597755576-marker" href="ch05.xhtml#idm45969597755576">16</a>] shows how to implement TextRank from scratch. You can explore multiple library implementations and compare them before choosing one.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Practical Advice"><div class="sect2" id="practical_advice-id00012">
<h2>Practical Advice</h2>

<p>We’ve seen how keyphrase extraction can be implemented using spaCy and textacy and how we can modify it to suit our needs. From a practical point of view, there are a few caveats to keep in mind when using such graph-based algorithms in production, though. We’ll list a few of them below, along with some suggestions for working around them based on our experience with adding KPE as a feature in software <span class="keep-together">products:</span></p>
<ul>
	<li>
	<p>The process of extracting potential n-grams and building the graph with them is sensitive to document length, which could be an issue in a production scenario. One approach to dealing with it is to not use the full text, but instead try using the first M% and the last N% of the text, since we would expect that the introductory and concluding parts of the text should cover the main summary of the text.</p>
	</li>
	<li>
	<p>Since each keyphrase is independently ranked, we sometimes end up seeing overlapping keyphrases (e.g., “buy back stock” and “buy back”). One solution for this could be to use some similarity measure (e.g., cosine similarity) between the top-ranked keyphrases and choose the ones that are most dissimilar to one another. textacy already implements a function to address this issue, as shown in the <span class="keep-together">notebook.</span></p>
	</li>
	<li>
	<p>Seeing counterproductive patterns (e.g., a keyphrase that starts with a preposition when you don’t want that) is another common problem. This is relatively straightforward to handle by tweaking the implementation code for the algorithm and explicitly encoding information about such unwanted word patterns.</p>
	</li>
	<li>
	<p>Improper text extraction can affect the rest of the KPE process, especially when dealing with formats such as PDF or scanned images. This is primarily because KPE is sensitive to sentence structure in the document. Hence, it’s always a good idea to add some post-processing to the extracted key phrases list to create a final, meaningful list without noise.</p>
	</li>
</ul>

<p>A custom solution could be a combination of an existing graph-based KPE algorithm that addresses the above-mentioned issues and a domain-specific list of heuristics, if available. From our experience, this covers the issues most commonly encountered with KPE in typical NLP projects.</p>

<p>In this section, we saw how to use KPE algorithms to extract important words and phrases from any document and some ways to overcome potential challenges. While such keyphrases can potentially capture the names of important entities in the text, we’re not specifically looking for them when we use KPE algorithms. Let’s now look at the next—and perhaps most popular—IE task, which is designed to look specifically for the presence of named entities in the<a contenteditable="false" data-primary="keyphrase extraction (KPE)" data-startref="ch05_term5" data-type="indexterm" id="idm45969597743448"/><a contenteditable="false" data-primary="KPE" data-see="keyphase extraction" data-type="indexterm" id="idm45969597742056"/> text.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Named Entity Recognition"><div class="sect1" id="named_entity_recognition">
<h1>Named Entity Recognition</h1>

<p><a contenteditable="false" data-primary="NER" data-see="named entity recognition" data-type="indexterm" id="idm45969597738984"/><a contenteditable="false" data-primary="named entity recognition (NER)" data-type="indexterm" id="ch05_term8"/>Consider a scenario where the user asks a search query—“Where was Albert Einstein born?”—using Google search. <a data-type="xref" href="#screenshot_of_a_google_search_result">Figure 5-5</a> shows a screenshot of what we see before a list of search results.</p>



<p>To be able to show “Ulm, Germany” for this query, the search engine needs to decipher that Albert Einstein is a person before going on to look for a place of birth. This is an example of <a contenteditable="false" data-primary="named entity recognition (NER)" data-secondary="examples" data-type="indexterm" id="idm45969597734328"/>NER in action in a real-world application.</p>

<figure><div id="screenshot_of_a_google_search_result" class="figure"><img alt="Screenshot of a Google search result" src="Images/pnlp_0505.png" width="1029" height="629"/>
<h6><span class="label">Figure 5-5. </span>Screenshot of a Google search result</h6>
</div></figure>

<p>NER refers to the IE task of identifying the entities in a document. Entities are typically names of persons, locations, and organizations, and other specialized strings, such as money expressions, dates, products, names/numbers of laws or articles, and so on. NER is an important step in the pipeline of several NLP applications involving information extraction. <a data-type="xref" href="#ner_example_using_the_displacy_visualiz">Figure 5-6</a> illustrates the function of NER using the displaCy visualizer by explosion.ai [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597729000-marker" href="ch05.xhtml#idm45969597729000">17</a>].</p>



<p>As seen in the figure, for a given text, NER is expected to identify person names, locations, dates, and other entities. Different categories of entities identified here are some of the ones commonly used in NER system development [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597726888-marker" href="ch05.xhtml#idm45969597726888">18</a>]. NER is a prerequisite for being able to do other IE tasks, such as relation extraction or event extraction, which were introduced earlier in this chapter and will be discussed in greater detail later on. NER is also useful in other applications like machine translation, as names need not necessarily be translated while translating a sentence. So, clearly, there’s a range of scenarios in NLP projects where NER is a major component. It’s one of the common tasks you’re likely to encounter in NLP projects in industry. How do we build such an NER system? The rest of this section focuses on this question, considering three cases: building our own NER system, using existing libraries, and using active learning.</p>

<figure><div id="ner_example_using_the_displacy_visualiz" class="figure"><img alt="NER example using the displaCy visualizer" src="Images/pnlp_0506.png" width="1243" height="697"/>
<h6><span class="label">Figure 5-6. </span>NER example using the displaCy visualizer<a contenteditable="false" data-primary="displaCy visualizer" data-type="indexterm" id="idm45969597722856"/></h6>
</div></figure>

<section data-type="sect2" data-pdf-bookmark="Building an NER System"><div class="sect2" id="building_an_ner_system">
<h2>Building an NER System</h2>

<p><a contenteditable="false" data-primary="named entity recognition (NER)" data-secondary="building" data-type="indexterm" id="ch05_term9"/>A simple approach to building an NER system is to maintain a large collection of person/organization/location names that are the most relevant to our company (e.g., names of all clients, cities in their addresses, etc.); this is typically referred to as a <em>gazetteer</em>. To check whether a given word is a named entity or not, just do a lookup in the gazetteer<em>.</em> If a large number of entities present in our data are covered by a gazetteer, then it’s a great way to start, especially when we don’t have an existing NER system available. There are a few questions to consider with such an approach. How does it deal with new names? How do we periodically update this database? How does it keep track of aliases, i.e., different variations of a given name (e.g., USA, United States, etc.)?</p>

<p>An approach that goes beyond a lookup table is rule-based NER, which can be based on a compiled list of patterns based on word tokens and POS tags. For example, a pattern “NNP was born,” where “NNP” is the POS tag for a proper noun, indicates that the word that was tagged “NNP” refers to a person. Such rules can be programmed to cover as many cases as possible to build a rule-based NER system. Stanford NLP’s RegexNER<a contenteditable="false" data-primary="RegexNER (Stanford NLP)" data-type="indexterm" id="idm45969597714760"/><a contenteditable="false" data-primary="Stanford Natural Language Processing Group" data-secondary="RegexNER" data-type="indexterm" id="idm45969597713656"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597712120-marker" href="ch05.xhtml#idm45969597712120">19</a>] and spaCy’s EntityRuler<a contenteditable="false" data-primary="EntityRuler (spaCy)" data-type="indexterm" id="idm45969597710712"/><a contenteditable="false" data-primary="spaCy library" data-secondary="EntityRuler" data-type="indexterm" id="idm45969597709640"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597708136-marker" href="ch05.xhtml#idm45969597708136">20</a>] provide functionalities to implement your own rule-based <a contenteditable="false" data-primary="named entity recognition (NER)" data-secondary="rule-based" data-type="indexterm" id="idm45969597706648"/>NER.</p>

<p>A more practical approach to NER is to train an ML model, which can predict the named entities in unseen text. For each word, a decision has to be made whether or not that word is an entity, and if it is, what type of the entity it is. In many ways, this is very similar to the classification problems we discussed in detail in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>. The only difference here is that NER is a “sequence labeling<a contenteditable="false" data-primary="sequence labeling" data-type="indexterm" id="idm45969597703480"/>” problem [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597702248-marker" href="ch05.xhtml#idm45969597702248">21</a>]. The typical classifiers we saw in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a> predict labels for texts independent of their surrounding context. Consider a classifier that classifies sentences in a movie review into positive/negative/neutral categories based on their sentiment. This classifier does not (usually) take into account the sentiment of previous (or subsequent) sentences when classifying the current sentence. In a sequence classifier, such context is important. A common use case for sequence labeling is POS tagging, where we need information about the parts of speech of surrounding words to estimate the part of speech of the current word. NER is traditionally modeled as a sequence classification problem, where the entity prediction for the current word also depends on the context. For example, if the previous word was a person name, there’s a higher probability that the current word is also a person name if it’s a noun (e.g., first and last names).</p>

<p>To illustrate the difference between a normal classifier and a sequence classifier, consider the following sentence: “Washington is a rainy state.” When a normal classifier sees this sentence and has to classify it word by word, it has to make a decision as to whether Washington refers to a person (e.g., George Washington) or the State of Washington without looking at the surrounding words. It’s possible to classify the word “Washington” in this particular sentence as a location only after looking at the context in which it’s being used. It’s for this reason that sequence classifiers are used for training NER models.</p>

<p><em>Conditional random fields (CRFs)</em><a contenteditable="false" data-primary="conditional random fields (CRFs)" data-type="indexterm" id="idm45969597697272"/><a contenteditable="false" data-primary="CRFs (conditional random fields)" data-type="indexterm" id="idm45969597696136"/> is one of the popular sequence classifier training algorithms. The notebook associated with this section (<em>Ch5/NERTraining.ipynb</em>) shows how we can use CRFs to train an NER system. We’ll use CONLL-03, a popular dataset used for training NER systems [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597694200-marker" href="ch05.xhtml#idm45969597694200">22</a>], and an open source sequence labeling library called sklearn-crfsuite [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597692952-marker" href="ch05.xhtml#idm45969597692952">23</a>], along with a set of simple word- and POS tag–based features, which provide contextual information we need for this task.</p>

<p>To perform sequence classification<a contenteditable="false" data-primary="sequence classification" data-type="indexterm" id="idm45969597690904"/>, we need data in a format that allows us to model the context. Typical training data for NER looks like <a data-type="xref" href="#ner_training_data_format_example">Figure 5-7</a>, which is a sentence from the CONLL-03 dataset.</p>

<p>The labels in the figure follow what’s known as a BIO notation: B indicates the beginning of an entity; I, inside an entity, indicates when entities comprise more than one word; and O, other, indicates non-entities. Peter Such is a name with two words in the example shown in <a data-type="xref" href="#ner_training_data_format_example">Figure 5-7</a>. Thus, “Peter” gets tagged as a B-PER, and “Such” gets tagged as an I-PER to indicate that Such is a part of the entity from the previous word. The remaining entities in this example, Essex, Yorkshire, and Headingley, are all one-word entities. So, we only see B-ORG and B-LOC as their tags. Once we obtain a dataset of sentences annotated in this form and we have a sequence classifier algorithm, how should we train an NER system?</p>

<p class="pagebreak-before">The steps are the same as those for the text classifiers we saw in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>:</p>

<ol>
	<li>
	<p>Load the dataset</p>
	</li>
	<li>
	<p>Extract the features</p>
	</li>
	<li>
	<p>Train the classifier</p>
	</li>
	<li>
	<p>Evaluate it on a test set</p>
	</li>
</ol>

<figure><div id="ner_training_data_format_example" class="figure"><img alt="NER training data format example" src="Images/pnlp_0507.png" width="276" height="801"/>
<h6><span class="label">Figure 5-7. </span>NER training data format example</h6>
</div></figure>

<p>Loading<a contenteditable="false" data-primary="named entity recognition (NER)" data-secondary="typical training data" data-type="indexterm" id="idm45969597678248"/> the dataset is straightforward. This particular dataset is also already split into a train/dev/test set. So, we’ll train the model using the training set. We saw a range of feature representation techniques in <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a>. Let’s look at an example using handcrafted features this time. What features seem intuitively relevant for this task? To identify names of people or places, for example, patterns such as whether the word starts with an uppercase character or whether it’s preceded or succeeded by a verb/noun, etc., can be used as starting points to train an NER model. The following code snippet shows a function that extracts the previous and next words’ POS tags for a given sentence. The notebook has a more elaborate feature set:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">sent2feats</code><code class="p">(</code><code class="n">sentence</code><code class="p">):</code>
    <code class="n">feats</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="n">sen_tags</code> <code class="o">=</code> <code class="n">pos_tag</code><code class="p">(</code><code class="n">sentence</code><code class="p">)</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code><code class="nb">len</code><code class="p">(</code><code class="n">sentence</code><code class="p">)):</code>
         <code class="n">word</code> <code class="o">=</code> <code class="n">sentence</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
         <code class="n">wordfeats</code> <code class="o">=</code> <code class="p">{}</code>
         <code class="c1">#POS tag features: current tag, previous and next 2 tags.</code>
         <code class="n">wordfeats</code><code class="p">[</code><code class="s1">'tag'</code><code class="p">]</code> <code class="o">=</code> <code class="n">sen_tags</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="mi">1</code><code class="p">]</code>
         <code class="k">if</code> <code class="n">i</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
         	<code class="n">wordfeats</code><code class="p">[</code><code class="s2">"prevTag"</code><code class="p">]</code> <code class="o">=</code> <code class="s2">"&lt;S&gt;"</code>
         <code class="k">elif</code> <code class="n">i</code> <code class="o">==</code> <code class="mi">1</code><code class="p">:</code>
         	<code class="n">wordfeats</code><code class="p">[</code><code class="s2">"prevTag"</code><code class="p">]</code> <code class="o">=</code> <code class="n">sen_tags</code><code class="p">[</code><code class="mi">0</code><code class="p">][</code><code class="mi">1</code><code class="p">]</code>
         <code class="k">else</code><code class="p">:</code>
         	<code class="n">wordfeats</code><code class="p">[</code><code class="s2">"prevTag"</code><code class="p">]</code> <code class="o">=</code> <code class="n">sen_tags</code><code class="p">[</code><code class="n">i</code> <code class="o">-</code> <code class="mi">1</code><code class="p">][</code><code class="mi">1</code><code class="p">]</code>
         <code class="k">if</code> <code class="n">i</code> <code class="o">==</code> <code class="nb">len</code><code class="p">(</code><code class="n">sentence</code><code class="p">)</code> <code class="o">-</code> <code class="mi">2</code><code class="p">:</code>
         	<code class="n">wordfeats</code><code class="p">[</code><code class="s2">"nextTag"</code><code class="p">]</code> <code class="o">=</code> <code class="n">sen_tags</code><code class="p">[</code><code class="n">i</code> <code class="o">+</code> <code class="mi">1</code><code class="p">][</code><code class="mi">1</code><code class="p">]</code>
         <code class="k">elif</code> <code class="n">i</code> <code class="o">==</code> <code class="nb">len</code><code class="p">(</code><code class="n">sentence</code><code class="p">)</code> <code class="o">-</code> <code class="mi">1</code><code class="p">:</code>
         	<code class="n">wordfeats</code><code class="p">[</code><code class="s2">"nextTag"</code><code class="p">]</code> <code class="o">=</code> <code class="s2">"&lt;/S&gt;"</code>
         <code class="k">else</code><code class="p">:</code>
         	<code class="n">wordfeats</code><code class="p">[</code><code class="s2">"nextTag"</code><code class="p">]</code> <code class="o">=</code> <code class="n">sen_tags</code><code class="p">[</code><code class="n">i</code> <code class="o">+</code> <code class="mi">1</code><code class="p">][</code><code class="mi">1</code><code class="p">]</code>
         <code class="n">feats</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">wordfeats</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">feats</code></pre>

<p>As you can see from the <code>wordfeats</code> variable in this code sample, each word is transformed into a dictionary of features, and therefore each sentence will look like a list of dictionaries (the variable <code>feats</code> in the code), which will be used by the CRF classifier. The following code snippet shows a function to train an NER system with a CRF model and evaluates the model performance on the development set:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="c1">#Train a sequence model</code>
<code class="k">def</code> <code class="nf">train_seq</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code><code class="n">Y_train</code><code class="p">,</code><code class="n">X_dev</code><code class="p">,</code><code class="n">Y_dev</code><code class="p">):</code>
    <code class="n">crf</code> <code class="o">=</code> <code class="n">CRF</code><code class="p">(</code><code class="n">algorithm</code><code class="o">=</code><code class="s1">'lbfgs'</code><code class="p">,</code> <code class="n">c1</code><code class="o">=</code><code class="mf">0.1</code><code class="p">,</code> <code class="n">c2</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code> <code class="n">max_iterations</code><code class="o">=</code><code class="mi">50</code><code class="p">)</code>
    <code class="n">crf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">)</code>
    <code class="n">labels</code> <code class="o">=</code> <code class="nb">list</code><code class="p">(</code><code class="n">crf</code><code class="o">.</code><code class="n">classes_</code><code class="p">)</code>
    <code class="n">y_pred</code> <code class="o">=</code> <code class="n">crf</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_dev</code><code class="p">)</code>
    <code class="n">sorted_labels</code> <code class="o">=</code> <code class="nb">sorted</code><code class="p">(</code><code class="n">labels</code><code class="p">,</code> <code class="n">key</code><code class="o">=</code><code class="k">lambda</code> <code class="n">name</code><code class="p">:</code> <code class="p">(</code><code class="n">name</code><code class="p">[</code><code class="mi">1</code><code class="p">:],</code> <code class="n">name</code><code class="p">[</code><code class="mi">0</code><code class="p">]))</code>
    <code class="k">print</code><code class="p">(</code><code class="n">metrics</code><code class="o">.</code><code class="n">flat_f1_score</code><code class="p">(</code><code class="n">Y_dev</code><code class="p">,</code><code class="n">y_pred</code><code class="p">,</code><code class="n">average</code><code class="o">=</code><code class="s1">'weighted'</code><code class="p">,</code>
                          <code class="n">labels</code><code class="o">=</code><code class="n">labels</code><code class="p">))</code></pre>

<p>Training this CRF model gave an F1 score of 0.92 on the development data, which is a very good score! The notebook shows more detailed evaluation measures and how to calculate them. Here, we showed some of the most commonly used features in learning an NER system and used a popular training method and a publicly available dataset. Clearly, there’s a lot to be done in terms of tuning the model and developing (even) better features; this example only serves to illustrate one way of developing an NER model quickly using one particular library in case you need to and you have a relevant dataset. MITIE<a contenteditable="false" data-primary="MITIE" data-type="indexterm" id="idm45969597426984"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_5_43-marker" href="ch05.xhtml#footnote_5_43">24</a>] is another such library to train NER systems.</p>

<p>Recent advances in NER research either exclude or augment the kind of feature engineering we did in this example with neural network models. NCRF++<a contenteditable="false" data-primary="NCRF++" data-type="indexterm" id="idm45969597377432"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597376232-marker" href="ch05.xhtml#idm45969597376232">25</a>] is another library that can be used to train your own NER using different neural network architectures. A notebook that uses the BERT model for training an NER system using the same dataset is available in the GitHub repo (<em>Ch5/BERT_CONLL_NER.ipynb</em>). We leave working through that as an exercise for the reader.</p>

<p>We took a quick tour of how to train our own NER system. However, in real-world scenarios, using the trained model by itself won’t be sufficient, as the data keeps changing and new entities keep getting added, and there will also be some domain-specific entities or patterns that were not seen in generic training datasets. Hence, most NER systems deployed in real-world scenarios use a combination of ML models, gazetteers, and some pattern matching–based heuristics to improve their performance [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_5_7-marker" href="ch05.xhtml#footnote_5_7">26</a>]. [<a data-type="noteref" href="ch05.xhtml#footnote_5_43">24</a>] shows an example of how Rasa<a contenteditable="false" data-primary="Rasa" data-type="indexterm" id="idm45969597370408"/>, a company that builds intelligent chatbots, improves its entity extraction using lookup tables.</p>

<p>Clearly, to build these NER systems ourselves, we need large, annotated datasets in a format similar to the one shown in <a data-type="xref" href="#ner_training_data_format_example">Figure 5-7</a>. While datasets like CONLL-03<a contenteditable="false" data-primary="CONLL-03 dataset" data-type="indexterm" id="idm45969597367560"/> are available, they work with a limited set of entities (person, organization, location, miscellaneous, other) and in limited domains. There are other such datasets, such as OntoNotes<a contenteditable="false" data-primary="OntoNotes" data-type="indexterm" id="idm45969597366152"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597364920-marker" href="ch05.xhtml#idm45969597364920">27</a>], which are much larger and cover different kinds of text. However, they’re not freely available and usually need to be purchased under expensive license agreements, which may not always be supported by our organizations’ budgets. So, what should we do?<a contenteditable="false" data-primary="named entity recognition (NER)" data-secondary="building" data-startref="ch05_term9" data-type="indexterm" id="idm45969597363096"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="NER Using an Existing Library"><div class="sect2" id="ner_using_an_existing_library">
<h2>NER Using an Existing Library</h2>

<p><a contenteditable="false" data-primary="named entity recognition (NER)" data-secondary="with existing libraries" data-secondary-sortas="existing libraries" data-type="indexterm" id="ch05_term10"/>While all this discussion about training an NER system may make building and deploying it look like a long process (starting with procuring a dataset), thankfully, NER has been well researched over the past few decades, and we have off-the-shelf libraries to start with. Stanford NER<a contenteditable="false" data-primary="Stanford Named Entity Recognizer (NER)" data-type="indexterm" id="idm45969597357608"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597356360-marker" href="ch05.xhtml#idm45969597356360">28</a>], spaCy<a contenteditable="false" data-primary="spaCy library" data-type="indexterm" id="idm45969597354824"/>, and AllenNLP<a contenteditable="false" data-primary="AllenNLP" data-type="indexterm" id="idm45969597353624"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597352360-marker" href="ch05.xhtml#idm45969597352360">29</a>] are some well-known NLP libraries that can be used to incorporate a pre-trained NER model into a software product. The code snippet below illustrates using NER from spaCy<a contenteditable="false" data-primary="spaCy library" data-secondary="NER with" data-type="indexterm" id="idm45969597350664"/>:</p>

<pre data-code-language="python" data-type="programlisting" class="less_space pagebreak-before">
<code class="kn">import</code> <code class="nn">spacy</code>
<code class="n">nlp</code> <code class="o">=</code> <code class="n">spacy</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="s2">"en_core_web_lg"</code><code class="p">)</code>
<code class="n">text_from_fig</code> <code class="o">=</code> <code class="s2">"On Tuesday, Apple announced its plans for another major chunk </code>
                 <code class="n">of</code> <code class="n">the</code> <code class="n">money</code><code class="p">:</code> <code class="n">It</code> <code class="n">will</code> <code class="n">buy</code> <code class="n">back</code> <code class="n">a</code> <code class="n">further</code> <code class="err">$</code><code class="mi">75</code> <code class="n">billion</code> <code class="ow">in</code> <code class="n">stock</code><code class="o">.</code><code class="s2">"</code>
<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text_from_fig</code><code class="p">)</code>
<code class="k">for</code> <code class="n">ent</code> <code class="ow">in</code> <code class="n">doc</code><code class="o">.</code><code class="n">ents</code><code class="p">:</code>
    <code class="k">if</code> <code class="n">ent</code><code class="o">.</code><code class="n">text</code><code class="p">:</code>
         <code class="k">print</code><code class="p">(</code><code class="n">ent</code><code class="o">.</code><code class="n">text</code><code class="p">,</code> <code class="s2">"</code><code class="se">\t</code><code class="s2">"</code><code class="p">,</code> <code class="n">ent</code><code class="o">.</code><code class="n">label_</code><code class="p">)</code></pre>

<p>Running this code snippet will show Tuesday as DATE, Apple as ORG, and $75 billion as MONEY. Considering that spaCy’s NER is based on a state-of-the-art neural model coupled with some pattern matching and heuristics, it’s a good starting point. However, we may run into two issues:</p>

<ol>
	<li>
	<p>As mentioned earlier, we may be using NER in a specific domain, and the pre-trained models may not capture the specific nature of our own domain.</p>
	</li>
	<li>
	<p>Sometimes, we may want to add new categories to the NER system without having to collect a large dataset for all the common categories.</p>
	</li>
</ol>

<p>What should we do in such cases?</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="NER Using Active Learning"><div class="sect2" id="ner_using_active_learning">
<h2>NER Using Active Learning</h2>

<p><a contenteditable="false" data-primary="active learning" data-secondary="NER using" data-type="indexterm" id="ch05_term12"/><a contenteditable="false" data-primary="named entity recognition (NER)" data-secondary="with active learning" data-secondary-sortas="active learning" data-type="indexterm" id="ch05_term11"/>From our experience, the best approach to NER when we want customized solutions but don’t want to train everything from scratch is to start with an off-the-shelf product and either augment it with customized heuristics for our problem domain (using tools such as RegexNER<a contenteditable="false" data-primary="RegexNER (Stanford NLP)" data-type="indexterm" id="idm45969597175384"/><a contenteditable="false" data-primary="Stanford Natural Language Processing Group" data-secondary="RegexNER" data-type="indexterm" id="idm45969597174280"/> or EntityRuler<a contenteditable="false" data-primary="EntityRuler (spaCy)" data-type="indexterm" id="idm45969597172680"/><a contenteditable="false" data-primary="spaCy library" data-secondary="EntityRuler" data-type="indexterm" id="idm45969597171544"/>) and/or use active learning using tools like Prodigy<a contenteditable="false" data-primary="Prodigy" data-type="indexterm" id="idm45969597170040"/> (like we saw in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a> for text classification). This allows us to improve an existing pre-trained NER model by manually tagging a few example sentences containing new NER categories or correct a few model predictions manually and use these to retrain the model. [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597167560-marker" href="ch05.xhtml#idm45969597167560">30</a>] shows some examples of going through this process using Prodigy.</p>

<p>In general, in most cases, we don’t always have to think about developing an NER system from scratch. If we do have to develop an NER system from scratch, the first thing we would need, as we saw in this section, is a large collection of annotated data of sentences where each word/token is tagged with its category (entity type or other). Once such a dataset is available, the next step is to use it to obtain handcrafted and/or neural feature representations and feed them to a sequence labeling model. Chapters 8 and 9 in [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="footnote_5_24-marker" href="ch05.xhtml#footnote_5_24">31</a>] deal with specific methods to learn from such sequences. In the absence of such data, rule-based NER is the first step.</p>

<div data-type="tip"><h6>Tip</h6>
<p>Start with a pre-trained NER model and enhance it with heuristics, active learning, or both.</p>
<a contenteditable="false" data-primary="named entity recognition (NER)" data-secondary="with active learning" data-secondary-sortas="active learning" data-startref="ch05_term11" data-type="indexterm" id="idm45969597162440"/><a contenteditable="false" data-primary="active learning" data-secondary="NER using" data-startref="ch05_term12" data-type="indexterm" id="idm45969597160456"/></div>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Practical Advice"><div class="sect2" id="practical_advice-id00013">
<h2>Practical Advice</h2>

<p><a contenteditable="false" data-primary="named entity recognition (NER)" data-secondary="practical advice" data-type="indexterm" id="ch05_term13"/>So far, we’ve taken a quick look at how to use existing NER systems, discussed some ways of augmenting them, and discussed how to train our own NER from scratch. Despite the fact that state-of-the-art NER is highly accurate (with F1 scores over 90% using standard evaluation frameworks for NER in NLP research), there are several issues to keep in mind when using NER in our own software applications. Here are a couple caveats based on our own experience with developing NER systems:</p>

<ul>
	<li>
	<p>NER is very sensitive to the format of its input. It’s more accurate with well-formatted plain text than with, say, a PDF document from which plain text needs to be extracted first. While it’s possible to build custom NER systems for specific domains or for data like tweets, the challenge with PDFs comes from the failure to be 100% accurate in extracting text from them while preserving the structure. [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597153288-marker" href="ch05.xhtml#idm45969597153288">32</a>] illustrates some of the challenges with PDF-to-text extraction. Why do we need to be so accurate in properly extracting the structure from PDFs, though? In PDFs, partial sentences, headings, and formatting are common, and they can all mess up NER accuracy. There’s no single solution for this. One approach is to do custom post-processing of PDFs to extract blobs of text, then run NER on the blobs.</p>

	<div data-type="tip"><h6>Tip</h6>
	<p>If you’re working with documents, such as reports, etc., pre-process them to extract text blobs, then run NER on them.</p>
	</div>
	</li>
	<li>
	<p>NER is also very sensitive to the accuracy of the prior steps in its processing pipeline: sentence splitting, tokenization, and POS tagging (refer back to <a data-type="xref" href="#a_new_york_times_article_from_april_30c">Figure 5-2</a>). To understand how improper sentence splitting can result in poor NER results, try taking the content from the screenshot back in <a data-type="xref" href="#screenshot_from_the_google_news_homepag">Figure 5-1</a> and looking at the output from spaCy (see the notebook <em>Ch5/NERIssues.ipynb</em> for a short illustration). So, some amount of pre-processing may be necessary before passing a piece of text into an NER model to extract entities.</p>
	</li>
</ul>

<p>Despite such shortcomings, NER is immensely useful for many IE scenarios, such as content tagging, search, and mining social media to identify customer feedback about specific products, to name a few. While NER (and KPE<a contenteditable="false" data-primary="keyphrase extraction (KPE)" data-type="indexterm" id="idm45969597144024"/>) serve the useful task of <span class="keep-together">identifying</span> important words, phrases, and entities in documents, some NLP applications require further analysis of language, which leads us to more advanced NLP tasks. One such IE task is entity disambiguation or entity linking, and it’s the topic of the next<a contenteditable="false" data-primary="named entity recognition (NER)" data-startref="ch05_term8" data-type="indexterm" id="idm45969597141816"/><a contenteditable="false" data-primary="named entity recognition (NER)" data-secondary="practical advice" data-startref="ch05_term13" data-type="indexterm" id="idm45969597140376"/> section.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Named Entity Disambiguation and Linking"><div class="sect1" id="named_entity_disambiguation_and_linking">
<h1>Named Entity Disambiguation and Linking</h1>

<p>Consider a scenario where we’re working on the data science team of a large newspaper publication (say, <em>The New York Times</em>). We’re charged with the task of building a system that creates visual representation of news stories by connecting different entities mentioned in the stories to what they refer to in the real world, as shown in <a data-type="xref" href="#entity_linking_by_ibm_left_square_brack">Figure 5-8</a>.</p>

<figure><div id="entity_linking_by_ibm_left_square_brack" class="figure"><img alt="Entity linking by IBM [_12]" src="Images/pnlp_0508.png" width="698" height="416"/>
<h6><span class="label">Figure 5-8. </span>Entity linking by IBM<a contenteditable="false" data-primary="IBM Research" data-type="indexterm" id="idm45969597133320"/><a contenteditable="false" data-primary="entity linking" data-type="indexterm" id="idm45969597132184"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597130952-marker" href="ch05.xhtml#idm45969597130952">33</a>]</h6>
</div></figure>

<p>Doing this requires knowledge of several IE tasks beyond what we’ve seen with NER and KPE. As a first step, we have to know what these entities or keywords actually refer to in the real world. Let’s take another example to illustrate why this could be challenging. Consider this sentence: “Lincoln drives a Lincoln Aviator and lives on Lincoln Way.” All three mentions of “Lincoln” here refer to different entities and different types of entities: the first Lincoln is a person, the second one is a vehicle, and the third is a location. How can we reliably link the three Lincolns to their correct Wikipedia pages like in <a data-type="xref" href="#entity_linking_by_ibm_left_square_brack">Figure 5-8</a>?</p>

<p class="pagebreak-before"><em>Named entity disambiguation (NED)</em><a contenteditable="false" data-primary="named entity disambiguation (NED)" data-type="indexterm" id="idm45969597126152"/><a contenteditable="false" data-primary="NED (named entity disambiguation)" data-type="indexterm" id="idm45969597125016"/> refers to the NLP task of achieving exactly this: assigning a unique identity to entities mentioned in the text. It’s also the first step in moving toward more sophisticated tasks to address the scenario mentioned above by identifying relationships between entities. NER and NED together are known as <em>named entity linking (NEL)</em>. Some other NLP applications that would need NEL include question answering and constructing large knowledge bases of connected events and entities, such as the Google Knowledge Graph<a contenteditable="false" data-primary="Google Knowledge Graph" data-type="indexterm" id="idm45969597122824"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597121624-marker" href="ch05.xhtml#idm45969597121624">34</a>].</p>

<p>So, how do we build an IE system for performing NEL? Just as NER identifies entities and their spans using contextual information encoded by a range of features, NEL also relies on context. However, it requires going beyond POS tagging in terms of the NLP pre-processing needed. At a minimum, NEL needs some form of parsing to identify linguistic items like subject, verb, and object. Additionally, it may also need coreference resolution to resolve and link multiple references to the same entity (e.g., Albert Einstein, the scientist, Einstein, etc.) to the same reference in a large, encyclopedic knowledge base (e.g., Wikipedia<a contenteditable="false" data-primary="Wikipedia" data-type="indexterm" id="idm45969597119208"/>). This is typically modeled as a supervised ML problem and evaluated in terms of precision, recall, and F1 scores on standard test sets.</p>

<p>State-of-the-art NEL uses a range of different neural network architectures [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597117400-marker" href="ch05.xhtml#idm45969597117400">35</a>]. Clearly, learning an NEL model requires the presence of a large, annotated dataset as well as some kind of encyclopedic resource to link to. Further, NEL is a much more specialized NLP task compared to what we’ve seen so far (text representation, text classification, NER, KPE). In our experience as industry practitioners, it’s more common to use off-the-shelf, pay-as-you-use services offered by big providers such as IBM (Watson)<a contenteditable="false" data-primary="IBM Watson" data-type="indexterm" id="idm45969597062968"/> and Microsoft (Azure)<a contenteditable="false" data-primary="Microsoft Azure" data-secondary="NEL with" data-type="indexterm" id="ch05_term15"/> for NEL rather than developing an in-house system. Let’s look at an example of using one such service.</p>

<section data-type="sect2" data-pdf-bookmark="NEL Using Azure API"><div class="sect2" id="nel_using_azure_api">
<h2>NEL Using Azure API</h2>

<p><a contenteditable="false" data-primary="Microsoft Azure" data-secondary="Text Analytics API" data-type="indexterm" id="ch05_term17"/><a contenteditable="false" data-primary="named entity linking (NEL)" data-type="indexterm" id="ch05_term16"/><a contenteditable="false" data-type="indexterm" data-primary="NEL (named entity linking)" id="ch05_term117"/>The Azure Text Analytics API is one of the popular APIs for NEL. DBpedia Spotlight<a contenteditable="false" data-primary="DBpedia Spotlight" data-type="indexterm" id="idm45969597053304"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969597052072-marker" href="ch05.xhtml#idm45969597052072">36</a>] is a freely available tool to do the same. The following code snippet (<em>Ch5/EntityLinking-AzureTextAnalytics.ipynb</em>) shows how to access the Azure API to perform entity linking on a text. Azure comes with a seven-day free trial, which is a good way to explore the API to understand whether it meets your requirements:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code> <code class="nn">requests</code>
<code class="n">my_api_key</code> <code class="o">=</code> <code class="s1">'XXXXXXX'</code>
<code class="k">def</code> <code class="nf">print_entities</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>
    <code class="n">url</code> <code class="o">=</code> <code class="s2">"https://westcentralus.api.cognitive.microsoft.com/text/analytics/</code><code class="se">\</code>
<code class="s2">    v2.1/entities"</code>
    <code class="n">documents</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'documents'</code><code class="p">:[{</code><code class="s1">'id'</code><code class="p">:</code><code class="s1">'1'</code><code class="p">,</code> <code class="s1">'language'</code><code class="p">:</code><code class="s1">'en'</code><code class="p">,</code> <code class="s1">'text'</code><code class="p">:</code><code class="n">text</code><code class="p">}]}</code>
    <code class="n">headers</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'Ocp-Apim-Subscription-Key'</code><code class="p">:</code> <code class="n">my_api_key</code><code class="p">}</code>
    <code class="n">response</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">post</code><code class="p">(</code><code class="n">url</code><code class="p">,</code> <code class="n">headers</code><code class="o">=</code><code class="n">headers</code><code class="p">,</code> <code class="n">json</code><code class="o">=</code><code class="n">documents</code><code class="p">)</code>
    <code class="n">entities</code> <code class="o">=</code> <code class="n">response</code><code class="o">.</code><code class="n">json</code><code class="p">()</code>
    <code class="k">return</code> <code class="n">entities</code>

<code class="n">mytext</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="s2">"nytarticle.txt"</code><code class="p">)</code><code class="o">.</code><code class="n">read</code><code class="p">()</code> <code class="c1">#file is in the github repo.</code>
<code class="n">entities</code> <code class="o">=</code> <code class="n">print_entities</code><code class="p">(</code><code class="n">mytext</code><code class="p">)</code>
<code class="k">for</code> <code class="n">document</code> <code class="ow">in</code> <code class="n">entities</code><code class="p">[</code><code class="s1">'documents'</code><code class="p">]:</code>
    <code class="k">print</code><code class="p">(</code><code class="s2">"Entities in this document: "</code><code class="p">)</code>
    <code class="k">for</code> <code class="n">entity</code> <code class="ow">in</code> <code class="n">document</code><code class="p">[</code><code class="s1">'entities'</code><code class="p">]:</code>
          <code class="k">if</code> <code class="n">entity</code><code class="p">[</code><code class="s1">'type'</code><code class="p">]</code> <code class="ow">in</code> <code class="p">[</code><code class="s2">"Person"</code><code class="p">,</code> <code class="s2">"Location"</code><code class="p">,</code> <code class="s2">"Organization"</code><code class="p">]:</code>
                     <code class="k">print</code><code class="p">(</code><code class="n">entity</code><code class="p">[</code><code class="s1">'name'</code><code class="p">],</code> <code class="s2">"</code><code class="se">\t</code><code class="s2">"</code><code class="p">,</code> <code class="n">entity</code><code class="p">[</code><code class="s1">'type'</code><code class="p">])</code>
                     <code class="k">if</code> <code class="s1">'wikipediaUrl'</code> <code class="ow">in</code> <code class="n">entity</code><code class="o">.</code><code class="n">keys</code><code class="p">():</code>
                          <code class="k">print</code><code class="p">(</code><code class="n">entity</code><code class="p">[</code><code class="s1">'wikipediaUrl'</code><code class="p">])</code></pre>

<p>The result of running this code using the Azure API is shown in <a data-type="xref" href="#output_of_entity_linking_for_a_news_art">Figure 5-9</a>; it lists entities in the text along with their Wikipedia links wherever available.</p>

<figure><div id="output_of_entity_linking_for_a_news_art" class="figure"><img alt="Output of entity linking for a news article from The New York Times" src="Images/pnlp_0509.png" width="411" height="255"/>
<h6><span class="label">Figure 5-9. </span>Output of entity linking for a news article from The New York Times</h6>
</div></figure>

<p>We see that San Francisco is a location, but a specific location, which is indicated by its Wikipedia page. Alex Jones is not any other Alex Jones, but an American TV show host, as can be seen from the Wikipedia page. This is clearly much more informative than stopping at NER, and it can be used for better information extraction. This information can then be used for understanding the relationship between these entities, which we’ll see later in this chapter.</p>

<p>So, we now have a way to incorporate NEL in our NLP system. How good is this solution? Based on our experience using off-the-shelf NEL systems, there are a few important things to keep in mind while using NEL in your project:</p>

<ul>
	<li>
	<p>Existing NEL approaches are not perfect, and they’re unlikely to fare well with new names or domain-specific terms. Since NEL also requires further linguistic processing, including syntactic parsing, its accuracy is also affected by how well the different processing steps are done.</p>
	</li>
	<li>
	<p>Like with other IE tasks, the first step in any NLP pipeline—text extraction and cleanup—affects what we see as output for NEL as well. When we use third-party services, we have little control over adapting them to our domain, if needed, or understanding their internal workings to modify them to our needs.</p>
	</li>
</ul>

<p>With this overview, now that we know how to introduce NEL into our project’s NLP pipeline if necessary, let’s move on to the next IE task that has NEL as a prerequisite: relationship<a contenteditable="false" data-primary="Microsoft Azure" data-secondary="NEL with" data-startref="ch05_term15" data-type="indexterm" id="idm45969596907512"/><a contenteditable="false" data-primary="named entity linking (NEL)" data-startref="ch05_term16" data-type="indexterm" id="idm45969596905864"/><a contenteditable="false" data-type="indexterm" data-primary="NEL (named entity linking)" data-startref="ch05_term117" id="idm45969596904472"/><a contenteditable="false" data-primary="Microsoft Azure" data-secondary="Text Analytics API" data-startref="ch05_term17" data-type="indexterm" id="idm45969596903080"/> extraction.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Relationship Extraction"><div class="sect1" id="relationship_extraction">
<h1>Relationship Extraction</h1>

<p><a contenteditable="false" data-primary="relationship extraction (RE)" data-type="indexterm" id="ch05_term18"/>Imagine we’re working at a company that mines tons of news articles to derive, say, financial insights. To be able to do such analysis on thousands of news texts every day, we would need a constantly updated knowledge base that connects different people, organizations, and events based on the news content. A use case for this knowledge base could be to analyze stock markets based on documents released by companies and the news articles about them. How will we get started building such a tool? The IE tasks we’ve seen so far—KPE, NER, and NEL—are all useful to a certain extent in helping identify entities, events, keyphrases, etc. But how do we go from there to the next step of “connecting” them with some relation? What exactly are the relations? How will we extract them? Let’s revisit <a data-type="xref" href="#a_new_york_times_article_from_april_30c">Figure 5-2</a>, which shows a screenshot of a <em>New York Times</em> article. One relation that can be extracted is: (Luca Maestri, finance chief, Apple). Here, we connect Luca Maestri to Apple with the relationship of finance chief.</p>

<p><em>Relationship extraction (RE)</em> is the IE task that deals with extracting entities and relationships between them from text documents. It’s an important step in building a knowledge base, and it’s also useful in improving search and developing question-answering systems. <a data-type="xref" href="#relation_extraction_demo">Figure 5-10</a> shows an example of a working RE system by Rosette Text Analytics<a contenteditable="false" data-primary="Rosette Text Analytics" data-type="indexterm" id="idm45969596893784"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596892504-marker" href="ch05.xhtml#idm45969596892504">37</a>] for the following text snippet [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596890904-marker" href="ch05.xhtml#idm45969596890904">38</a>]:</p>

<blockquote>
<p>Satya Narayana Nadella is an Indian-American business executive. He currently serves as the Chief Executive Officer (CEO) of Microsoft, succeeding Steve Ballmer in 2014. Before becoming chief executive, he was Executive Vice President of Microsoft’s Cloud and Enterprise Group, responsible for building and running the company’s computing platforms.</p>
</blockquote>



<p>This output shows that Narayana Nadella is a person related to Microsoft as an employee, related to India and America as a citizen, and so on. How does one proceed with extracting such relationships from a piece of text? Clearly, it’s more challenging than the other IE tasks we’ve seen so far in this chapter and requires deeper knowledge of language processing as compared to every other task we’ve covered in this book so far. Apart from identifying what entities there are and disambiguating them, we need to model the process of extracting the relationships between them by considering the words connecting the entities in a sentence, their sense of usage, and so on. Further, an important question that needs to be resolved is: what constitutes a “relation”? Relations can be specific to a given domain. For example, in the medical domain, relations could include type of injury, location of injury, cause of injury, treatment of injury, etc. In the financial domain, relations could mean something completely different. A few generic relations between people, locations, and organizations are: located in, is a part of, founder of, parent of, etc. How do we extract them?</p>

<figure><div id="relation_extraction_demo" class="figure"><img alt="Relation extraction demo" src="Images/pnlp_0510.png" width="1346" height="1163"/>
<h6><span class="label">Figure 5-10. </span>Relation extraction demo<a contenteditable="false" data-primary="relationship extraction (RE)" data-secondary="example" data-type="indexterm" id="idm45969596885032"/></h6>
</div></figure>

<section data-type="sect2" data-pdf-bookmark="Approaches to RE"><div class="sect2" id="approaches_to_re">
<h2>Approaches to RE</h2>

<p>In NLP, RE<a contenteditable="false" data-primary="relationship extraction (RE)" data-secondary="approaches to" data-type="indexterm" id="ch05_term19"/> is a well-researched topic, and—starting from handwritten patterns to different forms of supervised, semi-supervised, and unsupervised learning—various methods have been explored (and are still being used) for building RE systems. Hand-built patterns consist of regular expressions that aim to capture specific relationships. For example, a pattern such as “PER, [something] of ORG” can indicate a sort of “is-a-part-of” relation between that person and organization. Such patterns have the advantage of high precision, but they often have less coverage, and it could be challenging to create such patterns to cover all possible relations within a domain.</p>

<p>Hence, RE is often treated as a supervised classification problem. The datasets used to train RE systems contain a set of pre-defined relations, similar to classification datasets. This consists of modeling it as a two-step classification problem:</p>

<ol>
	<li>
	<p>Whether two entities in a text are related (binary classification).</p>
	</li>
	<li>
	<p>If they are related, what is the relation between them (multiclass classification)?</p>
	</li>
</ol>

<p>These are treated as a regular text classification problem, using handcrafted features, contextual features like in NER (e.g., words around a given entity), syntactic structure (e.g., a pattern such as NP VP NP, where NP is a noun phrase and VP is a verb phrase), and so on. Neural models typically use different embedding representations (which we saw in <a data-type="xref" href="ch03.xhtml#text_representation">Chapter 3</a>) followed by an architecture like recurrent neural networks (which we saw in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>).</p>

<p>Both supervised approaches and pattern-based approaches are typically domain specific, and getting large amounts of annotated data each time we start on a new domain can be both challenging and expensive. As we saw in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>, bootstrapping can be used in such scenarios, starting with a small set of seed patterns and generalizing by learning new patterns based on the sentences extracted using these seed patterns. An extension of such weak supervision approaches is called <em>distant supervision</em><a contenteditable="false" data-primary="distant supervision" data-type="indexterm" id="idm45969596870760"/>. In this, instead of using a small set of seed patterns, large databases such as Wikipedia<a contenteditable="false" data-primary="Wikipedia" data-type="indexterm" id="idm45969596869416"/>, Freebase<a contenteditable="false" data-primary="Freebase" data-type="indexterm" id="idm45969596868184"/>, etc., are used to first collect thousands of examples of many relations (e.g., using Wikipedia infoboxes), thereby creating a large dataset of relations. This can then be followed by a regular supervised relation extraction approach. Even this works only when such large databases exist. [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596866616-marker" href="ch05.xhtml#idm45969596866616">39</a>] illustrates how to use Snorkel, which we saw in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch02.xhtml#nlp_pipeline">2</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.xhtml#text_classification">4</a>, to learn specific relations in the absence of any training data. We leave its exploration as an exercise for the reader.</p>

<p>In scenarios where we cannot procure training data for supervised approaches, we can resort to unsupervised approaches. Unsupervised RE<a contenteditable="false" data-primary="relationship extraction (RE)" data-secondary="unsupervised" data-type="indexterm" id="idm45969596861896"/> (also known as “open IE”<a contenteditable="false" data-primary="open IE" data-type="indexterm" id="idm45969596860376"/><a contenteditable="false" data-primary="information extraction (IE)" data-secondary="open" data-type="indexterm" id="idm45969596859272"/>) aims to extract relations from the web without relying on any training data or any list of relations. The relations extracted are in the form of &lt;verb, argument1, argument2&gt; tuples. Sometimes, a verb may have more arguments. <a data-type="xref" href="#open_ie_demo_by_allennlp">Figure 5-11</a> shows an example of the output of such an open IE system by AllenNLP [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596856488-marker" href="ch05.xhtml#idm45969596856488">40</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596854920-marker" href="ch05.xhtml#idm45969596854920">41</a>].</p>

<figure><div id="open_ie_demo_by_allennlp" class="figure"><img alt="Open IE demo by AllenNLP" src="Images/pnlp_0511.png" width="1214" height="412"/>
<h6><span class="label">Figure 5-11. </span>Open IE<a contenteditable="false" data-primary="open IE" data-type="indexterm" id="idm45969596852056"/><a contenteditable="false" data-primary="information extraction (IE)" data-secondary="open" data-type="indexterm" id="idm45969596850920"/> demo by AllenNLP<a contenteditable="false" data-primary="AllenNLP" data-type="indexterm" id="idm45969596849400"/></h6>
</div></figure>

<p>In this example, we see the relation as a verb and its three arguments &lt;published, albert einstein, the theory of relativity, in 1915&gt;. We can also extract the relation tuples &lt;published, albert einstein, the theory of relativity&gt;, &lt;published, albert einstein, in 1915&gt;, and &lt;published, theory of relativity, 1915&gt;. Obviously, in such a system, we see at least as many (typically, more) such tuples/quadruples as the number of verbs. While this is an advantage in the sense that it can extract all such relations, the challenge with this approach lies in mapping the extracted versions to some standardized set of relations (e.g., fatherOf, motherOf, inventorOf, etc.) from a database. To then extract specific relations from this information (if we need to), we would have to devise our own procedures combining the outputs of NER/NEL, coreference resolution, and open IE<a contenteditable="false" data-primary="relationship extraction (RE)" data-secondary="approaches to" data-startref="ch05_term19" data-type="indexterm" id="idm45969596846824"/>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="RE with the Watson API"><div class="sect2" id="re_with_the_watson_api">
<h2>RE with the Watson API</h2>

<p><a contenteditable="false" data-primary="relationship extraction (RE)" data-secondary="with Watson API" data-secondary-sortas="Watson API" data-type="indexterm" id="ch05_term20"/><a contenteditable="false" data-primary="IBM Watson" data-secondary="RE with" data-type="indexterm" id="ch05_term221"/>RE is a hard problem, and it would be challenging and time consuming to develop our own relation extraction systems from scratch. A solution commonly used in NLP projects in the industry is to rely on the Natural Language Understanding service provided by IBM Watson [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596839352-marker" href="ch05.xhtml#idm45969596839352">42</a>]. The next code snippet (<em>Ch5/REWatson.ipynb</em>) shows how to extract relationships between entities with IBM Watson using a text snippet from the Wikipedia page referenced earlier in this section:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">mytext3</code> <code class="o">=</code> <code class="s2">"""Nadella attended the Hyderabad Public School, Begumpet [12] before </code>
<code class="s2">receiving a bachelor's in electrical engineering[13] from the Manipal Institute </code>
<code class="s2">of Technology (then part of Mangalore University)in Karnataka in 1988."""</code>
<code class="n">response</code> <code class="o">=</code> <code class="n">natural_language_understanding</code><code class="o">.</code><code class="n">analyze</code><code class="p">(</code><code class="n">text</code><code class="o">=</code><code class="n">mytext3</code><code class="p">,</code>
            <code class="n">features</code><code class="o">=</code><code class="n">Features</code><code class="p">(</code><code class="n">relations</code><code class="o">=</code><code class="n">RelationsOptions</code><code class="p">()))</code><code class="o">.</code><code class="n">get_result</code><code class="p">()</code>
<code class="k">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">response</code><code class="p">[</code><code class="s1">'relations'</code><code class="p">]:</code>
         <code class="k">print</code><code class="p">(</code><code class="n">item</code><code class="p">[</code><code class="s1">'type'</code><code class="p">])</code>
         <code class="k">for</code> <code class="n">subitem</code> <code class="ow">in</code> <code class="n">item</code><code class="p">[</code><code class="s1">'arguments'</code><code class="p">]:</code>
         	<code class="k">print</code><code class="p">(</code><code class="n">subitem</code><code class="p">[</code><code class="s1">'entities'</code><code class="p">])</code></pre>

<p><a data-type="xref" href="#relation_extraction_output_from_ibm_wat">Figure 5-12</a> shows the output of this code in terms of the relations it extracted. The relations are extracted using a supervised model and contain a preset list of relations [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596790728-marker" href="ch05.xhtml#idm45969596790728">43</a>]. Thus, anything outside that list of relations will not be extracted.</p>

<figure><div id="relation_extraction_output_from_ibm_wat" class="figure"><img alt="Relation extraction output from IBM Watson" src="Images/pnlp_0512.png" width="880" height="307"/>
<h6><span class="label">Figure 5-12. </span>Relation extraction output from IBM Watson</h6>
</div></figure>

<p>This output information, showing relations between different entities, can then be used to construct a knowledge base for the organization’s data. As we can see, RE is not a completely solved problem yet, and the performance of the approach is also domain dependent. What worked for a Wikipedia article may not work for a general news article or, say, social media text. [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596786808-marker" href="ch05.xhtml#idm45969596786808">44</a>] summarizes the state of the art in RE.</p>

<div data-type="tip"><h6>Tip</h6>
<p>Start with pattern-based approaches and use some form of weak supervision in scenarios where pre-trained supervised models may not work.</p>
</div>

<p>We hope this gave an overview of where RE is useful and how to approach the problem if you encounter it at your workplace. Let’s now take a look at a few other IE tasks before concluding the discussion on this<a contenteditable="false" data-primary="relationship extraction (RE)" data-startref="ch05_term18" data-type="indexterm" id="idm45969596783464"/><a contenteditable="false" data-primary="relationship extraction (RE)" data-secondary="with Watson API" data-secondary-sortas="Watson API" data-startref="ch05_term20" data-type="indexterm" id="idm45969596712344"/><a contenteditable="false" data-primary="IBM Watson" data-secondary="RE with" data-startref="ch05_term221" data-type="indexterm" id="idm45969596710408"/> topic.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Other Advanced IE Tasks"><div class="sect1" id="other_advanced_ie_tasks">
<h1>Other Advanced IE Tasks</h1>

<p><a contenteditable="false" data-primary="information extraction (IE)" data-secondary="advanced tasks" data-type="indexterm" id="ch05_term21"/>So far, we’ve discussed different information extraction tasks, where they’re useful, and how we can build them into our NLP projects if required. While this list of tasks is by no means exhaustive, they’re the tasks most commonly used across industry use cases. In this section, let’s take a quick look at a few more specialized IE tasks. These are not very common and are used sparingly in NLP projects in the industry, so we’ll only introduce them briefly in this section. We would advise the reader to start with [<a data-type="noteref" href="ch05.xhtml#footnote_5_7">26</a>] to get further guidance on the different approaches for solving these tasks. Let’s look at an overview of three other IE tasks: temporal IE, event extraction, and template filling.</p>

<section data-type="sect2" data-pdf-bookmark="Temporal Information Extraction"><div class="sect2" id="temporal_information_extraction">
<h2>Temporal Information Extraction</h2>

<p><a contenteditable="false" data-primary="temporal information extraction" data-type="indexterm" id="ch05_term22"/><a contenteditable="false" data-primary="information extraction (IE)" data-secondary="temporal" data-type="indexterm" id="ch05_term23"/>Consider an email text: “Let us meet at 3 p.m. today and decide on what to present at the meeting on Friday.” Say we’re working on an application to identify and populate calendars with events extracted from such conversations, much like we see in Gmail. <a data-type="xref" href="#identifying_and_extracting_temporal_eve">Figure 5-13</a> shows a screenshot of this utility in Gmail<a contenteditable="false" data-primary="Gmail" data-type="indexterm" id="idm45969596697192"/>.</p>



<p>To build a similar application, in addition to extracting date and time information (3 pm, today, Friday) from the text, we should also convert the extracted data into some kind of standard form (e.g., mapping the expression “on Friday” to the exact date, based on context, and “today” to today’s date). While extracting date and time information can be done using a collection of handcrafted patterns in the form of regex, or by applying supervised sequence labeling techniques like we did for NER, normalization of extracted date and time into a standard date-time format can be challenging. Together, these tasks are referred to as <em>temporal IE and normalization</em><a contenteditable="false" data-primary="normalization" data-secondary="temporal IE and normalization" data-type="indexterm" id="idm45969596694600"/><a contenteditable="false" data-primary="temporal IE and normalization" data-type="indexterm" id="idm45969596693192"/>. Contemporary approaches to such temporal expression normalization are primarily rule based and coupled with semantic analysis [<a data-type="noteref" href="ch05.xhtml#footnote_5_7">26</a>].</p>

<figure><div id="identifying_and_extracting_temporal_eve" class="figure"><img alt="Identifying and extracting temporal events from emails [_23]" src="Images/pnlp_0513.png" width="572" height="309"/>
<h6><span class="label">Figure 5-13. </span>Identifying and extracting temporal events from emails<a contenteditable="false" data-primary="emails: IE from" data-type="indexterm" id="idm45969596689240"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596688008-marker" href="ch05.xhtml#idm45969596688008">45</a>]</h6>
</div></figure>

<p>Duckling<a contenteditable="false" data-primary="Duckling library" data-type="indexterm" id="idm45969596686056"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596684792-marker" href="ch05.xhtml#idm45969596684792">46</a>] is a Python library recently released by Facebook’s bots team that was used to build bots for Facebook Messenger<a contenteditable="false" data-primary="Facebook Messenger" data-type="indexterm" id="idm45969596683176"/>. The package is designed to parse text and get structured data. Among the many tasks it can do, it can process the natural language text data to extract temporal events. <a data-type="xref" href="#fig_5_14_sample_output_of_temporal_ie_v">Figure 5-14</a> shows the output when we run the sentence “Let us meet at 3 p.m. today and decide on what to present at the meeting on Friday” through Duckling. It’s able to map “3 p.m. today” to the correct time on a given day.</p>



<p>Duckling supports multiple languages. From our experience, it works very well and is a great off-the-shelf package to begin with if you want to incorporate some form of temporal IE into your project. Other packages, such as SUTime<a contenteditable="false" data-primary="SUTime (Stanford NLP)" data-type="indexterm" id="idm45969596679640"/><a contenteditable="false" data-primary="Stanford Natural Language Processing Group" data-secondary="SUTime" data-type="indexterm" id="idm45969596678536"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596676936-marker" href="ch05.xhtml#idm45969596676936">47</a>] by Stanford NLP, Natty<a contenteditable="false" data-primary="Natty" data-type="indexterm" id="idm45969596675432"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596674264-marker" href="ch05.xhtml#idm45969596674264">48</a>], Parsedatetime<a contenteditable="false" data-primary="Parsedatetime" data-type="indexterm" id="idm45969596672776"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596671544-marker" href="ch05.xhtml#idm45969596671544">49</a>], and Chronic<a contenteditable="false" data-primary="Chronic" data-type="indexterm" id="idm45969596670056"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596668824-marker" href="ch05.xhtml#idm45969596668824">50</a>], are also capable of processing human-readable dates and times. We leave it to the reader to explore these packages further and see how useful they are for temporal IE. Now, let’s move on to the next IE task: event extraction.<a contenteditable="false" data-primary="temporal information extraction" data-startref="ch05_term22" data-type="indexterm" id="idm45969596632936"/><a contenteditable="false" data-primary="information extraction (IE)" data-secondary="temporal" data-startref="ch05_term23" data-type="indexterm" id="idm45969596631560"/></p>

<figure><div id="fig_5_14_sample_output_of_temporal_ie_v" class="figure"><img alt="Sample output of temporal IE via Duckling" src="Images/pnlp_0514.png" width="992" height="547"/>
<h6><span class="label">Figure 5-14. </span>Sample output of temporal IE via Duckling</h6>
</div></figure>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Event Extraction"><div class="sect2" id="event_extraction">
<h2>Event Extraction</h2>

<p><a contenteditable="false" data-primary="event extraction" data-type="indexterm" id="ch05_term24"/>In the email-text example we discussed in the previous section, the aim of extracting temporal expressions is to eventually extract information about an “event.” Events can be anything that happens at a certain point in time: meetings, increase in fuel prices in a region at a certain time, presidential elections, the rise and fall of stocks, life events like birth, marriage, and demise, and so on. <em>Event extraction</em> is the IE task that deals with identifying and extracting events from text data. <a data-type="xref" href="#examples_of_extracting_life_events_from">Figure 5-15</a> shows an example of extracting life events from people’s Twitter feeds.</p>



<p>There are many business applications of event extraction. Consider a finance-lending company that reaches out to people for education loans. Wouldn’t they love to have a system that can scan Twitter feeds and identify “university admission” events? Or consider a trade analyst in a hedge fund who needs to keep tabs on major events around the world. It’s believed that Bloomberg Terminal<a contenteditable="false" data-primary="Bloomberg Terminal" data-type="indexterm" id="idm45969596621960"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596620728-marker" href="ch05.xhtml#idm45969596620728">51</a>] has a submodule that reports major events that are identified from thousands of news sources and social channels like Twitter in real time across the globe. A popular, fun application of event extraction is the congratsbot<a contenteditable="false" data-primary="congratsbot" data-type="indexterm" id="idm45969596619080"/> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596617912-marker" href="ch05.xhtml#idm45969596617912">52</a>]. The bot reads through tweets and responds with a “congrats” message if it sees any event that one should be congratulated on. See <a data-type="xref" href="#congratsbot_in_action">Figure 5-16</a> for an example.</p>

<figure><div id="examples_of_extracting_life_events_from" class="figure"><img alt="Examples of extracting life events from Twitter data [_47]" src="Images/pnlp_0515.png" width="1418" height="538"/>
<h6><span class="label">Figure 5-15. </span>Examples of extracting life events from Twitter<a contenteditable="false" data-primary="Twitter" data-secondary="event extraction from" data-type="indexterm" id="idm45969596613672"/> data [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596612168-marker" href="ch05.xhtml#idm45969596612168">53</a>]</h6>
</div></figure>

<figure><div id="congratsbot_in_action" class="figure"><img alt="Congratsbot in action" src="Images/pnlp_0516.png" width="623" height="235"/>
<h6><span class="label">Figure 5-16. </span>Congratsbot in action</h6>
</div></figure>

<p>So, how should we approach this problem? Event extraction is treated as a supervised learning problem in NLP literature. Contemporary approaches use sequence tagging and multilevel classifiers, much like we saw earlier with relationship extraction. The ultimate goal is to identify various events over time periods, connect them, and create a temporally ordered event graph. This is still an active area of research, and working solutions for event extraction like those mentioned previously only work for specific scenarios; i.e., there are no relatively generic solutions like we saw for RE, NER, etc. To the best of our knowledge, there are no off-the-shelf services or packages for this task. If you end up doing a project that requires event extraction, the best way forward is to first start with a rule-based approach based on domain knowledge, then follow it up with weak supervision. As you start accumulating more data, you can move toward ML<a contenteditable="false" data-primary="event extraction" data-startref="ch05_term24" data-type="indexterm" id="idm45969596606200"/> approaches.</p>
</div></section>

<section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Template Filling"><div class="sect2" id="template_filling">
<h2 class="less_space">Template Filling</h2>

<p><a contenteditable="false" data-primary="template filling" data-type="indexterm" id="ch05_term25"/>In some application scenarios, such as weather forecasts and financial reports, the text format is fairly standard, and what changes are the specific details pertaining to that situation. For example, consider a scenario where we work in an organization that sends reports on companies’ stock prices on a daily basis. The format of these reports will be similar for most companies. An example of one such “template” sentence is: “Company X’s stock is up by Y% since yesterday,” where X and Y change but the sentence pattern remains the same. If we’re asked to automate the report generation process, how should we approach it? Such scenarios are good use cases for an IE task called <em>template filling</em><em>,</em> where the task is to model text generation as a slot-filling problem. <a data-type="xref" href="#example_of_template_filling_left_square">Figure 5-17</a> shows an example of template filling and how it can be used to build an entity graph.</p>

<figure><div id="example_of_template_filling_left_square" class="figure"><img alt="Example of template filling [_46]" src="Images/pnlp_0517.png" width="1129" height="1317"/>
<h6><span class="label">Figure 5-17. </span>Example of template filling [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596596680-marker" href="ch05.xhtml#idm45969596596680">54</a>]</h6>
</div></figure>

<p>Generally, the templates to fill are pre-defined. This is typically modeled as a two-stage, supervised ML problem, similar to relation extraction. The first step involves identifying whether a template is present in a given sentence, and the second step involves identifying slot fillers for that template, with a separate classifier trained for each slot. Work is being done in the direction of automatically inducing templates. Since this is a specialized, domain-dependent case, we’re not aware of any off-the-shelf service provider for this task. As with other tasks in this section, we recommend you start with the chapter on IE in [<a data-type="noteref" href="ch05.xhtml#footnote_5_24">31</a>] to gain further understanding.</p>

<p>A recent real-world example of template filling–based text generation is the BBC<a contenteditable="false" data-primary="BBC" data-type="indexterm" id="idm45969596592840"/>’s coverage of the 2019 UK elections. BBC created a template and created news stories automatically for all of the UK’s 650 electoral areas. [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596591448-marker" href="ch05.xhtml#idm45969596591448">55</a>] and [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="idm45969596589416-marker" href="ch05.xhtml#idm45969596589416">56</a>] discuss this project in greater detail.</p>

<p>With this, we conclude our discussion of most IE tasks. So far, we’ve seen a wide range of IE tasks and how to incorporate some of them individually in your code. How do these tasks connect with one another in a real-world application? Let’s discuss<a contenteditable="false" data-primary="information extraction (IE)" data-secondary="advanced tasks" data-startref="ch05_term21" data-type="indexterm" id="idm45969596586728"/><a contenteditable="false" data-primary="template filling" data-startref="ch05_term25" data-type="indexterm" id="idm45969596585016"/> a case study.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Case Study"><div class="sect1" id="case_study-id00005">
<h1>Case Study</h1>

<p><a contenteditable="false" data-primary="information extraction (IE)" data-secondary="case study" data-type="indexterm" id="ch05_term26"/>Imagine we work for a large, traditional enterprise. We communicate via email and enterprise messaging platforms like Slack or Yammer. A lot of discussions about meetings happen as part of email threads. There are the three main types of meetings: team meeting, one-on-one meeting, and talk/presentation, plus their associated venues. Say we’re tasked with building a system that automatically finds relevant meetings, books the venue or conference hall, and notifies people. Let’s look at how the IE tasks we’ve discussed would be useful in this scenario. We’ll assume that there’s only one meeting per email. Look at the email exchange in <a data-type="xref" href="#meeting_information_extraction_from_ema">Figure 5-18</a> for our scenario description. How would we go about starting to build that?</p>



<p>As a caveat, we might need to restrict what we’re building at the start and solve a more focused problem. For instance, an email my contain multiple meeting mentions, like in this example: “MountLogan was a good venue. Let us meet there tomorrow and have an all hands in MountRainer on Thursday.” Let’s assume there’s only one meeting per email in our case study and start thinking about how to approach the problem of building a simple system as an MVP to get started.</p>

<p>First, we’ll need some amount of labeled data. We can start building labeled data in multiple ways. Imagine we have access to past calendar and conference booking information as well as email. Does comparing booking information and the emails yield positive matches? If so, we could try hardcoded weak supervision, similar to the one described in <a data-type="xref" href="ch04.xhtml#text_classification">Chapter 4</a>. Alternatively, we could try bootstrapping with pre-built services like Google Cloud NLP<a contenteditable="false" data-primary="Google Cloud" data-secondary="NLP" data-type="indexterm" id="idm45969596575352"/> or AWS Comprehend<a contenteditable="false" data-primary="Amazon Comprehend" data-type="indexterm" id="idm45969596573848"/>. For example, Google Cloud NLP has an entity extraction service that returns events, and we can use it to generate a dataset. However, as such automatically created datasets may not be perfect, we’ll need manual verification.</p>



<p>Let’s say we’re dealing with the following entities and have collected some data with these annotations: Room Name (Meeting Location), Meeting Date, Meeting Time, Meeting Type (derived field), Meeting Invitees. For our first model, we can use a sequence labeling model like conditional random fields (CRFs), which are also used for NER. To classify the type of meeting, we can start with a rule-based classifier based on features such as room size (larger rooms may generally imply larger meetings), number of invitees, etc.</p>

<figure><div id="meeting_information_extraction_from_ema" class="figure"><img alt="Meeting information extraction from email (representative image)" src="Images/pnlp_0518.png" width="560" height="763"/>
<h6><span class="label">Figure 5-18. </span>Meeting information extraction from email<a contenteditable="false" data-primary="emails: IE from" data-type="indexterm" id="idm45969596569576"/> (representative image)</h6>
</div></figure>

<p>Once our system is in deployment, we can start collecting feedback in the form of explicit tagging or more implicit feedback. These may include meeting accept/reject rates and meeting conflict rates on the calendar and for the room. All this information can be used to collect more data so we can apply more sophisticated models.</p>

<p>Once we have enough data (5–10K labeled sentences from emails), we can start exploring more powerful language understanding models. If enough compute power is available, we may take advantage of a powerful pre-trained model like BERT and can fine-tune it on the new labeled dataset. The pipeline for this process is depicted in <a data-type="xref" href="#pipeline_for_meeting_information_extrac">Figure 5-19</a>.</p>

<figure><div id="pipeline_for_meeting_information_extrac" class="figure"><img alt="Pipeline for meeting information extraction system development" src="Images/pnlp_0519.png" width="995" height="1553"/>
<h6><span class="label">Figure 5-19. </span>Pipeline for meeting information extraction system development</h6>
</div></figure>

<p>Now let’s consider the more complex case we discussed at the beginning, where we may have mentions of multiple entities (room names) and also loose mentions of multiple meetings happening at different times. We want to tackle this problem as a multiclass, multilabel classification problem. The linguistic ambiguity could be hard to decipher via handcrafted feature engineering like the presence of some specific entity, fixed vocabulary, etc. A reasonable way to approach this problem would be to use a deeper neural network with recurrence, such as an LSTM or a GRU network. These networks will model contextual information around each word and encode that knowledge into the hidden vectors we would use to finally classify the email. While all this discussion is specific to one real-world IE problem, it’s possible to incrementally implement and improve a solution to any IE problem using the approach outlined in this<a contenteditable="false" data-primary="information extraction (IE)" data-secondary="case study" data-startref="ch05_term26" data-type="indexterm" id="idm45969596562184"/> section.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Wrapping Up"><div class="sect1" id="wrapping_up-id00070">
<h1>Wrapping Up</h1>

<p>In this chapter, we looked at information extraction and its usefulness in different real-world scenarios and discussed how to implement solutions for different IE tasks, including keyphrase extraction, named entity recognition, named entity linking, and relationship extraction. We also introduced the tasks of temporal information extraction, event extraction, and template filling. Compared to what we saw with text classification, an important difference with IE is that these tasks rely on resources beyond large annotated corpora and also require more domain knowledge. Hence, in a practical scenario, it’s more common to use pre-trained models and solutions from large service providers rather than developing IE systems of our own from scratch, unless we’re working on a super-specialized domain that needs custom solutions. Another important point to note, which we also reiterated several times throughout the chapter, is the role that a good text extraction and cleanup process plays in all these tasks. While we didn’t take up specific end-to-end examples involving multiple IE tasks (some of which will be covered in <a data-type="xref" href="part03.xhtml#applied">Part III</a> of the book), we hope that this chapter gives you enough of an idea about IE and the things to keep in mind when implementing IE tasks in your projects. In the next chapter, we’ll take a look at how to build chatbots for different use cases you may encounter in your workplace.</p>
</div></section>

<div data-type="footnotes"><h5>Footnotes</h5></div><div data-type="footnotes"><h5>References</h5><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969598002856">[<a href="ch05.xhtml#idm45969598002856-marker">1</a>] Wikipedia. <a href="https://oreil.ly/trYdm">“Message Understanding Conference”</a>. Last modified November 20, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597999992">[<a href="ch05.xhtml#idm45969597999992-marker">2</a>] Linguistic Data Consortium. <a href="https://oreil.ly/Zy0VO">“ACE”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597996040">[<a href="ch05.xhtml#idm45969597996040-marker">3</a>] NIST. <a href="https://tac.nist.gov">“Text Analysis Conference”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597985352">[<a href="ch05.xhtml#idm45969597985352-marker">4</a>] <a href="https://news.google.ca">Google News</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597964424">[<a href="ch05.xhtml#idm45969597964424-marker">5</a>] Sarno, Adrian. <a href="https://oreil.ly/bpw5v">“Information Extraction from Receipts with Graph Convolutional Networks”</a>, <em>Nanonets (blog)</em>, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597962504">[<a href="ch05.xhtml#idm45969597962504-marker">6</a>] <a href="https://oreil.ly/zDNVs">Sensibill</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597951656">[<a href="ch05.xhtml#idm45969597951656-marker">7</a>] Nicas, Jack. <a href="https://oreil.ly/LJnCI">“Apple’s Plan to Buy $75 Billion of Its Stock Fuels Spending Debate”</a>. <em>New York Times</em>, April 30, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597930520">[<a href="ch05.xhtml#idm45969597930520-marker">8</a>] Chiticariu, Laura, Yunyao Li, and Frederick Reiss. “Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!” <em>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</em> (2013): 827–832.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597929336">[<a href="ch05.xhtml#idm45969597929336-marker">9</a>] Chiticariu, L. et al. “Web Information Extraction”. In Liu, L. and Özsu, M.T. (eds), <em>Encyclopedia of Database Systems</em>, New York: Springer, 2018.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597897080">[<a href="ch05.xhtml#idm45969597897080-marker">10</a>] Hasan, Kazi Saidul and Vincent Ng. “Automatic Keyphrase Extraction: A Survey of the State of the Art.” <em>Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</em> 1: (2014): 1262–1273.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597895320">[<a href="ch05.xhtml#idm45969597895320-marker">11</a>] Çano, Erion and Ondřej Bojar. “Keyphrase Generation: A Text Summarization Struggle.” <em>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em> 1 (2019): 666–672.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597888696">[<a href="ch05.xhtml#idm45969597888696-marker">12</a>] Chartbeat Labs Projects. <a href="https://oreil.ly/9INdz">textacy: NLP, before and after spaCy</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597887064">[<a href="ch05.xhtml#idm45969597887064-marker">13</a>] Explosion.ai. <a href="https://spacy.io">“SpaCy: Industrial-Strength Natural Language Processing in Python”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597885048">[<a href="ch05.xhtml#idm45969597885048-marker">14</a>] Mihalcea, Rada and Paul Tarau. “Textrank: Bringing Order into Text.” <em>Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</em> (2004): 404–411.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597757016">[<a href="ch05.xhtml#idm45969597757016-marker">15</a>] Gensim. <a href="https://oreil.ly/74MxG">“summarization.keywords—Keywords for TextRank summarization algorithm”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597755576">[<a href="ch05.xhtml#idm45969597755576-marker">16</a>] Chowdhury, Jishnu Ray. <a href="https://oreil.ly/05FtV">“Implementation of TextRank”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597729000">[<a href="ch05.xhtml#idm45969597729000-marker">17</a>] Explosion.ai. <a href="https://oreil.ly/1nhKg">“displaCy Named Entity Visualizer”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597726888">[<a href="ch05.xhtml#idm45969597726888-marker">18</a>] spaCy. <a href="https://oreil.ly/ztbb7">Common entity categories in NER development</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597712120">[<a href="ch05.xhtml#idm45969597712120-marker">19</a>] The Stanford Natural Language Processing Group. <a href="https://oreil.ly/9kXyW">“Stanford RegexNER”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597708136">[<a href="ch05.xhtml#idm45969597708136-marker">20</a>] Explosion.ai. <a href="https://oreil.ly/m7eXK">spacy’s EntityRuler</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597702248">[<a href="ch05.xhtml#idm45969597702248-marker">21</a>] Wikipedia. <a href="https://oreil.ly/YDupI">“Sequence labeling”</a>. Last modified January 18, 2017.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597694200">[<a href="ch05.xhtml#idm45969597694200-marker">22</a>] Sang, Erik F. and Fien De Meulder. “Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition.” <em>Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL</em> (2003).</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597692952">[<a href="ch05.xhtml#idm45969597692952-marker">23</a>] Team HG-Memex. <a href="https://oreil.ly/kgHD5">sklearn-crfsuite: scikit-learn inspired API for CRFsuite</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_5_43">[<a href="ch05.xhtml#footnote_5_43-marker">24</a>] MIT-NLP. <a href="https://oreil.ly/SZPdT">MITIE: library and tools for information extraction</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597376232">[<a href="ch05.xhtml#idm45969597376232-marker">25</a>] Yang, Jie. <a href="https://oreil.ly/vqAeA">NCRF++: a Neural Sequence Labeling Toolkit</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_5_7">[<a href="ch05.xhtml#footnote_5_7-marker">26</a>] Jurafsky, Dan and James H. Martin. <a href="https://oreil.ly/Ta16f"><em>Speech and Language Processing</em>, Third Edition (Draft)</a>, 2018, Chapter 18.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597364920">[<a href="ch05.xhtml#idm45969597364920-marker">27</a>] Linguistic Data Consortium. <a href="https://oreil.ly/3dDIU">“OntoNotes Release 5.0”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597356360">[<a href="ch05.xhtml#idm45969597356360-marker">28</a>] The Stanford Natural Language Processing Group. <a href="https://oreil.ly/ocVdM">“Stanford Named Entity Recognizer (NER)”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597352360">[<a href="ch05.xhtml#idm45969597352360-marker">29</a>] Allen Institute for AI. <a href="https://allennlp.org">“AllenNLP: An open-source NLP research library, built on PyTorch”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597167560">[<a href="ch05.xhtml#idm45969597167560-marker">30</a>] Explosion.ai. <a href="https://oreil.ly/YtP8J">Prodigy’s NER Recipes</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="footnote_5_24">[<a href="ch05.xhtml#footnote_5_24-marker">31</a>] Jurafsky, Daniel and James H. Martin. <em>Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition</em>. Upper Saddle River, NJ: Prentice Hall, 2008.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597153288">[<a href="ch05.xhtml#idm45969597153288-marker">32</a>] FilingDB. <a href="https://oreil.ly/W9VRo">“What’s so hard about PDF text extraction?”</a> Last accessed June 15, 2020.<a contenteditable="false" data-primary="information extraction (IE)" data-startref="ch05_term1" data-type="indexterm" id="idm45969597151944"/></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597130952">[<a href="ch05.xhtml#idm45969597130952-marker">33</a>] IBM Research Editorial Staff. <a href="https://oreil.ly/55aoa">“Making sense of language. Any language”</a>. October 28, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597121624">[<a href="ch05.xhtml#idm45969597121624-marker">34</a>] Wikipedia. <a href="https://oreil.ly/phOGJ">“Knowledge Graph”</a>. Last modified April 12, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597117400">[<a href="ch05.xhtml#idm45969597117400-marker">35</a>] NLP-progress. <a href="https://oreil.ly/5fhhN">“Entity Linking”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969597052072">[<a href="ch05.xhtml#idm45969597052072-marker">36</a>] DBpedia Spotlight. <a href="https://oreil.ly/wM1Ax">“Shedding light on the web of documents”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596892504">[<a href="ch05.xhtml#idm45969596892504-marker">37</a>] Rosette Text Analytics. <a href="https://oreil.ly/i_pXV">“Relationship Extraction”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596890904">[<a href="ch05.xhtml#idm45969596890904-marker">38</a>] Wikipedia. <a href="https://oreil.ly/4bjlF">“Satya Nadella”</a>. Last modified April 10, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596866616">[<a href="ch05.xhtml#idm45969596866616-marker">39</a>] Snorkel. <a href="https://oreil.ly/Is2Ll">“Detecting spouse mentions in sentences”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596856488">[<a href="ch05.xhtml#idm45969596856488-marker">40</a>] Allen Institute for AI. <a href="https://oreil.ly/nj3jL">“Reading Comprehension: Demo”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596854920">[<a href="ch05.xhtml#idm45969596854920-marker">41</a>] <a href="https://oreil.ly/cbd6v">AllenNLP’s GitHub repository</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596839352">[<a href="ch05.xhtml#idm45969596839352-marker">42</a>] IBM Cloud. <a href="https://oreil.ly/syL2g">“Watson Natural Language Understanding”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596790728">[<a href="ch05.xhtml#idm45969596790728-marker">43</a>] IBM Cloud. <a href="https://oreil.ly/y97Oo">Relation types</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596786808">[<a href="ch05.xhtml#idm45969596786808-marker">44</a>] NLP-progress. <a href="https://oreil.ly/7VZiR">“Relationship Extraction”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596688008">[<a href="ch05.xhtml#idm45969596688008-marker">45</a>] BetterCloud. <a href="https://oreil.ly/RcrLQ">“Hidden Shortcuts for Creating Calendar Events Right from Gmail”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596684792">[<a href="ch05.xhtml#idm45969596684792-marker">46</a>] Wit.ai. <a href="https://duckling.wit.ai">Duckling</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596676936">[<a href="ch05.xhtml#idm45969596676936-marker">47</a>] The Stanford Natural Language Processing Group. <a href="https://oreil.ly/8WQHC">“Stanford Temporal Tagger”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596674264">[<a href="ch05.xhtml#idm45969596674264-marker">48</a>] Stelmach, Joe. <a href="https://oreil.ly/Y7roo">“Natty”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596671544">[<a href="ch05.xhtml#idm45969596671544-marker">49</a>] Taylor, Mike. <a href="https://oreil.ly/tOVxl">“parsedatetime”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596668824">[<a href="ch05.xhtml#idm45969596668824-marker">50</a>] Preston-Warner, Tom. <a href="https://oreil.ly/Pt3op">Chronic: a pure Ruby natural language date parser</a>, (GitHub repo). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596620728">[<a href="ch05.xhtml#idm45969596620728-marker">51</a>] Bloomberg Professional Services. <a href="https://oreil.ly/UP2gQ">“Event-Driven Feeds”</a>. Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596617912">[<a href="ch05.xhtml#idm45969596617912-marker">52</a>] Twitter. Congratulatron (<a href="https://oreil.ly/fStKj">@congratsbot</a>). Last accessed June 15, 2020.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596612168">[<a href="ch05.xhtml#idm45969596612168-marker">53</a>] Li, Jiwei, Alan Ritter, Claire Cardie, and Eduard Hovy. <a href="https://oreil.ly/ixoM2">“Major Life Event Extraction from Twitter based on Congratulations/Condolences Speech Acts”</a>. <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</em> <em>(EMNLP)</em> (2014): 1997–2007.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596596680">[<a href="ch05.xhtml#idm45969596596680-marker">54</a>] Jean-Louis, Ludovic, Romaric Besançon, and Olivier Ferret. “Text Segmentation and Graph-based Method for Template Filling in Information Extraction.” <em>Proceedings of 5th International Joint Conference on Natural Language Processing</em> (2011): 723–731.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596591448">[<a href="ch05.xhtml#idm45969596591448-marker">55</a>] Molumby, Conor and Joe Whitwell. <a href="https://oreil.ly/NRiA0">“General Election 2019: Semi-Automation Makes It a Night of 689 Stories”</a>. <em>BBC News Labs</em>, December 13, 2019.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm45969596589416">[<a href="ch05.xhtml#idm45969596589416-marker">56</a>] Reiter, Ehud. <a href="https://oreil.ly/ukiXH">“Election Results: Lessons from a Real-World NLG System”</a>, <em>Ehud Reiter’s Blog</em>, December 23, 2019.</p></div></div></section></div>



  </body>
</html>